{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60718ffa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-04T13:56:59.295637Z",
     "start_time": "2023-07-04T13:56:59.286151Z"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1688887793547,
     "user": {
      "displayName": "Yoni Krichevsky",
      "userId": "07735752940575548299"
     },
     "user_tz": -180
    },
    "id": "60718ffa"
   },
   "outputs": [],
   "source": [
    "# ! pip install --user librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c223697b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-04T15:08:07.159437Z",
     "start_time": "2023-07-04T15:08:02.089282Z"
    },
    "executionInfo": {
     "elapsed": 4250,
     "status": "ok",
     "timestamp": 1688887799963,
     "user": {
      "displayName": "Yoni Krichevsky",
      "userId": "07735752940575548299"
     },
     "user_tz": -180
    },
    "id": "c223697b"
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from scipy.io import wavfile\n",
    "import scipy.signal\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import LSTM, Dense, Bidirectional, Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "s4x4DS3IxaYL",
   "metadata": {
    "id": "s4x4DS3IxaYL"
   },
   "source": [
    "## Mount Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "gWhFzrEkxZdC",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1688887799964,
     "user": {
      "displayName": "Yoni Krichevsky",
      "userId": "07735752940575548299"
     },
     "user_tz": -180
    },
    "id": "gWhFzrEkxZdC",
    "outputId": "417012ca-a509-4cde-ad58-b544d4bcb6fa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def is_running_on_colab():\n",
    "    try:\n",
    "        import google.colab\n",
    "        return True\n",
    "    except ImportError:\n",
    "        return False\n",
    "\n",
    "ON_COLAB = is_running_on_colab()\n",
    "ON_COLAB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "-SEvLXbvxe0A",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17659,
     "status": "ok",
     "timestamp": 1688887817618,
     "user": {
      "displayName": "Yoni Krichevsky",
      "userId": "07735752940575548299"
     },
     "user_tz": -180
    },
    "id": "-SEvLXbvxe0A",
    "outputId": "b7cae414-4e9d-469b-a759-1ff1502cd631"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/gdrive\n"
     ]
    }
   ],
   "source": [
    "if ON_COLAB:\n",
    "  from google.colab import drive\n",
    "  drive.mount('/content/gdrive')\n",
    "  intermediate_folder = Path('/content/gdrive/MyDrive/Colab Notebooks/Speech recognition')\n",
    "else:\n",
    "  intermediate_folder = Path('..') / 'data' / 'intermediate'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f22118",
   "metadata": {
    "id": "c0f22118"
   },
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1cf1809d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-04T15:23:08.691126Z",
     "start_time": "2023-07-04T15:23:08.359560Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11732,
     "status": "ok",
     "timestamp": 1688887833101,
     "user": {
      "displayName": "Yoni Krichevsky",
      "userId": "07735752940575548299"
     },
     "user_tz": -180
    },
    "id": "1cf1809d",
    "outputId": "731d3856-372e-4ef4-a6e3-7aeb4c517d28"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33566, 32, 20)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = np.load(intermediate_folder / 'train_main_1_sec_audio_mfcc.npy').transpose(0, 2, 1)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e323dc3a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-04T15:23:08.906806Z",
     "start_time": "2023-07-04T15:23:08.785010Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1069,
     "status": "ok",
     "timestamp": 1688887834167,
     "user": {
      "displayName": "Yoni Krichevsky",
      "userId": "07735752940575548299"
     },
     "user_tz": -180
    },
    "id": "e323dc3a",
    "outputId": "56c33fc8-e7a3-452a-b204-a6e3f82c8095"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4619, 32, 20)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "X_val = np.load(intermediate_folder / 'val_main_1_sec_audio_mfcc.npy').transpose(0, 2, 1)\n",
    "X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1947bcc5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-04T15:23:09.634515Z",
     "start_time": "2023-07-04T15:23:09.575687Z"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1688887834168,
     "user": {
      "displayName": "Yoni Krichevsky",
      "userId": "07735752940575548299"
     },
     "user_tz": -180
    },
    "id": "1947bcc5"
   },
   "outputs": [],
   "source": [
    "# X_test = np.load(intermediate_folder / 'test_main_1_sec_audio_mfcc.npy').transpose(0, 2, 1)\n",
    "# X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a94d9740",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-04T15:23:10.843802Z",
     "start_time": "2023-07-04T15:23:10.759245Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 889,
     "status": "ok",
     "timestamp": 1688887835055,
     "user": {
      "displayName": "Yoni Krichevsky",
      "userId": "07735752940575548299"
     },
     "user_tz": -180
    },
    "id": "a94d9740",
    "outputId": "6c0c0328-dd54-4d76-bcb4-6f643b9e77a4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((33566,), (4619,))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_labels = pd.read_csv(intermediate_folder / 'train_main_1_sec_labels.csv', header=None, index_col=False)[0]\n",
    "y_val_labels = pd.read_csv(intermediate_folder / 'val_main_1_sec_labels.csv', header=None, index_col=False)[0]\n",
    "# y_test_labels = pd.read_csv(intermediate_folder / 'test_main_1_sec_labels.csv', header=None, index_col=False)[0]\n",
    "y_train_labels.shape, y_val_labels.shape\n",
    "# y_train_labels.shape, y_val_labels.shape, y_test_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "z7I_fnXDy1ZS",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1688887835056,
     "user": {
      "displayName": "Yoni Krichevsky",
      "userId": "07735752940575548299"
     },
     "user_tz": -180
    },
    "id": "z7I_fnXDy1ZS",
    "outputId": "94ec53da-7fb5-4fe5-a7cc-d0941fa341d7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((33566,), (4619,))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "le.fit(y_train_labels)\n",
    "\n",
    "y_train = le.transform(y_train_labels)\n",
    "y_val = le.transform(y_val_labels)\n",
    "# y_test = le.transform(y_test_labels)\n",
    "y_train.shape, y_val.shape\n",
    "# y_train.shape, y_val.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "uxvX7cPdzMje",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1688887836512,
     "user": {
      "displayName": "Yoni Krichevsky",
      "userId": "07735752940575548299"
     },
     "user_tz": -180
    },
    "id": "uxvX7cPdzMje",
    "outputId": "c56b45c7-ae6a-4797-c32b-e5f0b3a5cd51"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     1667\n",
       "1     1655\n",
       "2     1696\n",
       "3     1662\n",
       "4     1647\n",
       "5     1683\n",
       "6     1723\n",
       "7     1630\n",
       "8     1668\n",
       "9     1650\n",
       "10    1672\n",
       "11    1687\n",
       "12    1708\n",
       "13    1727\n",
       "14    1715\n",
       "15    1672\n",
       "16    1693\n",
       "17    1591\n",
       "18    1686\n",
       "19    1734\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(y_train).value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3ajlBElxj9th",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 288,
     "status": "ok",
     "timestamp": 1688888082414,
     "user": {
      "displayName": "Yoni Krichevsky",
      "userId": "07735752940575548299"
     },
     "user_tz": -180
    },
    "id": "3ajlBElxj9th",
    "outputId": "630315ec-dbfd-4dce-d73b-3f3565d00bd0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4619, 32, 20)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "hYu90HBQkCXs",
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1688888083382,
     "user": {
      "displayName": "Yoni Krichevsky",
      "userId": "07735752940575548299"
     },
     "user_tz": -180
    },
    "id": "hYu90HBQkCXs"
   },
   "outputs": [],
   "source": [
    "assert np.mean(X_val[:, :, 0]) == np.mean(X_val.transpose(0, 2, 1)[:, 0, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qkzIR3-bjDAv",
   "metadata": {
    "id": "qkzIR3-bjDAv"
   },
   "source": [
    "## Standardize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "BqLe3gCOjFhD",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1688888132653,
     "user": {
      "displayName": "Yoni Krichevsky",
      "userId": "07735752940575548299"
     },
     "user_tz": -180
    },
    "id": "BqLe3gCOjFhD",
    "outputId": "ea0852a7-84b1-4669-973c-e1df15d021ac"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52.29702396428691, 173.88891616468194)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MEAN = X_train[:,:,:13].mean()\n",
    "STD = np.std(X_train[:,:,:13])\n",
    "MEAN, STD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "XlJt9Y4xj1Nt",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1688888134194,
     "user": {
      "displayName": "Yoni Krichevsky",
      "userId": "07735752940575548299"
     },
     "user_tz": -180
    },
    "id": "XlJt9Y4xj1Nt",
    "outputId": "14fde9a7-595a-4adc-c99d-9c3770215679"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((33566, 32, 20), (4619, 32, 20))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = (X_train - MEAN) / STD\n",
    "X_val = (X_val - MEAN) / STD\n",
    "# X_test = (X_test - MEAN) / STD\n",
    "X_train.shape, X_val.shape\n",
    "# X_train.shape, X_val.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0_rSMkZulkgM",
   "metadata": {
    "id": "0_rSMkZulkgM"
   },
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c_Y1l4B2lqud",
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1688888363912,
     "user": {
      "displayName": "Yoni Krichevsky",
      "userId": "07735752940575548299"
     },
     "user_tz": -180
    },
    "id": "c_Y1l4B2lqud"
   },
   "outputs": [],
   "source": [
    "def train(model, patience_train, patience_val=None, learning_rate=.001, X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, epochs=20, batch_size=128, cont_train=False):\n",
    "  print(f'{patience_train=}, {patience_val=}, {learning_rate=}, {epochs=}, {batch_size=}, {cont_train=}, {X_train.shape=}, {y_train.shape=}, {X_val.shape=}, {y_val.shape=}')\n",
    "  model.summary()\n",
    "  print(f'Input shape {model.input_shape}, output shape {model.output_shape}')\n",
    "  early_stopping = []\n",
    "  if patience_train:\n",
    "    early_stopping.append(EarlyStopping(monitor='loss', patience=patience_train))\n",
    "  if patience_val:\n",
    "    early_stopping.append(EarlyStopping(monitor='loss', patience=patience_val))\n",
    "\n",
    "  if not cont_train:\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate),\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "  model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(X_val, y_val), callbacks=[early_stopping]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Ub6F584ol4j7",
   "metadata": {
    "id": "Ub6F584ol4j7"
   },
   "source": [
    "## New simple RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "SdvPDN-DooJB",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 208839,
     "status": "ok",
     "timestamp": 1688889447055,
     "user": {
      "displayName": "Yoni Krichevsky",
      "userId": "07735752940575548299"
     },
     "user_tz": -180
    },
    "id": "SdvPDN-DooJB",
    "outputId": "556d9dad-1506-4e88-c28c-98678751c1d9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patience_train=5, patience_val=None, learning_rate=0.001, epochs=1000, batch_size=128, cont_train=False, X_train.shape=(33566, 32, 20), y_train.shape=(33566,), X_val.shape=(4619, 32, 20), y_val.shape=(4619,)\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_4 (LSTM)               (None, 32)                6784      \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 20)                660       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7,444\n",
      "Trainable params: 7,444\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Input shape (None, 32, 20), output shape (None, 20)\n",
      "Epoch 1/1000\n",
      "263/263 [==============================] - 3s 6ms/step - loss: 2.9997 - accuracy: 0.0516 - val_loss: 2.9981 - val_accuracy: 0.0517\n",
      "Epoch 2/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9968 - accuracy: 0.0504 - val_loss: 2.9972 - val_accuracy: 0.0530\n",
      "Epoch 3/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9964 - accuracy: 0.0508 - val_loss: 2.9965 - val_accuracy: 0.0489\n",
      "Epoch 4/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9960 - accuracy: 0.0536 - val_loss: 2.9968 - val_accuracy: 0.0528\n",
      "Epoch 5/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9957 - accuracy: 0.0532 - val_loss: 2.9971 - val_accuracy: 0.0522\n",
      "Epoch 6/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9955 - accuracy: 0.0543 - val_loss: 2.9973 - val_accuracy: 0.0515\n",
      "Epoch 7/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9953 - accuracy: 0.0516 - val_loss: 2.9976 - val_accuracy: 0.0528\n",
      "Epoch 8/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9952 - accuracy: 0.0543 - val_loss: 2.9978 - val_accuracy: 0.0489\n",
      "Epoch 9/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9952 - accuracy: 0.0541 - val_loss: 2.9971 - val_accuracy: 0.0494\n",
      "Epoch 10/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9950 - accuracy: 0.0541 - val_loss: 2.9980 - val_accuracy: 0.0481\n",
      "Epoch 11/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9948 - accuracy: 0.0544 - val_loss: 2.9977 - val_accuracy: 0.0470\n",
      "Epoch 12/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9946 - accuracy: 0.0543 - val_loss: 2.9975 - val_accuracy: 0.0468\n",
      "Epoch 13/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9947 - accuracy: 0.0546 - val_loss: 2.9972 - val_accuracy: 0.0520\n",
      "Epoch 14/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9944 - accuracy: 0.0529 - val_loss: 2.9988 - val_accuracy: 0.0465\n",
      "Epoch 15/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9943 - accuracy: 0.0562 - val_loss: 2.9978 - val_accuracy: 0.0504\n",
      "Epoch 16/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9941 - accuracy: 0.0569 - val_loss: 2.9978 - val_accuracy: 0.0509\n",
      "Epoch 17/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9942 - accuracy: 0.0553 - val_loss: 2.9988 - val_accuracy: 0.0463\n",
      "Epoch 18/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9939 - accuracy: 0.0569 - val_loss: 2.9982 - val_accuracy: 0.0491\n",
      "Epoch 19/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9940 - accuracy: 0.0568 - val_loss: 2.9975 - val_accuracy: 0.0448\n",
      "Epoch 20/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9936 - accuracy: 0.0548 - val_loss: 2.9983 - val_accuracy: 0.0489\n",
      "Epoch 21/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9937 - accuracy: 0.0585 - val_loss: 2.9986 - val_accuracy: 0.0433\n",
      "Epoch 22/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9934 - accuracy: 0.0561 - val_loss: 2.9990 - val_accuracy: 0.0452\n",
      "Epoch 23/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9934 - accuracy: 0.0557 - val_loss: 2.9989 - val_accuracy: 0.0485\n",
      "Epoch 24/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9931 - accuracy: 0.0565 - val_loss: 2.9991 - val_accuracy: 0.0442\n",
      "Epoch 25/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9927 - accuracy: 0.0565 - val_loss: 2.9988 - val_accuracy: 0.0515\n",
      "Epoch 26/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9926 - accuracy: 0.0562 - val_loss: 3.0002 - val_accuracy: 0.0500\n",
      "Epoch 27/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9924 - accuracy: 0.0582 - val_loss: 2.9989 - val_accuracy: 0.0478\n",
      "Epoch 28/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9921 - accuracy: 0.0582 - val_loss: 2.9996 - val_accuracy: 0.0515\n",
      "Epoch 29/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9918 - accuracy: 0.0593 - val_loss: 3.0026 - val_accuracy: 0.0496\n",
      "Epoch 30/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9913 - accuracy: 0.0593 - val_loss: 3.0005 - val_accuracy: 0.0474\n",
      "Epoch 31/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9911 - accuracy: 0.0606 - val_loss: 3.0000 - val_accuracy: 0.0461\n",
      "Epoch 32/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9904 - accuracy: 0.0597 - val_loss: 3.0017 - val_accuracy: 0.0533\n",
      "Epoch 33/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9902 - accuracy: 0.0596 - val_loss: 3.0007 - val_accuracy: 0.0478\n",
      "Epoch 34/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9894 - accuracy: 0.0606 - val_loss: 3.0040 - val_accuracy: 0.0481\n",
      "Epoch 35/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9890 - accuracy: 0.0599 - val_loss: 3.0014 - val_accuracy: 0.0450\n",
      "Epoch 36/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9881 - accuracy: 0.0638 - val_loss: 3.0063 - val_accuracy: 0.0474\n",
      "Epoch 37/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9877 - accuracy: 0.0625 - val_loss: 3.0017 - val_accuracy: 0.0489\n",
      "Epoch 38/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9868 - accuracy: 0.0626 - val_loss: 3.0030 - val_accuracy: 0.0502\n",
      "Epoch 39/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9864 - accuracy: 0.0618 - val_loss: 3.0042 - val_accuracy: 0.0478\n",
      "Epoch 40/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9856 - accuracy: 0.0628 - val_loss: 3.0050 - val_accuracy: 0.0476\n",
      "Epoch 41/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9850 - accuracy: 0.0654 - val_loss: 3.0053 - val_accuracy: 0.0507\n",
      "Epoch 42/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9840 - accuracy: 0.0646 - val_loss: 3.0116 - val_accuracy: 0.0502\n",
      "Epoch 43/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9832 - accuracy: 0.0654 - val_loss: 3.0069 - val_accuracy: 0.0463\n",
      "Epoch 44/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9825 - accuracy: 0.0658 - val_loss: 3.0053 - val_accuracy: 0.0520\n",
      "Epoch 45/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9819 - accuracy: 0.0651 - val_loss: 3.0083 - val_accuracy: 0.0485\n",
      "Epoch 46/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9810 - accuracy: 0.0672 - val_loss: 3.0105 - val_accuracy: 0.0476\n",
      "Epoch 47/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9800 - accuracy: 0.0685 - val_loss: 3.0101 - val_accuracy: 0.0470\n",
      "Epoch 48/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9794 - accuracy: 0.0662 - val_loss: 3.0082 - val_accuracy: 0.0535\n",
      "Epoch 49/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9787 - accuracy: 0.0680 - val_loss: 3.0108 - val_accuracy: 0.0489\n",
      "Epoch 50/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9774 - accuracy: 0.0683 - val_loss: 3.0114 - val_accuracy: 0.0539\n",
      "Epoch 51/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9766 - accuracy: 0.0686 - val_loss: 3.0112 - val_accuracy: 0.0511\n",
      "Epoch 52/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9766 - accuracy: 0.0689 - val_loss: 3.0102 - val_accuracy: 0.0494\n",
      "Epoch 53/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9749 - accuracy: 0.0710 - val_loss: 3.0137 - val_accuracy: 0.0511\n",
      "Epoch 54/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9742 - accuracy: 0.0703 - val_loss: 3.0105 - val_accuracy: 0.0526\n",
      "Epoch 55/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9733 - accuracy: 0.0692 - val_loss: 3.0205 - val_accuracy: 0.0496\n",
      "Epoch 56/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9724 - accuracy: 0.0706 - val_loss: 3.0118 - val_accuracy: 0.0478\n",
      "Epoch 57/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9722 - accuracy: 0.0710 - val_loss: 3.0133 - val_accuracy: 0.0498\n",
      "Epoch 58/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9709 - accuracy: 0.0703 - val_loss: 3.0134 - val_accuracy: 0.0513\n",
      "Epoch 59/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9696 - accuracy: 0.0712 - val_loss: 3.0152 - val_accuracy: 0.0513\n",
      "Epoch 60/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9685 - accuracy: 0.0731 - val_loss: 3.0166 - val_accuracy: 0.0526\n",
      "Epoch 61/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9677 - accuracy: 0.0732 - val_loss: 3.0228 - val_accuracy: 0.0489\n",
      "Epoch 62/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9672 - accuracy: 0.0745 - val_loss: 3.0159 - val_accuracy: 0.0498\n",
      "Epoch 63/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9659 - accuracy: 0.0756 - val_loss: 3.0227 - val_accuracy: 0.0507\n",
      "Epoch 64/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9666 - accuracy: 0.0743 - val_loss: 3.0188 - val_accuracy: 0.0524\n",
      "Epoch 65/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9650 - accuracy: 0.0734 - val_loss: 3.0189 - val_accuracy: 0.0468\n",
      "Epoch 66/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9636 - accuracy: 0.0750 - val_loss: 3.0244 - val_accuracy: 0.0463\n",
      "Epoch 67/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9625 - accuracy: 0.0756 - val_loss: 3.0245 - val_accuracy: 0.0522\n",
      "Epoch 68/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9614 - accuracy: 0.0775 - val_loss: 3.0167 - val_accuracy: 0.0548\n",
      "Epoch 69/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9616 - accuracy: 0.0766 - val_loss: 3.0241 - val_accuracy: 0.0481\n",
      "Epoch 70/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9603 - accuracy: 0.0759 - val_loss: 3.0273 - val_accuracy: 0.0509\n",
      "Epoch 71/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9583 - accuracy: 0.0774 - val_loss: 3.0269 - val_accuracy: 0.0513\n",
      "Epoch 72/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9579 - accuracy: 0.0786 - val_loss: 3.0200 - val_accuracy: 0.0520\n",
      "Epoch 73/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9573 - accuracy: 0.0798 - val_loss: 3.0297 - val_accuracy: 0.0498\n",
      "Epoch 74/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9560 - accuracy: 0.0798 - val_loss: 3.0264 - val_accuracy: 0.0487\n",
      "Epoch 75/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9547 - accuracy: 0.0802 - val_loss: 3.0307 - val_accuracy: 0.0526\n",
      "Epoch 76/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9545 - accuracy: 0.0800 - val_loss: 3.0260 - val_accuracy: 0.0515\n",
      "Epoch 77/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9526 - accuracy: 0.0814 - val_loss: 3.0279 - val_accuracy: 0.0546\n",
      "Epoch 78/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9516 - accuracy: 0.0805 - val_loss: 3.0379 - val_accuracy: 0.0500\n",
      "Epoch 79/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9508 - accuracy: 0.0818 - val_loss: 3.0297 - val_accuracy: 0.0524\n",
      "Epoch 80/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9512 - accuracy: 0.0809 - val_loss: 3.0352 - val_accuracy: 0.0522\n",
      "Epoch 81/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9480 - accuracy: 0.0814 - val_loss: 3.0330 - val_accuracy: 0.0511\n",
      "Epoch 82/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9477 - accuracy: 0.0831 - val_loss: 3.0352 - val_accuracy: 0.0541\n",
      "Epoch 83/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9465 - accuracy: 0.0814 - val_loss: 3.0306 - val_accuracy: 0.0507\n",
      "Epoch 84/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9452 - accuracy: 0.0828 - val_loss: 3.0340 - val_accuracy: 0.0511\n",
      "Epoch 85/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9451 - accuracy: 0.0840 - val_loss: 3.0340 - val_accuracy: 0.0511\n",
      "Epoch 86/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9449 - accuracy: 0.0831 - val_loss: 3.0343 - val_accuracy: 0.0520\n",
      "Epoch 87/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9438 - accuracy: 0.0834 - val_loss: 3.0363 - val_accuracy: 0.0494\n",
      "Epoch 88/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9417 - accuracy: 0.0840 - val_loss: 3.0454 - val_accuracy: 0.0533\n",
      "Epoch 89/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9405 - accuracy: 0.0846 - val_loss: 3.0358 - val_accuracy: 0.0513\n",
      "Epoch 90/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9401 - accuracy: 0.0862 - val_loss: 3.0399 - val_accuracy: 0.0565\n",
      "Epoch 91/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9393 - accuracy: 0.0846 - val_loss: 3.0475 - val_accuracy: 0.0528\n",
      "Epoch 92/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9381 - accuracy: 0.0842 - val_loss: 3.0378 - val_accuracy: 0.0528\n",
      "Epoch 93/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9368 - accuracy: 0.0857 - val_loss: 3.0516 - val_accuracy: 0.0483\n",
      "Epoch 94/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9362 - accuracy: 0.0855 - val_loss: 3.0407 - val_accuracy: 0.0500\n",
      "Epoch 95/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9350 - accuracy: 0.0874 - val_loss: 3.0361 - val_accuracy: 0.0530\n",
      "Epoch 96/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9347 - accuracy: 0.0889 - val_loss: 3.0450 - val_accuracy: 0.0522\n",
      "Epoch 97/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9338 - accuracy: 0.0878 - val_loss: 3.0433 - val_accuracy: 0.0552\n",
      "Epoch 98/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9334 - accuracy: 0.0874 - val_loss: 3.0446 - val_accuracy: 0.0507\n",
      "Epoch 99/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9302 - accuracy: 0.0898 - val_loss: 3.0588 - val_accuracy: 0.0509\n",
      "Epoch 100/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9315 - accuracy: 0.0883 - val_loss: 3.0467 - val_accuracy: 0.0567\n",
      "Epoch 101/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9308 - accuracy: 0.0893 - val_loss: 3.0550 - val_accuracy: 0.0522\n",
      "Epoch 102/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9301 - accuracy: 0.0878 - val_loss: 3.0526 - val_accuracy: 0.0517\n",
      "Epoch 103/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9277 - accuracy: 0.0897 - val_loss: 3.0459 - val_accuracy: 0.0528\n",
      "Epoch 104/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9295 - accuracy: 0.0887 - val_loss: 3.0545 - val_accuracy: 0.0528\n",
      "Epoch 105/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9263 - accuracy: 0.0888 - val_loss: 3.0581 - val_accuracy: 0.0513\n",
      "Epoch 106/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9260 - accuracy: 0.0902 - val_loss: 3.0606 - val_accuracy: 0.0513\n",
      "Epoch 107/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9255 - accuracy: 0.0919 - val_loss: 3.0514 - val_accuracy: 0.0509\n",
      "Epoch 108/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9247 - accuracy: 0.0908 - val_loss: 3.0548 - val_accuracy: 0.0526\n",
      "Epoch 109/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9232 - accuracy: 0.0905 - val_loss: 3.0593 - val_accuracy: 0.0500\n",
      "Epoch 110/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9225 - accuracy: 0.0926 - val_loss: 3.0597 - val_accuracy: 0.0526\n",
      "Epoch 111/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9213 - accuracy: 0.0927 - val_loss: 3.0608 - val_accuracy: 0.0509\n",
      "Epoch 112/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9212 - accuracy: 0.0932 - val_loss: 3.0597 - val_accuracy: 0.0513\n",
      "Epoch 113/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9213 - accuracy: 0.0927 - val_loss: 3.0609 - val_accuracy: 0.0509\n",
      "Epoch 114/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9208 - accuracy: 0.0924 - val_loss: 3.0530 - val_accuracy: 0.0509\n",
      "Epoch 115/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9200 - accuracy: 0.0924 - val_loss: 3.0614 - val_accuracy: 0.0487\n",
      "Epoch 116/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9199 - accuracy: 0.0920 - val_loss: 3.0640 - val_accuracy: 0.0483\n",
      "Epoch 117/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9179 - accuracy: 0.0933 - val_loss: 3.0665 - val_accuracy: 0.0502\n",
      "Epoch 118/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9166 - accuracy: 0.0947 - val_loss: 3.0622 - val_accuracy: 0.0526\n",
      "Epoch 119/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9177 - accuracy: 0.0944 - val_loss: 3.0607 - val_accuracy: 0.0504\n",
      "Epoch 120/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9143 - accuracy: 0.0936 - val_loss: 3.0733 - val_accuracy: 0.0474\n",
      "Epoch 121/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9141 - accuracy: 0.0943 - val_loss: 3.0643 - val_accuracy: 0.0546\n",
      "Epoch 122/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9152 - accuracy: 0.0951 - val_loss: 3.0609 - val_accuracy: 0.0513\n",
      "Epoch 123/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9128 - accuracy: 0.0962 - val_loss: 3.0711 - val_accuracy: 0.0483\n",
      "Epoch 124/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9107 - accuracy: 0.0973 - val_loss: 3.0806 - val_accuracy: 0.0500\n",
      "Epoch 125/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9131 - accuracy: 0.0964 - val_loss: 3.0670 - val_accuracy: 0.0530\n",
      "Epoch 126/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9117 - accuracy: 0.0955 - val_loss: 3.0743 - val_accuracy: 0.0511\n",
      "Epoch 127/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9107 - accuracy: 0.0957 - val_loss: 3.0643 - val_accuracy: 0.0524\n",
      "Epoch 128/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9098 - accuracy: 0.0967 - val_loss: 3.0783 - val_accuracy: 0.0504\n",
      "Epoch 129/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9103 - accuracy: 0.0966 - val_loss: 3.0688 - val_accuracy: 0.0533\n",
      "Epoch 130/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9093 - accuracy: 0.0967 - val_loss: 3.0822 - val_accuracy: 0.0496\n",
      "Epoch 131/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9080 - accuracy: 0.0983 - val_loss: 3.0808 - val_accuracy: 0.0507\n",
      "Epoch 132/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9084 - accuracy: 0.0962 - val_loss: 3.0793 - val_accuracy: 0.0507\n",
      "Epoch 133/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9087 - accuracy: 0.0961 - val_loss: 3.0751 - val_accuracy: 0.0502\n",
      "Epoch 134/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9078 - accuracy: 0.0963 - val_loss: 3.0740 - val_accuracy: 0.0500\n",
      "Epoch 135/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9062 - accuracy: 0.0984 - val_loss: 3.0783 - val_accuracy: 0.0517\n",
      "Epoch 136/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9041 - accuracy: 0.0982 - val_loss: 3.0814 - val_accuracy: 0.0500\n",
      "Epoch 137/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9044 - accuracy: 0.0978 - val_loss: 3.0768 - val_accuracy: 0.0491\n",
      "Epoch 138/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9034 - accuracy: 0.0993 - val_loss: 3.0937 - val_accuracy: 0.0461\n",
      "Epoch 139/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9032 - accuracy: 0.1002 - val_loss: 3.0769 - val_accuracy: 0.0528\n",
      "Epoch 140/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9007 - accuracy: 0.1015 - val_loss: 3.0916 - val_accuracy: 0.0509\n",
      "Epoch 141/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9010 - accuracy: 0.0992 - val_loss: 3.0858 - val_accuracy: 0.0507\n",
      "Epoch 142/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9021 - accuracy: 0.0987 - val_loss: 3.1015 - val_accuracy: 0.0496\n",
      "Epoch 143/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9014 - accuracy: 0.1004 - val_loss: 3.0829 - val_accuracy: 0.0509\n",
      "Epoch 144/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9001 - accuracy: 0.0986 - val_loss: 3.0985 - val_accuracy: 0.0502\n",
      "Epoch 145/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.8990 - accuracy: 0.0996 - val_loss: 3.0980 - val_accuracy: 0.0504\n",
      "Epoch 146/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.8994 - accuracy: 0.0993 - val_loss: 3.0814 - val_accuracy: 0.0522\n",
      "Epoch 147/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.8984 - accuracy: 0.1020 - val_loss: 3.0860 - val_accuracy: 0.0513\n",
      "Epoch 148/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9004 - accuracy: 0.1000 - val_loss: 3.0964 - val_accuracy: 0.0511\n",
      "Epoch 149/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.8972 - accuracy: 0.1008 - val_loss: 3.0927 - val_accuracy: 0.0500\n",
      "Epoch 150/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.8985 - accuracy: 0.0994 - val_loss: 3.0941 - val_accuracy: 0.0543\n",
      "Epoch 151/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.8955 - accuracy: 0.1004 - val_loss: 3.0935 - val_accuracy: 0.0515\n",
      "Epoch 152/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.8971 - accuracy: 0.1014 - val_loss: 3.0966 - val_accuracy: 0.0496\n",
      "Epoch 153/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.8959 - accuracy: 0.1007 - val_loss: 3.0982 - val_accuracy: 0.0483\n",
      "Epoch 154/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.8960 - accuracy: 0.1012 - val_loss: 3.1019 - val_accuracy: 0.0478\n",
      "Epoch 155/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.8984 - accuracy: 0.1028 - val_loss: 3.0976 - val_accuracy: 0.0507\n",
      "Epoch 156/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.8915 - accuracy: 0.1027 - val_loss: 3.0964 - val_accuracy: 0.0491\n",
      "Epoch 157/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.8914 - accuracy: 0.1029 - val_loss: 3.0974 - val_accuracy: 0.0524\n",
      "Epoch 158/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.8918 - accuracy: 0.1044 - val_loss: 3.0973 - val_accuracy: 0.0537\n",
      "Epoch 159/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.8912 - accuracy: 0.1034 - val_loss: 3.0985 - val_accuracy: 0.0500\n",
      "Epoch 160/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.8913 - accuracy: 0.1042 - val_loss: 3.0934 - val_accuracy: 0.0489\n",
      "Epoch 161/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.8913 - accuracy: 0.1055 - val_loss: 3.1097 - val_accuracy: 0.0491\n",
      "Epoch 162/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.8909 - accuracy: 0.1025 - val_loss: 3.0957 - val_accuracy: 0.0537\n",
      "Epoch 163/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.8896 - accuracy: 0.1041 - val_loss: 3.0979 - val_accuracy: 0.0533\n",
      "Epoch 164/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.8870 - accuracy: 0.1059 - val_loss: 3.0940 - val_accuracy: 0.0535\n",
      "Epoch 165/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.8903 - accuracy: 0.1033 - val_loss: 3.1049 - val_accuracy: 0.0530\n",
      "Epoch 166/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.8871 - accuracy: 0.1046 - val_loss: 3.0906 - val_accuracy: 0.0541\n",
      "Epoch 167/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.8889 - accuracy: 0.1045 - val_loss: 3.1024 - val_accuracy: 0.0504\n",
      "Epoch 168/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.8911 - accuracy: 0.1021 - val_loss: 3.0991 - val_accuracy: 0.0524\n",
      "Epoch 169/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.8864 - accuracy: 0.1049 - val_loss: 3.1014 - val_accuracy: 0.0526\n",
      "Epoch 170/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.8852 - accuracy: 0.1032 - val_loss: 3.1078 - val_accuracy: 0.0496\n",
      "Epoch 171/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.8883 - accuracy: 0.1011 - val_loss: 3.1056 - val_accuracy: 0.0520\n",
      "Epoch 172/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.8850 - accuracy: 0.1043 - val_loss: 3.1145 - val_accuracy: 0.0491\n",
      "Epoch 173/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.8838 - accuracy: 0.1054 - val_loss: 3.1139 - val_accuracy: 0.0535\n",
      "Epoch 174/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.8880 - accuracy: 0.1033 - val_loss: 3.1064 - val_accuracy: 0.0567\n",
      "Epoch 175/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.8840 - accuracy: 0.1073 - val_loss: 3.1071 - val_accuracy: 0.0522\n",
      "Epoch 176/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.8858 - accuracy: 0.1053 - val_loss: 3.0996 - val_accuracy: 0.0546\n",
      "Epoch 177/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.8847 - accuracy: 0.1048 - val_loss: 3.1113 - val_accuracy: 0.0522\n",
      "Epoch 178/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.8784 - accuracy: 0.1078 - val_loss: 3.1107 - val_accuracy: 0.0526\n",
      "Epoch 179/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.8805 - accuracy: 0.1070 - val_loss: 3.1105 - val_accuracy: 0.0556\n",
      "Epoch 180/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.8810 - accuracy: 0.1061 - val_loss: 3.1142 - val_accuracy: 0.0520\n",
      "Epoch 181/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.8784 - accuracy: 0.1063 - val_loss: 3.1200 - val_accuracy: 0.0491\n",
      "Epoch 182/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.8833 - accuracy: 0.1051 - val_loss: 3.1091 - val_accuracy: 0.0537\n",
      "Epoch 183/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.8798 - accuracy: 0.1066 - val_loss: 3.1242 - val_accuracy: 0.0554\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([LSTM(32, input_shape=(32, 20)),\n",
    "                  Dense(20, activation='softmax')])\n",
    "train(model=model,\n",
    "      patience_train=5,\n",
    "      patience_val=None,\n",
    "      learning_rate=.001,\n",
    "      epochs=1000,\n",
    "      batch_size=128,\n",
    "      # cont_train=True,\n",
    "      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "aPKQfBx6oTW8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 180892,
     "status": "ok",
     "timestamp": 1688889202945,
     "user": {
      "displayName": "Yoni Krichevsky",
      "userId": "07735752940575548299"
     },
     "user_tz": -180
    },
    "id": "aPKQfBx6oTW8",
    "outputId": "4a739c9c-e5d7-43e4-e1d6-97959c6fcf3c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patience_train=5, patience_val=None, learning_rate=0.001, epochs=1000, batch_size=128, cont_train=False, X_train.shape=(33566, 32, 20), y_train.shape=(33566,), X_val.shape=(4619, 32, 20), y_val.shape=(4619,)\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_3 (LSTM)               (None, 64)                21760     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 20)                1300      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 23,060\n",
      "Trainable params: 23,060\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Input shape (None, 32, 20), output shape (None, 20)\n",
      "Epoch 1/1000\n",
      "263/263 [==============================] - 3s 6ms/step - loss: 2.9997 - accuracy: 0.0489 - val_loss: 2.9967 - val_accuracy: 0.0524\n",
      "Epoch 2/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9973 - accuracy: 0.0504 - val_loss: 2.9967 - val_accuracy: 0.0474\n",
      "Epoch 3/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9964 - accuracy: 0.0521 - val_loss: 2.9972 - val_accuracy: 0.0507\n",
      "Epoch 4/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9960 - accuracy: 0.0526 - val_loss: 2.9976 - val_accuracy: 0.0517\n",
      "Epoch 5/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9956 - accuracy: 0.0537 - val_loss: 2.9970 - val_accuracy: 0.0498\n",
      "Epoch 6/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9956 - accuracy: 0.0529 - val_loss: 2.9972 - val_accuracy: 0.0507\n",
      "Epoch 7/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9954 - accuracy: 0.0532 - val_loss: 2.9972 - val_accuracy: 0.0457\n",
      "Epoch 8/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9951 - accuracy: 0.0540 - val_loss: 2.9974 - val_accuracy: 0.0530\n",
      "Epoch 9/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9948 - accuracy: 0.0557 - val_loss: 2.9976 - val_accuracy: 0.0435\n",
      "Epoch 10/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9948 - accuracy: 0.0544 - val_loss: 2.9971 - val_accuracy: 0.0543\n",
      "Epoch 11/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9947 - accuracy: 0.0553 - val_loss: 2.9976 - val_accuracy: 0.0504\n",
      "Epoch 12/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9944 - accuracy: 0.0545 - val_loss: 2.9970 - val_accuracy: 0.0530\n",
      "Epoch 13/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9944 - accuracy: 0.0549 - val_loss: 2.9975 - val_accuracy: 0.0517\n",
      "Epoch 14/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9941 - accuracy: 0.0557 - val_loss: 2.9987 - val_accuracy: 0.0513\n",
      "Epoch 15/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9939 - accuracy: 0.0564 - val_loss: 2.9974 - val_accuracy: 0.0489\n",
      "Epoch 16/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9938 - accuracy: 0.0566 - val_loss: 2.9981 - val_accuracy: 0.0463\n",
      "Epoch 17/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9937 - accuracy: 0.0545 - val_loss: 2.9978 - val_accuracy: 0.0470\n",
      "Epoch 18/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9935 - accuracy: 0.0556 - val_loss: 2.9981 - val_accuracy: 0.0496\n",
      "Epoch 19/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9931 - accuracy: 0.0564 - val_loss: 2.9981 - val_accuracy: 0.0487\n",
      "Epoch 20/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9927 - accuracy: 0.0570 - val_loss: 2.9984 - val_accuracy: 0.0483\n",
      "Epoch 21/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9925 - accuracy: 0.0560 - val_loss: 2.9993 - val_accuracy: 0.0550\n",
      "Epoch 22/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9920 - accuracy: 0.0569 - val_loss: 3.0003 - val_accuracy: 0.0442\n",
      "Epoch 23/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9920 - accuracy: 0.0571 - val_loss: 2.9987 - val_accuracy: 0.0470\n",
      "Epoch 24/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9912 - accuracy: 0.0588 - val_loss: 3.0012 - val_accuracy: 0.0474\n",
      "Epoch 25/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9907 - accuracy: 0.0571 - val_loss: 2.9995 - val_accuracy: 0.0491\n",
      "Epoch 26/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9905 - accuracy: 0.0586 - val_loss: 3.0008 - val_accuracy: 0.0509\n",
      "Epoch 27/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9899 - accuracy: 0.0603 - val_loss: 3.0012 - val_accuracy: 0.0543\n",
      "Epoch 28/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9892 - accuracy: 0.0600 - val_loss: 2.9999 - val_accuracy: 0.0559\n",
      "Epoch 29/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9881 - accuracy: 0.0621 - val_loss: 3.0021 - val_accuracy: 0.0511\n",
      "Epoch 30/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9875 - accuracy: 0.0610 - val_loss: 3.0032 - val_accuracy: 0.0530\n",
      "Epoch 31/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9870 - accuracy: 0.0610 - val_loss: 3.0025 - val_accuracy: 0.0487\n",
      "Epoch 32/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9857 - accuracy: 0.0625 - val_loss: 3.0018 - val_accuracy: 0.0487\n",
      "Epoch 33/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9847 - accuracy: 0.0631 - val_loss: 3.0065 - val_accuracy: 0.0524\n",
      "Epoch 34/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9838 - accuracy: 0.0633 - val_loss: 3.0054 - val_accuracy: 0.0481\n",
      "Epoch 35/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9822 - accuracy: 0.0647 - val_loss: 3.0092 - val_accuracy: 0.0535\n",
      "Epoch 36/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9807 - accuracy: 0.0672 - val_loss: 3.0076 - val_accuracy: 0.0502\n",
      "Epoch 37/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9790 - accuracy: 0.0656 - val_loss: 3.0099 - val_accuracy: 0.0487\n",
      "Epoch 38/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9773 - accuracy: 0.0689 - val_loss: 3.0087 - val_accuracy: 0.0468\n",
      "Epoch 39/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9758 - accuracy: 0.0680 - val_loss: 3.0095 - val_accuracy: 0.0498\n",
      "Epoch 40/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9731 - accuracy: 0.0703 - val_loss: 3.0193 - val_accuracy: 0.0546\n",
      "Epoch 41/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9705 - accuracy: 0.0708 - val_loss: 3.0204 - val_accuracy: 0.0463\n",
      "Epoch 42/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9695 - accuracy: 0.0721 - val_loss: 3.0177 - val_accuracy: 0.0461\n",
      "Epoch 43/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9666 - accuracy: 0.0759 - val_loss: 3.0168 - val_accuracy: 0.0511\n",
      "Epoch 44/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9641 - accuracy: 0.0748 - val_loss: 3.0258 - val_accuracy: 0.0478\n",
      "Epoch 45/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9619 - accuracy: 0.0740 - val_loss: 3.0266 - val_accuracy: 0.0533\n",
      "Epoch 46/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9581 - accuracy: 0.0814 - val_loss: 3.0254 - val_accuracy: 0.0513\n",
      "Epoch 47/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9567 - accuracy: 0.0788 - val_loss: 3.0273 - val_accuracy: 0.0537\n",
      "Epoch 48/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9534 - accuracy: 0.0798 - val_loss: 3.0338 - val_accuracy: 0.0450\n",
      "Epoch 49/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9502 - accuracy: 0.0827 - val_loss: 3.0357 - val_accuracy: 0.0528\n",
      "Epoch 50/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9474 - accuracy: 0.0826 - val_loss: 3.0408 - val_accuracy: 0.0522\n",
      "Epoch 51/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9446 - accuracy: 0.0840 - val_loss: 3.0341 - val_accuracy: 0.0546\n",
      "Epoch 52/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9411 - accuracy: 0.0868 - val_loss: 3.0426 - val_accuracy: 0.0546\n",
      "Epoch 53/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9395 - accuracy: 0.0854 - val_loss: 3.0466 - val_accuracy: 0.0507\n",
      "Epoch 54/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9353 - accuracy: 0.0862 - val_loss: 3.0535 - val_accuracy: 0.0494\n",
      "Epoch 55/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9306 - accuracy: 0.0867 - val_loss: 3.0508 - val_accuracy: 0.0502\n",
      "Epoch 56/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9289 - accuracy: 0.0898 - val_loss: 3.0433 - val_accuracy: 0.0494\n",
      "Epoch 57/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9252 - accuracy: 0.0904 - val_loss: 3.0620 - val_accuracy: 0.0498\n",
      "Epoch 58/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9210 - accuracy: 0.0911 - val_loss: 3.0613 - val_accuracy: 0.0543\n",
      "Epoch 59/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9176 - accuracy: 0.0952 - val_loss: 3.0654 - val_accuracy: 0.0498\n",
      "Epoch 60/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9159 - accuracy: 0.0916 - val_loss: 3.0646 - val_accuracy: 0.0533\n",
      "Epoch 61/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9124 - accuracy: 0.0959 - val_loss: 3.0677 - val_accuracy: 0.0485\n",
      "Epoch 62/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9096 - accuracy: 0.0951 - val_loss: 3.0656 - val_accuracy: 0.0470\n",
      "Epoch 63/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9053 - accuracy: 0.0991 - val_loss: 3.0706 - val_accuracy: 0.0483\n",
      "Epoch 64/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9016 - accuracy: 0.0998 - val_loss: 3.0802 - val_accuracy: 0.0489\n",
      "Epoch 65/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.8976 - accuracy: 0.0992 - val_loss: 3.0794 - val_accuracy: 0.0528\n",
      "Epoch 66/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.8926 - accuracy: 0.1023 - val_loss: 3.0886 - val_accuracy: 0.0500\n",
      "Epoch 67/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.8897 - accuracy: 0.1033 - val_loss: 3.0928 - val_accuracy: 0.0524\n",
      "Epoch 68/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.8878 - accuracy: 0.1031 - val_loss: 3.0840 - val_accuracy: 0.0498\n",
      "Epoch 69/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.8837 - accuracy: 0.1055 - val_loss: 3.0942 - val_accuracy: 0.0498\n",
      "Epoch 70/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.8822 - accuracy: 0.1058 - val_loss: 3.0887 - val_accuracy: 0.0528\n",
      "Epoch 71/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.8770 - accuracy: 0.1067 - val_loss: 3.0856 - val_accuracy: 0.0496\n",
      "Epoch 72/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.8752 - accuracy: 0.1090 - val_loss: 3.1003 - val_accuracy: 0.0481\n",
      "Epoch 73/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.8706 - accuracy: 0.1099 - val_loss: 3.1100 - val_accuracy: 0.0539\n",
      "Epoch 74/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.8700 - accuracy: 0.1105 - val_loss: 3.1044 - val_accuracy: 0.0535\n",
      "Epoch 75/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.8632 - accuracy: 0.1137 - val_loss: 3.0979 - val_accuracy: 0.0524\n",
      "Epoch 76/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.8601 - accuracy: 0.1132 - val_loss: 3.1182 - val_accuracy: 0.0496\n",
      "Epoch 77/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.8601 - accuracy: 0.1129 - val_loss: 3.1222 - val_accuracy: 0.0515\n",
      "Epoch 78/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.8560 - accuracy: 0.1148 - val_loss: 3.1255 - val_accuracy: 0.0494\n",
      "Epoch 79/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.8495 - accuracy: 0.1174 - val_loss: 3.1460 - val_accuracy: 0.0476\n",
      "Epoch 80/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.8479 - accuracy: 0.1164 - val_loss: 3.1277 - val_accuracy: 0.0528\n",
      "Epoch 81/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.8453 - accuracy: 0.1182 - val_loss: 3.1216 - val_accuracy: 0.0539\n",
      "Epoch 82/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.8439 - accuracy: 0.1195 - val_loss: 3.1410 - val_accuracy: 0.0502\n",
      "Epoch 83/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.8411 - accuracy: 0.1212 - val_loss: 3.1236 - val_accuracy: 0.0543\n",
      "Epoch 84/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.8382 - accuracy: 0.1201 - val_loss: 3.1341 - val_accuracy: 0.0528\n",
      "Epoch 85/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.8332 - accuracy: 0.1237 - val_loss: 3.1280 - val_accuracy: 0.0543\n",
      "Epoch 86/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.8324 - accuracy: 0.1235 - val_loss: 3.1467 - val_accuracy: 0.0526\n",
      "Epoch 87/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.8266 - accuracy: 0.1249 - val_loss: 3.1370 - val_accuracy: 0.0574\n",
      "Epoch 88/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.8270 - accuracy: 0.1234 - val_loss: 3.1436 - val_accuracy: 0.0556\n",
      "Epoch 89/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.8208 - accuracy: 0.1255 - val_loss: 3.1588 - val_accuracy: 0.0502\n",
      "Epoch 90/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.8178 - accuracy: 0.1287 - val_loss: 3.1638 - val_accuracy: 0.0587\n",
      "Epoch 91/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.8150 - accuracy: 0.1283 - val_loss: 3.1697 - val_accuracy: 0.0491\n",
      "Epoch 92/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.8108 - accuracy: 0.1296 - val_loss: 3.1579 - val_accuracy: 0.0502\n",
      "Epoch 93/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.8108 - accuracy: 0.1290 - val_loss: 3.1800 - val_accuracy: 0.0563\n",
      "Epoch 94/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.8074 - accuracy: 0.1301 - val_loss: 3.1790 - val_accuracy: 0.0500\n",
      "Epoch 95/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.8057 - accuracy: 0.1288 - val_loss: 3.1698 - val_accuracy: 0.0504\n",
      "Epoch 96/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.7994 - accuracy: 0.1329 - val_loss: 3.1766 - val_accuracy: 0.0502\n",
      "Epoch 97/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.7987 - accuracy: 0.1342 - val_loss: 3.1707 - val_accuracy: 0.0546\n",
      "Epoch 98/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.7977 - accuracy: 0.1336 - val_loss: 3.1895 - val_accuracy: 0.0563\n",
      "Epoch 99/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.7951 - accuracy: 0.1346 - val_loss: 3.1899 - val_accuracy: 0.0554\n",
      "Epoch 100/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.7909 - accuracy: 0.1363 - val_loss: 3.1730 - val_accuracy: 0.0502\n",
      "Epoch 101/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.7940 - accuracy: 0.1352 - val_loss: 3.1915 - val_accuracy: 0.0502\n",
      "Epoch 102/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.7854 - accuracy: 0.1371 - val_loss: 3.1893 - val_accuracy: 0.0546\n",
      "Epoch 103/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.7857 - accuracy: 0.1385 - val_loss: 3.1921 - val_accuracy: 0.0526\n",
      "Epoch 104/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.7792 - accuracy: 0.1416 - val_loss: 3.2080 - val_accuracy: 0.0511\n",
      "Epoch 105/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.7780 - accuracy: 0.1413 - val_loss: 3.1919 - val_accuracy: 0.0548\n",
      "Epoch 106/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.7761 - accuracy: 0.1407 - val_loss: 3.1973 - val_accuracy: 0.0528\n",
      "Epoch 107/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.7713 - accuracy: 0.1430 - val_loss: 3.2142 - val_accuracy: 0.0509\n",
      "Epoch 108/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.7683 - accuracy: 0.1452 - val_loss: 3.2072 - val_accuracy: 0.0561\n",
      "Epoch 109/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.7678 - accuracy: 0.1444 - val_loss: 3.2135 - val_accuracy: 0.0561\n",
      "Epoch 110/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.7655 - accuracy: 0.1462 - val_loss: 3.2162 - val_accuracy: 0.0552\n",
      "Epoch 111/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.7675 - accuracy: 0.1428 - val_loss: 3.2138 - val_accuracy: 0.0539\n",
      "Epoch 112/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.7572 - accuracy: 0.1462 - val_loss: 3.2411 - val_accuracy: 0.0539\n",
      "Epoch 113/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.7586 - accuracy: 0.1478 - val_loss: 3.2254 - val_accuracy: 0.0522\n",
      "Epoch 114/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.7576 - accuracy: 0.1481 - val_loss: 3.2291 - val_accuracy: 0.0563\n",
      "Epoch 115/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.7547 - accuracy: 0.1497 - val_loss: 3.2283 - val_accuracy: 0.0543\n",
      "Epoch 116/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.7506 - accuracy: 0.1485 - val_loss: 3.2407 - val_accuracy: 0.0496\n",
      "Epoch 117/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.7488 - accuracy: 0.1506 - val_loss: 3.2480 - val_accuracy: 0.0537\n",
      "Epoch 118/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.7537 - accuracy: 0.1487 - val_loss: 3.2237 - val_accuracy: 0.0535\n",
      "Epoch 119/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.7526 - accuracy: 0.1476 - val_loss: 3.2488 - val_accuracy: 0.0526\n",
      "Epoch 120/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.7491 - accuracy: 0.1466 - val_loss: 3.2638 - val_accuracy: 0.0537\n",
      "Epoch 121/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.7485 - accuracy: 0.1485 - val_loss: 3.2236 - val_accuracy: 0.0561\n",
      "Epoch 122/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.7400 - accuracy: 0.1508 - val_loss: 3.2608 - val_accuracy: 0.0537\n",
      "Epoch 123/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.7372 - accuracy: 0.1518 - val_loss: 3.2499 - val_accuracy: 0.0504\n",
      "Epoch 124/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.7384 - accuracy: 0.1522 - val_loss: 3.2567 - val_accuracy: 0.0526\n",
      "Epoch 125/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.7536 - accuracy: 0.1472 - val_loss: 3.2916 - val_accuracy: 0.0559\n",
      "Epoch 126/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.7359 - accuracy: 0.1528 - val_loss: 3.2468 - val_accuracy: 0.0489\n",
      "Epoch 127/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.7310 - accuracy: 0.1543 - val_loss: 3.2770 - val_accuracy: 0.0533\n",
      "Epoch 128/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.7213 - accuracy: 0.1599 - val_loss: 3.2846 - val_accuracy: 0.0533\n",
      "Epoch 129/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.7267 - accuracy: 0.1549 - val_loss: 3.2816 - val_accuracy: 0.0533\n",
      "Epoch 130/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.7248 - accuracy: 0.1555 - val_loss: 3.2824 - val_accuracy: 0.0526\n",
      "Epoch 131/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.7227 - accuracy: 0.1566 - val_loss: 3.2763 - val_accuracy: 0.0524\n",
      "Epoch 132/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.7235 - accuracy: 0.1557 - val_loss: 3.2836 - val_accuracy: 0.0522\n",
      "Epoch 133/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.7181 - accuracy: 0.1567 - val_loss: 3.2869 - val_accuracy: 0.0476\n",
      "Epoch 134/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.7208 - accuracy: 0.1581 - val_loss: 3.2850 - val_accuracy: 0.0511\n",
      "Epoch 135/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.7161 - accuracy: 0.1596 - val_loss: 3.2673 - val_accuracy: 0.0498\n",
      "Epoch 136/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.7111 - accuracy: 0.1599 - val_loss: 3.2681 - val_accuracy: 0.0552\n",
      "Epoch 137/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.7072 - accuracy: 0.1612 - val_loss: 3.2798 - val_accuracy: 0.0535\n",
      "Epoch 138/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.7049 - accuracy: 0.1630 - val_loss: 3.2931 - val_accuracy: 0.0541\n",
      "Epoch 139/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.7081 - accuracy: 0.1618 - val_loss: 3.3021 - val_accuracy: 0.0559\n",
      "Epoch 140/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.7051 - accuracy: 0.1632 - val_loss: 3.3123 - val_accuracy: 0.0507\n",
      "Epoch 141/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.7031 - accuracy: 0.1656 - val_loss: 3.2989 - val_accuracy: 0.0530\n",
      "Epoch 142/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.7029 - accuracy: 0.1654 - val_loss: 3.3158 - val_accuracy: 0.0485\n",
      "Epoch 143/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.7032 - accuracy: 0.1628 - val_loss: 3.2875 - val_accuracy: 0.0507\n",
      "Epoch 144/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.6933 - accuracy: 0.1669 - val_loss: 3.3065 - val_accuracy: 0.0517\n",
      "Epoch 145/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.6917 - accuracy: 0.1657 - val_loss: 3.3214 - val_accuracy: 0.0520\n",
      "Epoch 146/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.6976 - accuracy: 0.1649 - val_loss: 3.3085 - val_accuracy: 0.0522\n",
      "Epoch 147/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.6917 - accuracy: 0.1674 - val_loss: 3.3202 - val_accuracy: 0.0526\n",
      "Epoch 148/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.6923 - accuracy: 0.1686 - val_loss: 3.3407 - val_accuracy: 0.0526\n",
      "Epoch 149/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.6989 - accuracy: 0.1644 - val_loss: 3.2936 - val_accuracy: 0.0543\n",
      "Epoch 150/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.6820 - accuracy: 0.1691 - val_loss: 3.3125 - val_accuracy: 0.0522\n",
      "Epoch 151/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.6829 - accuracy: 0.1690 - val_loss: 3.3274 - val_accuracy: 0.0504\n",
      "Epoch 152/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.6846 - accuracy: 0.1693 - val_loss: 3.3365 - val_accuracy: 0.0511\n",
      "Epoch 153/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.6830 - accuracy: 0.1698 - val_loss: 3.3320 - val_accuracy: 0.0502\n",
      "Epoch 154/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.6837 - accuracy: 0.1686 - val_loss: 3.3414 - val_accuracy: 0.0513\n",
      "Epoch 155/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.6857 - accuracy: 0.1697 - val_loss: 3.3426 - val_accuracy: 0.0500\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([LSTM(64, input_shape=(32, 20)),\n",
    "                  Dense(20, activation='softmax')])\n",
    "train(model=model,\n",
    "      patience_train=5,\n",
    "      patience_val=None,\n",
    "      learning_rate=.001,\n",
    "      epochs=1000,\n",
    "      batch_size=128,\n",
    "      # cont_train=True,\n",
    "      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "r1-n1tF3l03V",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 174595,
     "status": "ok",
     "timestamp": 1688888984606,
     "user": {
      "displayName": "Yoni Krichevsky",
      "userId": "07735752940575548299"
     },
     "user_tz": -180
    },
    "id": "r1-n1tF3l03V",
    "outputId": "7a1043ed-04f3-433c-eecd-c42126215970"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patience_train=5, patience_val=None, learning_rate=0.001, epochs=1000, batch_size=128, cont_train=False, X_train.shape=(33566, 32, 20), y_train.shape=(33566,), X_val.shape=(4619, 32, 20), y_val.shape=(4619,)\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_2 (LSTM)               (None, 128)               76288     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 20)                2580      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 78,868\n",
      "Trainable params: 78,868\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Input shape (None, 32, 20), output shape (None, 20)\n",
      "Epoch 1/1000\n",
      "263/263 [==============================] - 4s 6ms/step - loss: 3.0005 - accuracy: 0.0515 - val_loss: 2.9991 - val_accuracy: 0.0539\n",
      "Epoch 2/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9975 - accuracy: 0.0498 - val_loss: 2.9987 - val_accuracy: 0.0537\n",
      "Epoch 3/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9965 - accuracy: 0.0524 - val_loss: 2.9966 - val_accuracy: 0.0552\n",
      "Epoch 4/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9960 - accuracy: 0.0520 - val_loss: 2.9985 - val_accuracy: 0.0515\n",
      "Epoch 5/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9961 - accuracy: 0.0540 - val_loss: 2.9972 - val_accuracy: 0.0520\n",
      "Epoch 6/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9953 - accuracy: 0.0551 - val_loss: 2.9970 - val_accuracy: 0.0422\n",
      "Epoch 7/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9953 - accuracy: 0.0524 - val_loss: 2.9966 - val_accuracy: 0.0526\n",
      "Epoch 8/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9951 - accuracy: 0.0544 - val_loss: 2.9980 - val_accuracy: 0.0520\n",
      "Epoch 9/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9951 - accuracy: 0.0548 - val_loss: 2.9977 - val_accuracy: 0.0507\n",
      "Epoch 10/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9946 - accuracy: 0.0540 - val_loss: 2.9978 - val_accuracy: 0.0520\n",
      "Epoch 11/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9949 - accuracy: 0.0542 - val_loss: 2.9986 - val_accuracy: 0.0478\n",
      "Epoch 12/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9946 - accuracy: 0.0548 - val_loss: 2.9974 - val_accuracy: 0.0537\n",
      "Epoch 13/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9943 - accuracy: 0.0534 - val_loss: 2.9983 - val_accuracy: 0.0468\n",
      "Epoch 14/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9945 - accuracy: 0.0556 - val_loss: 2.9987 - val_accuracy: 0.0485\n",
      "Epoch 15/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9942 - accuracy: 0.0567 - val_loss: 2.9977 - val_accuracy: 0.0576\n",
      "Epoch 16/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9941 - accuracy: 0.0541 - val_loss: 2.9984 - val_accuracy: 0.0507\n",
      "Epoch 17/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9937 - accuracy: 0.0570 - val_loss: 2.9989 - val_accuracy: 0.0517\n",
      "Epoch 18/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9934 - accuracy: 0.0566 - val_loss: 2.9991 - val_accuracy: 0.0491\n",
      "Epoch 19/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9928 - accuracy: 0.0582 - val_loss: 2.9983 - val_accuracy: 0.0500\n",
      "Epoch 20/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9924 - accuracy: 0.0576 - val_loss: 2.9990 - val_accuracy: 0.0500\n",
      "Epoch 21/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9923 - accuracy: 0.0568 - val_loss: 3.0011 - val_accuracy: 0.0530\n",
      "Epoch 22/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9916 - accuracy: 0.0581 - val_loss: 3.0000 - val_accuracy: 0.0507\n",
      "Epoch 23/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9908 - accuracy: 0.0591 - val_loss: 3.0001 - val_accuracy: 0.0507\n",
      "Epoch 24/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9904 - accuracy: 0.0591 - val_loss: 3.0030 - val_accuracy: 0.0496\n",
      "Epoch 25/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9898 - accuracy: 0.0594 - val_loss: 3.0021 - val_accuracy: 0.0530\n",
      "Epoch 26/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9889 - accuracy: 0.0601 - val_loss: 3.0028 - val_accuracy: 0.0559\n",
      "Epoch 27/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9877 - accuracy: 0.0623 - val_loss: 3.0037 - val_accuracy: 0.0550\n",
      "Epoch 28/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9870 - accuracy: 0.0610 - val_loss: 3.0063 - val_accuracy: 0.0550\n",
      "Epoch 29/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9856 - accuracy: 0.0623 - val_loss: 3.0068 - val_accuracy: 0.0509\n",
      "Epoch 30/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9841 - accuracy: 0.0638 - val_loss: 3.0042 - val_accuracy: 0.0526\n",
      "Epoch 31/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9826 - accuracy: 0.0637 - val_loss: 3.0089 - val_accuracy: 0.0522\n",
      "Epoch 32/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9814 - accuracy: 0.0651 - val_loss: 3.0077 - val_accuracy: 0.0541\n",
      "Epoch 33/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9792 - accuracy: 0.0684 - val_loss: 3.0072 - val_accuracy: 0.0528\n",
      "Epoch 34/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9762 - accuracy: 0.0699 - val_loss: 3.0085 - val_accuracy: 0.0541\n",
      "Epoch 35/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9738 - accuracy: 0.0692 - val_loss: 3.0109 - val_accuracy: 0.0472\n",
      "Epoch 36/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9704 - accuracy: 0.0733 - val_loss: 3.0083 - val_accuracy: 0.0504\n",
      "Epoch 37/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9667 - accuracy: 0.0731 - val_loss: 3.0212 - val_accuracy: 0.0468\n",
      "Epoch 38/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9621 - accuracy: 0.0751 - val_loss: 3.0228 - val_accuracy: 0.0522\n",
      "Epoch 39/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9574 - accuracy: 0.0774 - val_loss: 3.0308 - val_accuracy: 0.0507\n",
      "Epoch 40/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9530 - accuracy: 0.0798 - val_loss: 3.0266 - val_accuracy: 0.0504\n",
      "Epoch 41/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9479 - accuracy: 0.0828 - val_loss: 3.0277 - val_accuracy: 0.0517\n",
      "Epoch 42/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9405 - accuracy: 0.0860 - val_loss: 3.0384 - val_accuracy: 0.0500\n",
      "Epoch 43/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9351 - accuracy: 0.0866 - val_loss: 3.0324 - val_accuracy: 0.0463\n",
      "Epoch 44/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9277 - accuracy: 0.0880 - val_loss: 3.0461 - val_accuracy: 0.0487\n",
      "Epoch 45/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9203 - accuracy: 0.0913 - val_loss: 3.0546 - val_accuracy: 0.0483\n",
      "Epoch 46/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9120 - accuracy: 0.0925 - val_loss: 3.0641 - val_accuracy: 0.0517\n",
      "Epoch 47/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9057 - accuracy: 0.0977 - val_loss: 3.0741 - val_accuracy: 0.0511\n",
      "Epoch 48/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.8964 - accuracy: 0.1008 - val_loss: 3.0738 - val_accuracy: 0.0496\n",
      "Epoch 49/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.8887 - accuracy: 0.1031 - val_loss: 3.0862 - val_accuracy: 0.0468\n",
      "Epoch 50/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.8793 - accuracy: 0.1074 - val_loss: 3.1011 - val_accuracy: 0.0491\n",
      "Epoch 51/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.8709 - accuracy: 0.1090 - val_loss: 3.1130 - val_accuracy: 0.0509\n",
      "Epoch 52/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.8583 - accuracy: 0.1148 - val_loss: 3.1216 - val_accuracy: 0.0474\n",
      "Epoch 53/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.8486 - accuracy: 0.1194 - val_loss: 3.1174 - val_accuracy: 0.0444\n",
      "Epoch 54/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.8395 - accuracy: 0.1228 - val_loss: 3.1307 - val_accuracy: 0.0481\n",
      "Epoch 55/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.8311 - accuracy: 0.1236 - val_loss: 3.1299 - val_accuracy: 0.0496\n",
      "Epoch 56/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.8194 - accuracy: 0.1284 - val_loss: 3.1244 - val_accuracy: 0.0483\n",
      "Epoch 57/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.8096 - accuracy: 0.1294 - val_loss: 3.1473 - val_accuracy: 0.0476\n",
      "Epoch 58/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.8014 - accuracy: 0.1339 - val_loss: 3.1634 - val_accuracy: 0.0496\n",
      "Epoch 59/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.7905 - accuracy: 0.1394 - val_loss: 3.1779 - val_accuracy: 0.0468\n",
      "Epoch 60/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.7803 - accuracy: 0.1397 - val_loss: 3.1811 - val_accuracy: 0.0444\n",
      "Epoch 61/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.7738 - accuracy: 0.1440 - val_loss: 3.1909 - val_accuracy: 0.0487\n",
      "Epoch 62/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.7622 - accuracy: 0.1450 - val_loss: 3.2128 - val_accuracy: 0.0487\n",
      "Epoch 63/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.7510 - accuracy: 0.1511 - val_loss: 3.1922 - val_accuracy: 0.0437\n",
      "Epoch 64/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.7397 - accuracy: 0.1547 - val_loss: 3.2288 - val_accuracy: 0.0455\n",
      "Epoch 65/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.7309 - accuracy: 0.1578 - val_loss: 3.2040 - val_accuracy: 0.0472\n",
      "Epoch 66/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.7174 - accuracy: 0.1626 - val_loss: 3.2368 - val_accuracy: 0.0463\n",
      "Epoch 67/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.7114 - accuracy: 0.1619 - val_loss: 3.2502 - val_accuracy: 0.0470\n",
      "Epoch 68/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.7019 - accuracy: 0.1661 - val_loss: 3.2986 - val_accuracy: 0.0424\n",
      "Epoch 69/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.6903 - accuracy: 0.1702 - val_loss: 3.2861 - val_accuracy: 0.0502\n",
      "Epoch 70/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.6808 - accuracy: 0.1723 - val_loss: 3.2774 - val_accuracy: 0.0476\n",
      "Epoch 71/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.6694 - accuracy: 0.1753 - val_loss: 3.3140 - val_accuracy: 0.0463\n",
      "Epoch 72/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.6618 - accuracy: 0.1783 - val_loss: 3.2986 - val_accuracy: 0.0463\n",
      "Epoch 73/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.6494 - accuracy: 0.1824 - val_loss: 3.3296 - val_accuracy: 0.0478\n",
      "Epoch 74/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.6429 - accuracy: 0.1839 - val_loss: 3.3207 - val_accuracy: 0.0429\n",
      "Epoch 75/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.6308 - accuracy: 0.1880 - val_loss: 3.3576 - val_accuracy: 0.0442\n",
      "Epoch 76/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.6270 - accuracy: 0.1906 - val_loss: 3.3549 - val_accuracy: 0.0478\n",
      "Epoch 77/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.6106 - accuracy: 0.1949 - val_loss: 3.3878 - val_accuracy: 0.0481\n",
      "Epoch 78/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.6045 - accuracy: 0.1973 - val_loss: 3.3803 - val_accuracy: 0.0455\n",
      "Epoch 79/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.5921 - accuracy: 0.2024 - val_loss: 3.3907 - val_accuracy: 0.0489\n",
      "Epoch 80/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.5834 - accuracy: 0.2046 - val_loss: 3.4090 - val_accuracy: 0.0455\n",
      "Epoch 81/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.5697 - accuracy: 0.2088 - val_loss: 3.4161 - val_accuracy: 0.0474\n",
      "Epoch 82/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.5725 - accuracy: 0.2083 - val_loss: 3.4728 - val_accuracy: 0.0452\n",
      "Epoch 83/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.5625 - accuracy: 0.2105 - val_loss: 3.4242 - val_accuracy: 0.0502\n",
      "Epoch 84/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.5469 - accuracy: 0.2142 - val_loss: 3.4179 - val_accuracy: 0.0483\n",
      "Epoch 85/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.5390 - accuracy: 0.2186 - val_loss: 3.4489 - val_accuracy: 0.0485\n",
      "Epoch 86/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.5300 - accuracy: 0.2221 - val_loss: 3.4397 - val_accuracy: 0.0489\n",
      "Epoch 87/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.5239 - accuracy: 0.2253 - val_loss: 3.5091 - val_accuracy: 0.0496\n",
      "Epoch 88/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.5300 - accuracy: 0.2216 - val_loss: 3.4914 - val_accuracy: 0.0483\n",
      "Epoch 89/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.5169 - accuracy: 0.2257 - val_loss: 3.4971 - val_accuracy: 0.0472\n",
      "Epoch 90/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.5019 - accuracy: 0.2314 - val_loss: 3.5295 - val_accuracy: 0.0470\n",
      "Epoch 91/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.4853 - accuracy: 0.2361 - val_loss: 3.5398 - val_accuracy: 0.0468\n",
      "Epoch 92/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.4814 - accuracy: 0.2351 - val_loss: 3.5073 - val_accuracy: 0.0457\n",
      "Epoch 93/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.4718 - accuracy: 0.2377 - val_loss: 3.5824 - val_accuracy: 0.0426\n",
      "Epoch 94/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.4594 - accuracy: 0.2449 - val_loss: 3.5657 - val_accuracy: 0.0498\n",
      "Epoch 95/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.4583 - accuracy: 0.2437 - val_loss: 3.5500 - val_accuracy: 0.0483\n",
      "Epoch 96/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.4556 - accuracy: 0.2460 - val_loss: 3.5696 - val_accuracy: 0.0457\n",
      "Epoch 97/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.4472 - accuracy: 0.2495 - val_loss: 3.5716 - val_accuracy: 0.0478\n",
      "Epoch 98/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.4392 - accuracy: 0.2498 - val_loss: 3.5988 - val_accuracy: 0.0489\n",
      "Epoch 99/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.4375 - accuracy: 0.2500 - val_loss: 3.6374 - val_accuracy: 0.0487\n",
      "Epoch 100/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.4436 - accuracy: 0.2478 - val_loss: 3.5981 - val_accuracy: 0.0500\n",
      "Epoch 101/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.4465 - accuracy: 0.2508 - val_loss: 3.6206 - val_accuracy: 0.0444\n",
      "Epoch 102/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.4115 - accuracy: 0.2590 - val_loss: 3.6690 - val_accuracy: 0.0509\n",
      "Epoch 103/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.3916 - accuracy: 0.2667 - val_loss: 3.6803 - val_accuracy: 0.0476\n",
      "Epoch 104/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.3964 - accuracy: 0.2649 - val_loss: 3.6763 - val_accuracy: 0.0515\n",
      "Epoch 105/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.3901 - accuracy: 0.2648 - val_loss: 3.6737 - val_accuracy: 0.0487\n",
      "Epoch 106/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.4009 - accuracy: 0.2632 - val_loss: 3.7224 - val_accuracy: 0.0487\n",
      "Epoch 107/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.3774 - accuracy: 0.2706 - val_loss: 3.7411 - val_accuracy: 0.0476\n",
      "Epoch 108/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.3640 - accuracy: 0.2744 - val_loss: 3.7183 - val_accuracy: 0.0496\n",
      "Epoch 109/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.3600 - accuracy: 0.2748 - val_loss: 3.7603 - val_accuracy: 0.0507\n",
      "Epoch 110/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.3560 - accuracy: 0.2755 - val_loss: 3.7687 - val_accuracy: 0.0511\n",
      "Epoch 111/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.3544 - accuracy: 0.2770 - val_loss: 3.7604 - val_accuracy: 0.0515\n",
      "Epoch 112/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.3659 - accuracy: 0.2725 - val_loss: 3.7595 - val_accuracy: 0.0491\n",
      "Epoch 113/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.3310 - accuracy: 0.2856 - val_loss: 3.7934 - val_accuracy: 0.0487\n",
      "Epoch 114/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.3410 - accuracy: 0.2816 - val_loss: 3.8048 - val_accuracy: 0.0465\n",
      "Epoch 115/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.3129 - accuracy: 0.2920 - val_loss: 3.8466 - val_accuracy: 0.0498\n",
      "Epoch 116/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.3141 - accuracy: 0.2896 - val_loss: 3.8525 - val_accuracy: 0.0478\n",
      "Epoch 117/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.3213 - accuracy: 0.2879 - val_loss: 3.7995 - val_accuracy: 0.0502\n",
      "Epoch 118/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.3022 - accuracy: 0.2923 - val_loss: 3.8000 - val_accuracy: 0.0472\n",
      "Epoch 119/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.3067 - accuracy: 0.2926 - val_loss: 3.8443 - val_accuracy: 0.0476\n",
      "Epoch 120/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.2994 - accuracy: 0.2924 - val_loss: 3.8342 - val_accuracy: 0.0537\n",
      "Epoch 121/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.2907 - accuracy: 0.2969 - val_loss: 3.8626 - val_accuracy: 0.0474\n",
      "Epoch 122/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.2902 - accuracy: 0.2963 - val_loss: 3.9052 - val_accuracy: 0.0504\n",
      "Epoch 123/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.3007 - accuracy: 0.2923 - val_loss: 3.8504 - val_accuracy: 0.0509\n",
      "Epoch 124/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.2758 - accuracy: 0.3016 - val_loss: 3.8884 - val_accuracy: 0.0457\n",
      "Epoch 125/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.2744 - accuracy: 0.3042 - val_loss: 3.8946 - val_accuracy: 0.0507\n",
      "Epoch 126/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.2653 - accuracy: 0.3061 - val_loss: 3.8605 - val_accuracy: 0.0513\n",
      "Epoch 127/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.2512 - accuracy: 0.3096 - val_loss: 3.9073 - val_accuracy: 0.0498\n",
      "Epoch 128/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.2379 - accuracy: 0.3145 - val_loss: 3.9268 - val_accuracy: 0.0528\n",
      "Epoch 129/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.2351 - accuracy: 0.3159 - val_loss: 3.9454 - val_accuracy: 0.0491\n",
      "Epoch 130/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.2509 - accuracy: 0.3100 - val_loss: 3.9681 - val_accuracy: 0.0465\n",
      "Epoch 131/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.2370 - accuracy: 0.3138 - val_loss: 4.0249 - val_accuracy: 0.0522\n",
      "Epoch 132/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.2314 - accuracy: 0.3143 - val_loss: 3.9897 - val_accuracy: 0.0481\n",
      "Epoch 133/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.2145 - accuracy: 0.3218 - val_loss: 3.9603 - val_accuracy: 0.0528\n",
      "Epoch 134/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.2153 - accuracy: 0.3202 - val_loss: 3.9699 - val_accuracy: 0.0494\n",
      "Epoch 135/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.2380 - accuracy: 0.3135 - val_loss: 4.0186 - val_accuracy: 0.0509\n",
      "Epoch 136/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.2093 - accuracy: 0.3229 - val_loss: 4.0124 - val_accuracy: 0.0496\n",
      "Epoch 137/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.2164 - accuracy: 0.3188 - val_loss: 3.9865 - val_accuracy: 0.0511\n",
      "Epoch 138/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.2013 - accuracy: 0.3238 - val_loss: 4.0351 - val_accuracy: 0.0478\n",
      "Epoch 139/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.2299 - accuracy: 0.3163 - val_loss: 4.0404 - val_accuracy: 0.0511\n",
      "Epoch 140/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.1859 - accuracy: 0.3291 - val_loss: 4.0814 - val_accuracy: 0.0530\n",
      "Epoch 141/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.1755 - accuracy: 0.3342 - val_loss: 4.0417 - val_accuracy: 0.0491\n",
      "Epoch 142/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.1795 - accuracy: 0.3328 - val_loss: 4.1519 - val_accuracy: 0.0502\n",
      "Epoch 143/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.1578 - accuracy: 0.3408 - val_loss: 4.0306 - val_accuracy: 0.0533\n",
      "Epoch 144/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.1775 - accuracy: 0.3333 - val_loss: 4.0774 - val_accuracy: 0.0498\n",
      "Epoch 145/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.1735 - accuracy: 0.3327 - val_loss: 4.1412 - val_accuracy: 0.0487\n",
      "Epoch 146/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.1961 - accuracy: 0.3256 - val_loss: 4.0789 - val_accuracy: 0.0496\n",
      "Epoch 147/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.1664 - accuracy: 0.3340 - val_loss: 4.1294 - val_accuracy: 0.0468\n",
      "Epoch 148/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.1593 - accuracy: 0.3368 - val_loss: 4.1370 - val_accuracy: 0.0496\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([LSTM(128, input_shape=(32, 20)),\n",
    "                  Dense(20, activation='softmax')])\n",
    "train(model=model,\n",
    "      patience_train=5,\n",
    "      patience_val=None,\n",
    "      learning_rate=.001,\n",
    "      epochs=1000,\n",
    "      batch_size=128,\n",
    "      # cont_train=True,\n",
    "      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "aBFwNPqsrJ8i",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 232802,
     "status": "ok",
     "timestamp": 1688889999606,
     "user": {
      "displayName": "Yoni Krichevsky",
      "userId": "07735752940575548299"
     },
     "user_tz": -180
    },
    "id": "aBFwNPqsrJ8i",
    "outputId": "777f9960-125d-4ac3-cede-5ee022bf87ae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patience_train=5, patience_val=None, learning_rate=0.001, epochs=1000, batch_size=128, cont_train=False, X_train.shape=(33566, 32, 20), y_train.shape=(33566,), X_val.shape=(4619, 32, 20), y_val.shape=(4619,)\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_5 (LSTM)               (None, 256)               283648    \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 20)                5140      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 288,788\n",
      "Trainable params: 288,788\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Input shape (None, 32, 20), output shape (None, 20)\n",
      "Epoch 1/1000\n",
      "263/263 [==============================] - 3s 6ms/step - loss: 3.0016 - accuracy: 0.0501 - val_loss: 2.9988 - val_accuracy: 0.0511\n",
      "Epoch 2/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9974 - accuracy: 0.0504 - val_loss: 2.9981 - val_accuracy: 0.0498\n",
      "Epoch 3/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9965 - accuracy: 0.0512 - val_loss: 2.9971 - val_accuracy: 0.0455\n",
      "Epoch 4/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9960 - accuracy: 0.0529 - val_loss: 2.9973 - val_accuracy: 0.0504\n",
      "Epoch 5/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9957 - accuracy: 0.0528 - val_loss: 2.9967 - val_accuracy: 0.0520\n",
      "Epoch 6/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9953 - accuracy: 0.0544 - val_loss: 2.9970 - val_accuracy: 0.0504\n",
      "Epoch 7/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9949 - accuracy: 0.0528 - val_loss: 2.9966 - val_accuracy: 0.0491\n",
      "Epoch 8/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9951 - accuracy: 0.0537 - val_loss: 2.9968 - val_accuracy: 0.0500\n",
      "Epoch 9/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9949 - accuracy: 0.0561 - val_loss: 2.9972 - val_accuracy: 0.0498\n",
      "Epoch 10/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9948 - accuracy: 0.0557 - val_loss: 2.9975 - val_accuracy: 0.0517\n",
      "Epoch 11/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9946 - accuracy: 0.0551 - val_loss: 2.9987 - val_accuracy: 0.0468\n",
      "Epoch 12/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9945 - accuracy: 0.0543 - val_loss: 2.9975 - val_accuracy: 0.0496\n",
      "Epoch 13/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9943 - accuracy: 0.0576 - val_loss: 2.9977 - val_accuracy: 0.0522\n",
      "Epoch 14/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9943 - accuracy: 0.0553 - val_loss: 2.9974 - val_accuracy: 0.0485\n",
      "Epoch 15/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9941 - accuracy: 0.0558 - val_loss: 2.9977 - val_accuracy: 0.0541\n",
      "Epoch 16/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9936 - accuracy: 0.0549 - val_loss: 2.9976 - val_accuracy: 0.0450\n",
      "Epoch 17/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9936 - accuracy: 0.0560 - val_loss: 2.9981 - val_accuracy: 0.0485\n",
      "Epoch 18/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9927 - accuracy: 0.0565 - val_loss: 2.9985 - val_accuracy: 0.0574\n",
      "Epoch 19/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9923 - accuracy: 0.0582 - val_loss: 2.9989 - val_accuracy: 0.0455\n",
      "Epoch 20/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9919 - accuracy: 0.0571 - val_loss: 3.0014 - val_accuracy: 0.0491\n",
      "Epoch 21/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9918 - accuracy: 0.0581 - val_loss: 3.0001 - val_accuracy: 0.0524\n",
      "Epoch 22/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9905 - accuracy: 0.0604 - val_loss: 2.9985 - val_accuracy: 0.0491\n",
      "Epoch 23/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9906 - accuracy: 0.0583 - val_loss: 3.0029 - val_accuracy: 0.0522\n",
      "Epoch 24/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9894 - accuracy: 0.0608 - val_loss: 3.0005 - val_accuracy: 0.0498\n",
      "Epoch 25/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9885 - accuracy: 0.0622 - val_loss: 3.0016 - val_accuracy: 0.0487\n",
      "Epoch 26/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9876 - accuracy: 0.0617 - val_loss: 3.0047 - val_accuracy: 0.0474\n",
      "Epoch 27/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9863 - accuracy: 0.0639 - val_loss: 3.0076 - val_accuracy: 0.0509\n",
      "Epoch 28/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9850 - accuracy: 0.0640 - val_loss: 3.0057 - val_accuracy: 0.0472\n",
      "Epoch 29/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9832 - accuracy: 0.0641 - val_loss: 3.0059 - val_accuracy: 0.0500\n",
      "Epoch 30/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9815 - accuracy: 0.0662 - val_loss: 3.0090 - val_accuracy: 0.0526\n",
      "Epoch 31/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9782 - accuracy: 0.0681 - val_loss: 3.0125 - val_accuracy: 0.0526\n",
      "Epoch 32/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9752 - accuracy: 0.0703 - val_loss: 3.0145 - val_accuracy: 0.0496\n",
      "Epoch 33/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9729 - accuracy: 0.0697 - val_loss: 3.0164 - val_accuracy: 0.0491\n",
      "Epoch 34/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9698 - accuracy: 0.0737 - val_loss: 3.0119 - val_accuracy: 0.0476\n",
      "Epoch 35/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9656 - accuracy: 0.0737 - val_loss: 3.0197 - val_accuracy: 0.0504\n",
      "Epoch 36/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9595 - accuracy: 0.0787 - val_loss: 3.0277 - val_accuracy: 0.0485\n",
      "Epoch 37/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9544 - accuracy: 0.0795 - val_loss: 3.0305 - val_accuracy: 0.0487\n",
      "Epoch 38/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9471 - accuracy: 0.0837 - val_loss: 3.0266 - val_accuracy: 0.0483\n",
      "Epoch 39/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9397 - accuracy: 0.0857 - val_loss: 3.0403 - val_accuracy: 0.0513\n",
      "Epoch 40/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9310 - accuracy: 0.0897 - val_loss: 3.0438 - val_accuracy: 0.0489\n",
      "Epoch 41/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9208 - accuracy: 0.0939 - val_loss: 3.0523 - val_accuracy: 0.0491\n",
      "Epoch 42/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.9103 - accuracy: 0.0964 - val_loss: 3.0681 - val_accuracy: 0.0500\n",
      "Epoch 43/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.8964 - accuracy: 0.1013 - val_loss: 3.0812 - val_accuracy: 0.0483\n",
      "Epoch 44/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.8845 - accuracy: 0.1039 - val_loss: 3.0796 - val_accuracy: 0.0500\n",
      "Epoch 45/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.8696 - accuracy: 0.1093 - val_loss: 3.0969 - val_accuracy: 0.0502\n",
      "Epoch 46/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.8531 - accuracy: 0.1157 - val_loss: 3.0881 - val_accuracy: 0.0546\n",
      "Epoch 47/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.8348 - accuracy: 0.1200 - val_loss: 3.1335 - val_accuracy: 0.0528\n",
      "Epoch 48/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.8160 - accuracy: 0.1272 - val_loss: 3.1369 - val_accuracy: 0.0550\n",
      "Epoch 49/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.8000 - accuracy: 0.1329 - val_loss: 3.1457 - val_accuracy: 0.0507\n",
      "Epoch 50/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.7773 - accuracy: 0.1408 - val_loss: 3.1573 - val_accuracy: 0.0485\n",
      "Epoch 51/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.7533 - accuracy: 0.1482 - val_loss: 3.1712 - val_accuracy: 0.0498\n",
      "Epoch 52/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.7342 - accuracy: 0.1541 - val_loss: 3.2015 - val_accuracy: 0.0487\n",
      "Epoch 53/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.7036 - accuracy: 0.1623 - val_loss: 3.2329 - val_accuracy: 0.0530\n",
      "Epoch 54/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.6898 - accuracy: 0.1672 - val_loss: 3.2162 - val_accuracy: 0.0520\n",
      "Epoch 55/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.6601 - accuracy: 0.1805 - val_loss: 3.2712 - val_accuracy: 0.0476\n",
      "Epoch 56/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.6337 - accuracy: 0.1880 - val_loss: 3.2677 - val_accuracy: 0.0504\n",
      "Epoch 57/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.6029 - accuracy: 0.1986 - val_loss: 3.3200 - val_accuracy: 0.0515\n",
      "Epoch 58/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.5811 - accuracy: 0.2063 - val_loss: 3.3628 - val_accuracy: 0.0507\n",
      "Epoch 59/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.5507 - accuracy: 0.2148 - val_loss: 3.3464 - val_accuracy: 0.0520\n",
      "Epoch 60/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.5277 - accuracy: 0.2224 - val_loss: 3.4065 - val_accuracy: 0.0474\n",
      "Epoch 61/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.5004 - accuracy: 0.2315 - val_loss: 3.4163 - val_accuracy: 0.0498\n",
      "Epoch 62/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.4765 - accuracy: 0.2395 - val_loss: 3.4572 - val_accuracy: 0.0543\n",
      "Epoch 63/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.4532 - accuracy: 0.2457 - val_loss: 3.4856 - val_accuracy: 0.0500\n",
      "Epoch 64/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.4152 - accuracy: 0.2584 - val_loss: 3.5187 - val_accuracy: 0.0465\n",
      "Epoch 65/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.3992 - accuracy: 0.2651 - val_loss: 3.5006 - val_accuracy: 0.0520\n",
      "Epoch 66/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.3654 - accuracy: 0.2730 - val_loss: 3.5595 - val_accuracy: 0.0465\n",
      "Epoch 67/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.3471 - accuracy: 0.2808 - val_loss: 3.5873 - val_accuracy: 0.0526\n",
      "Epoch 68/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.3276 - accuracy: 0.2862 - val_loss: 3.6610 - val_accuracy: 0.0491\n",
      "Epoch 69/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.2912 - accuracy: 0.2978 - val_loss: 3.6576 - val_accuracy: 0.0515\n",
      "Epoch 70/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.2626 - accuracy: 0.3081 - val_loss: 3.6380 - val_accuracy: 0.0500\n",
      "Epoch 71/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.2388 - accuracy: 0.3142 - val_loss: 3.7441 - val_accuracy: 0.0537\n",
      "Epoch 72/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.2176 - accuracy: 0.3201 - val_loss: 3.7719 - val_accuracy: 0.0507\n",
      "Epoch 73/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.1911 - accuracy: 0.3299 - val_loss: 3.7872 - val_accuracy: 0.0522\n",
      "Epoch 74/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.1738 - accuracy: 0.3364 - val_loss: 3.8964 - val_accuracy: 0.0498\n",
      "Epoch 75/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.1665 - accuracy: 0.3376 - val_loss: 3.8280 - val_accuracy: 0.0496\n",
      "Epoch 76/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.1211 - accuracy: 0.3511 - val_loss: 3.9408 - val_accuracy: 0.0487\n",
      "Epoch 77/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.0982 - accuracy: 0.3587 - val_loss: 3.9703 - val_accuracy: 0.0504\n",
      "Epoch 78/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.0786 - accuracy: 0.3670 - val_loss: 3.9885 - val_accuracy: 0.0491\n",
      "Epoch 79/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.0513 - accuracy: 0.3751 - val_loss: 3.9991 - val_accuracy: 0.0489\n",
      "Epoch 80/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.0414 - accuracy: 0.3762 - val_loss: 4.0228 - val_accuracy: 0.0502\n",
      "Epoch 81/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 2.0074 - accuracy: 0.3883 - val_loss: 4.1114 - val_accuracy: 0.0494\n",
      "Epoch 82/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 1.9838 - accuracy: 0.3946 - val_loss: 4.1010 - val_accuracy: 0.0468\n",
      "Epoch 83/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 1.9678 - accuracy: 0.3988 - val_loss: 4.0928 - val_accuracy: 0.0520\n",
      "Epoch 84/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 1.9569 - accuracy: 0.4039 - val_loss: 4.2094 - val_accuracy: 0.0498\n",
      "Epoch 85/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 1.9344 - accuracy: 0.4119 - val_loss: 4.2556 - val_accuracy: 0.0504\n",
      "Epoch 86/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 1.9199 - accuracy: 0.4153 - val_loss: 4.2431 - val_accuracy: 0.0472\n",
      "Epoch 87/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 1.8991 - accuracy: 0.4227 - val_loss: 4.2769 - val_accuracy: 0.0496\n",
      "Epoch 88/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 1.8668 - accuracy: 0.4319 - val_loss: 4.4222 - val_accuracy: 0.0496\n",
      "Epoch 89/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 1.8658 - accuracy: 0.4337 - val_loss: 4.2405 - val_accuracy: 0.0517\n",
      "Epoch 90/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 1.8634 - accuracy: 0.4354 - val_loss: 4.4102 - val_accuracy: 0.0498\n",
      "Epoch 91/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 1.9695 - accuracy: 0.4012 - val_loss: 4.3511 - val_accuracy: 0.0517\n",
      "Epoch 92/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 1.8142 - accuracy: 0.4489 - val_loss: 4.3632 - val_accuracy: 0.0487\n",
      "Epoch 93/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 1.7724 - accuracy: 0.4641 - val_loss: 4.3705 - val_accuracy: 0.0526\n",
      "Epoch 94/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 1.7736 - accuracy: 0.4622 - val_loss: 4.4158 - val_accuracy: 0.0515\n",
      "Epoch 95/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 1.7401 - accuracy: 0.4718 - val_loss: 4.4531 - val_accuracy: 0.0513\n",
      "Epoch 96/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 1.7243 - accuracy: 0.4765 - val_loss: 4.5355 - val_accuracy: 0.0517\n",
      "Epoch 97/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 1.7304 - accuracy: 0.4745 - val_loss: 4.4650 - val_accuracy: 0.0533\n",
      "Epoch 98/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 1.7438 - accuracy: 0.4700 - val_loss: 4.6058 - val_accuracy: 0.0485\n",
      "Epoch 99/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 1.7004 - accuracy: 0.4858 - val_loss: 4.5758 - val_accuracy: 0.0481\n",
      "Epoch 100/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 1.6704 - accuracy: 0.4973 - val_loss: 4.6819 - val_accuracy: 0.0504\n",
      "Epoch 101/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 1.6542 - accuracy: 0.5004 - val_loss: 4.6334 - val_accuracy: 0.0494\n",
      "Epoch 102/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 1.6587 - accuracy: 0.4969 - val_loss: 4.7814 - val_accuracy: 0.0489\n",
      "Epoch 103/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 1.6257 - accuracy: 0.5088 - val_loss: 4.7393 - val_accuracy: 0.0513\n",
      "Epoch 104/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 1.5831 - accuracy: 0.5234 - val_loss: 4.8330 - val_accuracy: 0.0485\n",
      "Epoch 105/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 1.6042 - accuracy: 0.5156 - val_loss: 4.8023 - val_accuracy: 0.0520\n",
      "Epoch 106/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 1.5932 - accuracy: 0.5171 - val_loss: 4.7903 - val_accuracy: 0.0463\n",
      "Epoch 107/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 1.5916 - accuracy: 0.5186 - val_loss: 4.9668 - val_accuracy: 0.0500\n",
      "Epoch 108/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 1.5599 - accuracy: 0.5299 - val_loss: 4.9344 - val_accuracy: 0.0487\n",
      "Epoch 109/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 1.5849 - accuracy: 0.5220 - val_loss: 4.9124 - val_accuracy: 0.0472\n",
      "Epoch 110/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 1.5524 - accuracy: 0.5331 - val_loss: 4.8728 - val_accuracy: 0.0485\n",
      "Epoch 111/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 1.5210 - accuracy: 0.5430 - val_loss: 4.9762 - val_accuracy: 0.0455\n",
      "Epoch 112/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 1.4784 - accuracy: 0.5580 - val_loss: 5.0307 - val_accuracy: 0.0450\n",
      "Epoch 113/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 1.5037 - accuracy: 0.5464 - val_loss: 5.0319 - val_accuracy: 0.0478\n",
      "Epoch 114/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 1.4801 - accuracy: 0.5547 - val_loss: 5.0604 - val_accuracy: 0.0442\n",
      "Epoch 115/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 1.4681 - accuracy: 0.5594 - val_loss: 5.1878 - val_accuracy: 0.0474\n",
      "Epoch 116/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 1.4284 - accuracy: 0.5725 - val_loss: 5.1298 - val_accuracy: 0.0517\n",
      "Epoch 117/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 1.4674 - accuracy: 0.5592 - val_loss: 5.1134 - val_accuracy: 0.0468\n",
      "Epoch 118/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 1.4451 - accuracy: 0.5661 - val_loss: 5.1282 - val_accuracy: 0.0483\n",
      "Epoch 119/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 1.4345 - accuracy: 0.5679 - val_loss: 5.2724 - val_accuracy: 0.0476\n",
      "Epoch 120/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 1.4532 - accuracy: 0.5615 - val_loss: 5.2831 - val_accuracy: 0.0494\n",
      "Epoch 121/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 1.4125 - accuracy: 0.5781 - val_loss: 5.2768 - val_accuracy: 0.0472\n",
      "Epoch 122/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 1.4036 - accuracy: 0.5808 - val_loss: 5.1907 - val_accuracy: 0.0489\n",
      "Epoch 123/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 1.4152 - accuracy: 0.5770 - val_loss: 5.2569 - val_accuracy: 0.0485\n",
      "Epoch 124/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 1.4128 - accuracy: 0.5764 - val_loss: 5.3539 - val_accuracy: 0.0483\n",
      "Epoch 125/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 1.3987 - accuracy: 0.5789 - val_loss: 5.2920 - val_accuracy: 0.0483\n",
      "Epoch 126/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 1.3570 - accuracy: 0.5922 - val_loss: 5.3836 - val_accuracy: 0.0472\n",
      "Epoch 127/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 1.2899 - accuracy: 0.6150 - val_loss: 5.4995 - val_accuracy: 0.0463\n",
      "Epoch 128/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 1.3111 - accuracy: 0.6072 - val_loss: 5.5105 - val_accuracy: 0.0444\n",
      "Epoch 129/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 1.3222 - accuracy: 0.6036 - val_loss: 5.5551 - val_accuracy: 0.0457\n",
      "Epoch 130/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 1.3193 - accuracy: 0.6047 - val_loss: 5.5376 - val_accuracy: 0.0494\n",
      "Epoch 131/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 1.3054 - accuracy: 0.6082 - val_loss: 5.7290 - val_accuracy: 0.0496\n",
      "Epoch 132/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 1.2601 - accuracy: 0.6238 - val_loss: 5.6482 - val_accuracy: 0.0450\n",
      "Epoch 133/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 1.2576 - accuracy: 0.6265 - val_loss: 5.7451 - val_accuracy: 0.0485\n",
      "Epoch 134/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 1.2686 - accuracy: 0.6213 - val_loss: 5.7336 - val_accuracy: 0.0498\n",
      "Epoch 135/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 1.2426 - accuracy: 0.6300 - val_loss: 5.7400 - val_accuracy: 0.0450\n",
      "Epoch 136/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 1.2712 - accuracy: 0.6202 - val_loss: 5.7650 - val_accuracy: 0.0474\n",
      "Epoch 137/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 1.2356 - accuracy: 0.6314 - val_loss: 5.7173 - val_accuracy: 0.0468\n",
      "Epoch 138/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 1.2096 - accuracy: 0.6401 - val_loss: 5.8057 - val_accuracy: 0.0517\n",
      "Epoch 139/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 1.2511 - accuracy: 0.6263 - val_loss: 5.8641 - val_accuracy: 0.0457\n",
      "Epoch 140/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 1.2326 - accuracy: 0.6309 - val_loss: 5.8669 - val_accuracy: 0.0483\n",
      "Epoch 141/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 1.1897 - accuracy: 0.6445 - val_loss: 5.9884 - val_accuracy: 0.0485\n",
      "Epoch 142/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 1.2075 - accuracy: 0.6392 - val_loss: 5.8886 - val_accuracy: 0.0494\n",
      "Epoch 143/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 1.2282 - accuracy: 0.6303 - val_loss: 5.7658 - val_accuracy: 0.0530\n",
      "Epoch 144/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 1.2012 - accuracy: 0.6396 - val_loss: 5.9104 - val_accuracy: 0.0442\n",
      "Epoch 145/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 1.1744 - accuracy: 0.6482 - val_loss: 5.9821 - val_accuracy: 0.0485\n",
      "Epoch 146/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 1.1497 - accuracy: 0.6574 - val_loss: 6.0350 - val_accuracy: 0.0507\n",
      "Epoch 147/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 1.1419 - accuracy: 0.6601 - val_loss: 5.9603 - val_accuracy: 0.0420\n",
      "Epoch 148/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 1.2034 - accuracy: 0.6384 - val_loss: 5.9039 - val_accuracy: 0.0489\n",
      "Epoch 149/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 1.1993 - accuracy: 0.6392 - val_loss: 6.0035 - val_accuracy: 0.0450\n",
      "Epoch 150/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 1.1772 - accuracy: 0.6490 - val_loss: 6.0332 - val_accuracy: 0.0470\n",
      "Epoch 151/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 1.1355 - accuracy: 0.6610 - val_loss: 6.1242 - val_accuracy: 0.0446\n",
      "Epoch 152/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 1.0971 - accuracy: 0.6740 - val_loss: 6.1794 - val_accuracy: 0.0472\n",
      "Epoch 153/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 1.0880 - accuracy: 0.6770 - val_loss: 6.2250 - val_accuracy: 0.0422\n",
      "Epoch 154/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 1.0734 - accuracy: 0.6813 - val_loss: 6.0955 - val_accuracy: 0.0463\n",
      "Epoch 155/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 1.1150 - accuracy: 0.6667 - val_loss: 6.1083 - val_accuracy: 0.0461\n",
      "Epoch 156/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 1.0783 - accuracy: 0.6805 - val_loss: 6.2404 - val_accuracy: 0.0442\n",
      "Epoch 157/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 1.0927 - accuracy: 0.6759 - val_loss: 6.3311 - val_accuracy: 0.0498\n",
      "Epoch 158/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 1.1118 - accuracy: 0.6662 - val_loss: 6.3034 - val_accuracy: 0.0487\n",
      "Epoch 159/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 1.0602 - accuracy: 0.6847 - val_loss: 6.3279 - val_accuracy: 0.0507\n",
      "Epoch 160/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 1.0622 - accuracy: 0.6875 - val_loss: 6.1825 - val_accuracy: 0.0520\n",
      "Epoch 161/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 1.0878 - accuracy: 0.6740 - val_loss: 6.3549 - val_accuracy: 0.0524\n",
      "Epoch 162/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 1.0063 - accuracy: 0.7038 - val_loss: 6.4384 - val_accuracy: 0.0468\n",
      "Epoch 163/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 1.0308 - accuracy: 0.6948 - val_loss: 6.3375 - val_accuracy: 0.0463\n",
      "Epoch 164/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 1.0205 - accuracy: 0.6976 - val_loss: 6.5180 - val_accuracy: 0.0465\n",
      "Epoch 165/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 1.0398 - accuracy: 0.6894 - val_loss: 6.5988 - val_accuracy: 0.0437\n",
      "Epoch 166/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 0.9965 - accuracy: 0.7055 - val_loss: 6.4748 - val_accuracy: 0.0463\n",
      "Epoch 167/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 0.9954 - accuracy: 0.7049 - val_loss: 6.5686 - val_accuracy: 0.0472\n",
      "Epoch 168/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 0.9795 - accuracy: 0.7091 - val_loss: 6.5478 - val_accuracy: 0.0446\n",
      "Epoch 169/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 0.9882 - accuracy: 0.7066 - val_loss: 6.5166 - val_accuracy: 0.0459\n",
      "Epoch 170/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 1.0036 - accuracy: 0.7013 - val_loss: 6.6872 - val_accuracy: 0.0481\n",
      "Epoch 171/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 0.9844 - accuracy: 0.7086 - val_loss: 6.5898 - val_accuracy: 0.0457\n",
      "Epoch 172/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 0.9656 - accuracy: 0.7143 - val_loss: 6.5805 - val_accuracy: 0.0457\n",
      "Epoch 173/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 0.9760 - accuracy: 0.7096 - val_loss: 6.7460 - val_accuracy: 0.0487\n",
      "Epoch 174/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 0.9623 - accuracy: 0.7140 - val_loss: 6.7737 - val_accuracy: 0.0489\n",
      "Epoch 175/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 0.9798 - accuracy: 0.7074 - val_loss: 6.7309 - val_accuracy: 0.0429\n",
      "Epoch 176/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 1.0328 - accuracy: 0.6936 - val_loss: 6.6513 - val_accuracy: 0.0461\n",
      "Epoch 177/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 0.9574 - accuracy: 0.7160 - val_loss: 6.7223 - val_accuracy: 0.0463\n",
      "Epoch 178/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 0.9288 - accuracy: 0.7259 - val_loss: 6.6801 - val_accuracy: 0.0489\n",
      "Epoch 179/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 0.8972 - accuracy: 0.7361 - val_loss: 6.9232 - val_accuracy: 0.0476\n",
      "Epoch 180/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 0.9069 - accuracy: 0.7337 - val_loss: 6.7741 - val_accuracy: 0.0452\n",
      "Epoch 181/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 0.8912 - accuracy: 0.7394 - val_loss: 6.9699 - val_accuracy: 0.0507\n",
      "Epoch 182/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 0.9167 - accuracy: 0.7285 - val_loss: 7.0482 - val_accuracy: 0.0437\n",
      "Epoch 183/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 1.0236 - accuracy: 0.6954 - val_loss: 6.8059 - val_accuracy: 0.0444\n",
      "Epoch 184/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 0.8826 - accuracy: 0.7411 - val_loss: 6.9747 - val_accuracy: 0.0457\n",
      "Epoch 185/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 0.8458 - accuracy: 0.7520 - val_loss: 7.0078 - val_accuracy: 0.0459\n",
      "Epoch 186/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 0.8459 - accuracy: 0.7517 - val_loss: 7.0375 - val_accuracy: 0.0459\n",
      "Epoch 187/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 0.8444 - accuracy: 0.7503 - val_loss: 6.9338 - val_accuracy: 0.0476\n",
      "Epoch 188/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 0.9781 - accuracy: 0.7093 - val_loss: 6.9609 - val_accuracy: 0.0509\n",
      "Epoch 189/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 0.8995 - accuracy: 0.7345 - val_loss: 7.0429 - val_accuracy: 0.0468\n",
      "Epoch 190/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 0.8518 - accuracy: 0.7495 - val_loss: 7.1083 - val_accuracy: 0.0487\n",
      "Epoch 191/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 0.8347 - accuracy: 0.7550 - val_loss: 7.2191 - val_accuracy: 0.0457\n",
      "Epoch 192/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 0.8137 - accuracy: 0.7598 - val_loss: 7.2267 - val_accuracy: 0.0494\n",
      "Epoch 193/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 0.8281 - accuracy: 0.7580 - val_loss: 7.2392 - val_accuracy: 0.0489\n",
      "Epoch 194/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 0.8577 - accuracy: 0.7468 - val_loss: 7.2697 - val_accuracy: 0.0478\n",
      "Epoch 195/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 0.8853 - accuracy: 0.7379 - val_loss: 7.2422 - val_accuracy: 0.0468\n",
      "Epoch 196/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 0.8291 - accuracy: 0.7531 - val_loss: 7.2510 - val_accuracy: 0.0465\n",
      "Epoch 197/1000\n",
      "263/263 [==============================] - 1s 4ms/step - loss: 0.8488 - accuracy: 0.7492 - val_loss: 7.3880 - val_accuracy: 0.0500\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([LSTM(256, input_shape=(32, 20)),\n",
    "                  Dense(20, activation='softmax')])\n",
    "train(model=model,\n",
    "      patience_train=5,\n",
    "      patience_val=None,\n",
    "      learning_rate=.001,\n",
    "      epochs=1000,\n",
    "      batch_size=128,\n",
    "      # cont_train=True,\n",
    "      )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "WsUTsxHC3Ol2",
   "metadata": {
    "id": "WsUTsxHC3Ol2"
   },
   "source": [
    "## 2 layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "_QJ7PYGK3N89",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 462303,
     "status": "ok",
     "timestamp": 1688893456933,
     "user": {
      "displayName": "Yoni Krichevsky",
      "userId": "07735752940575548299"
     },
     "user_tz": -180
    },
    "id": "_QJ7PYGK3N89",
    "outputId": "56b93312-e420-4221-e6d0-a6f82130cdff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patience_train=5, patience_val=None, learning_rate=0.001, epochs=1000, batch_size=128, cont_train=False, X_train.shape=(33566, 32, 20), y_train.shape=(33566,), X_val.shape=(4619, 32, 20), y_val.shape=(4619,)\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_6 (LSTM)               (None, 128)               76288     \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 20)                2580      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 95,380\n",
      "Trainable params: 95,380\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Input shape (None, 32, 20), output shape (None, 20)\n",
      "Epoch 1/1000\n",
      "263/263 [==============================] - 4s 7ms/step - loss: 3.0084 - accuracy: 0.0506 - val_loss: 3.0025 - val_accuracy: 0.0487\n",
      "Epoch 2/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 3.0015 - accuracy: 0.0506 - val_loss: 2.9995 - val_accuracy: 0.0535\n",
      "Epoch 3/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 3.0019 - accuracy: 0.0507 - val_loss: 3.0033 - val_accuracy: 0.0485\n",
      "Epoch 4/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 3.0018 - accuracy: 0.0504 - val_loss: 3.0044 - val_accuracy: 0.0502\n",
      "Epoch 5/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 3.0009 - accuracy: 0.0485 - val_loss: 3.0057 - val_accuracy: 0.0452\n",
      "Epoch 6/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 3.0012 - accuracy: 0.0521 - val_loss: 2.9991 - val_accuracy: 0.0474\n",
      "Epoch 7/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 3.0004 - accuracy: 0.0506 - val_loss: 3.0032 - val_accuracy: 0.0478\n",
      "Epoch 8/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9995 - accuracy: 0.0520 - val_loss: 2.9985 - val_accuracy: 0.0491\n",
      "Epoch 9/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9997 - accuracy: 0.0500 - val_loss: 2.9985 - val_accuracy: 0.0507\n",
      "Epoch 10/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9992 - accuracy: 0.0521 - val_loss: 2.9994 - val_accuracy: 0.0498\n",
      "Epoch 11/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9980 - accuracy: 0.0519 - val_loss: 2.9994 - val_accuracy: 0.0524\n",
      "Epoch 12/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9974 - accuracy: 0.0494 - val_loss: 2.9970 - val_accuracy: 0.0498\n",
      "Epoch 13/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9965 - accuracy: 0.0517 - val_loss: 2.9966 - val_accuracy: 0.0511\n",
      "Epoch 14/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9961 - accuracy: 0.0515 - val_loss: 2.9965 - val_accuracy: 0.0502\n",
      "Epoch 15/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9960 - accuracy: 0.0498 - val_loss: 2.9960 - val_accuracy: 0.0528\n",
      "Epoch 16/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9958 - accuracy: 0.0490 - val_loss: 2.9963 - val_accuracy: 0.0504\n",
      "Epoch 17/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9959 - accuracy: 0.0500 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 18/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9958 - accuracy: 0.0515 - val_loss: 2.9961 - val_accuracy: 0.0528\n",
      "Epoch 19/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9958 - accuracy: 0.0513 - val_loss: 2.9962 - val_accuracy: 0.0507\n",
      "Epoch 20/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9959 - accuracy: 0.0523 - val_loss: 2.9958 - val_accuracy: 0.0517\n",
      "Epoch 21/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9958 - accuracy: 0.0507 - val_loss: 2.9960 - val_accuracy: 0.0498\n",
      "Epoch 22/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9957 - accuracy: 0.0512 - val_loss: 2.9959 - val_accuracy: 0.0511\n",
      "Epoch 23/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9957 - accuracy: 0.0509 - val_loss: 2.9960 - val_accuracy: 0.0500\n",
      "Epoch 24/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9956 - accuracy: 0.0509 - val_loss: 2.9960 - val_accuracy: 0.0465\n",
      "Epoch 25/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9957 - accuracy: 0.0515 - val_loss: 2.9959 - val_accuracy: 0.0485\n",
      "Epoch 26/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9956 - accuracy: 0.0503 - val_loss: 2.9962 - val_accuracy: 0.0489\n",
      "Epoch 27/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9956 - accuracy: 0.0511 - val_loss: 2.9960 - val_accuracy: 0.0498\n",
      "Epoch 28/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9956 - accuracy: 0.0517 - val_loss: 2.9959 - val_accuracy: 0.0498\n",
      "Epoch 29/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9955 - accuracy: 0.0518 - val_loss: 2.9959 - val_accuracy: 0.0496\n",
      "Epoch 30/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9955 - accuracy: 0.0525 - val_loss: 2.9964 - val_accuracy: 0.0533\n",
      "Epoch 31/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9955 - accuracy: 0.0525 - val_loss: 2.9963 - val_accuracy: 0.0481\n",
      "Epoch 32/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9954 - accuracy: 0.0515 - val_loss: 2.9957 - val_accuracy: 0.0530\n",
      "Epoch 33/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9955 - accuracy: 0.0506 - val_loss: 2.9959 - val_accuracy: 0.0500\n",
      "Epoch 34/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9955 - accuracy: 0.0523 - val_loss: 2.9961 - val_accuracy: 0.0481\n",
      "Epoch 35/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9955 - accuracy: 0.0519 - val_loss: 2.9962 - val_accuracy: 0.0522\n",
      "Epoch 36/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9954 - accuracy: 0.0515 - val_loss: 2.9959 - val_accuracy: 0.0552\n",
      "Epoch 37/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9955 - accuracy: 0.0519 - val_loss: 2.9960 - val_accuracy: 0.0524\n",
      "Epoch 38/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9954 - accuracy: 0.0529 - val_loss: 2.9959 - val_accuracy: 0.0504\n",
      "Epoch 39/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9954 - accuracy: 0.0517 - val_loss: 2.9972 - val_accuracy: 0.0502\n",
      "Epoch 40/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9954 - accuracy: 0.0523 - val_loss: 2.9961 - val_accuracy: 0.0565\n",
      "Epoch 41/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9952 - accuracy: 0.0530 - val_loss: 2.9964 - val_accuracy: 0.0543\n",
      "Epoch 42/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9953 - accuracy: 0.0527 - val_loss: 2.9964 - val_accuracy: 0.0537\n",
      "Epoch 43/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9953 - accuracy: 0.0508 - val_loss: 2.9962 - val_accuracy: 0.0487\n",
      "Epoch 44/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9953 - accuracy: 0.0524 - val_loss: 2.9964 - val_accuracy: 0.0528\n",
      "Epoch 45/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9952 - accuracy: 0.0529 - val_loss: 2.9965 - val_accuracy: 0.0517\n",
      "Epoch 46/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9952 - accuracy: 0.0540 - val_loss: 2.9962 - val_accuracy: 0.0522\n",
      "Epoch 47/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9953 - accuracy: 0.0529 - val_loss: 2.9962 - val_accuracy: 0.0522\n",
      "Epoch 48/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9952 - accuracy: 0.0535 - val_loss: 2.9962 - val_accuracy: 0.0515\n",
      "Epoch 49/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9952 - accuracy: 0.0522 - val_loss: 2.9969 - val_accuracy: 0.0496\n",
      "Epoch 50/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9951 - accuracy: 0.0542 - val_loss: 2.9973 - val_accuracy: 0.0515\n",
      "Epoch 51/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9951 - accuracy: 0.0534 - val_loss: 2.9962 - val_accuracy: 0.0494\n",
      "Epoch 52/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9951 - accuracy: 0.0528 - val_loss: 2.9964 - val_accuracy: 0.0507\n",
      "Epoch 53/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9951 - accuracy: 0.0514 - val_loss: 2.9965 - val_accuracy: 0.0535\n",
      "Epoch 54/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9951 - accuracy: 0.0518 - val_loss: 2.9964 - val_accuracy: 0.0539\n",
      "Epoch 55/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9951 - accuracy: 0.0527 - val_loss: 2.9963 - val_accuracy: 0.0520\n",
      "Epoch 56/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9951 - accuracy: 0.0538 - val_loss: 2.9965 - val_accuracy: 0.0528\n",
      "Epoch 57/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9951 - accuracy: 0.0538 - val_loss: 2.9966 - val_accuracy: 0.0530\n",
      "Epoch 58/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9951 - accuracy: 0.0534 - val_loss: 2.9969 - val_accuracy: 0.0524\n",
      "Epoch 59/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9949 - accuracy: 0.0533 - val_loss: 2.9970 - val_accuracy: 0.0526\n",
      "Epoch 60/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9950 - accuracy: 0.0524 - val_loss: 2.9966 - val_accuracy: 0.0502\n",
      "Epoch 61/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9950 - accuracy: 0.0531 - val_loss: 2.9963 - val_accuracy: 0.0502\n",
      "Epoch 62/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9949 - accuracy: 0.0522 - val_loss: 2.9978 - val_accuracy: 0.0507\n",
      "Epoch 63/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9954 - accuracy: 0.0527 - val_loss: 2.9963 - val_accuracy: 0.0543\n",
      "Epoch 64/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9950 - accuracy: 0.0523 - val_loss: 2.9970 - val_accuracy: 0.0524\n",
      "Epoch 65/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9951 - accuracy: 0.0513 - val_loss: 2.9963 - val_accuracy: 0.0537\n",
      "Epoch 66/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9951 - accuracy: 0.0523 - val_loss: 2.9963 - val_accuracy: 0.0528\n",
      "Epoch 67/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9949 - accuracy: 0.0536 - val_loss: 2.9971 - val_accuracy: 0.0517\n",
      "Epoch 68/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9950 - accuracy: 0.0519 - val_loss: 2.9970 - val_accuracy: 0.0522\n",
      "Epoch 69/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9949 - accuracy: 0.0529 - val_loss: 2.9971 - val_accuracy: 0.0528\n",
      "Epoch 70/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9948 - accuracy: 0.0526 - val_loss: 2.9974 - val_accuracy: 0.0530\n",
      "Epoch 71/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9948 - accuracy: 0.0534 - val_loss: 2.9973 - val_accuracy: 0.0528\n",
      "Epoch 72/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9947 - accuracy: 0.0522 - val_loss: 2.9973 - val_accuracy: 0.0485\n",
      "Epoch 73/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9947 - accuracy: 0.0526 - val_loss: 2.9976 - val_accuracy: 0.0494\n",
      "Epoch 74/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9947 - accuracy: 0.0523 - val_loss: 2.9982 - val_accuracy: 0.0513\n",
      "Epoch 75/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9949 - accuracy: 0.0537 - val_loss: 2.9978 - val_accuracy: 0.0520\n",
      "Epoch 76/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9947 - accuracy: 0.0558 - val_loss: 2.9982 - val_accuracy: 0.0511\n",
      "Epoch 77/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9945 - accuracy: 0.0548 - val_loss: 2.9980 - val_accuracy: 0.0485\n",
      "Epoch 78/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9945 - accuracy: 0.0520 - val_loss: 2.9974 - val_accuracy: 0.0509\n",
      "Epoch 79/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9945 - accuracy: 0.0540 - val_loss: 2.9983 - val_accuracy: 0.0489\n",
      "Epoch 80/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9944 - accuracy: 0.0551 - val_loss: 2.9978 - val_accuracy: 0.0556\n",
      "Epoch 81/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9944 - accuracy: 0.0544 - val_loss: 2.9978 - val_accuracy: 0.0522\n",
      "Epoch 82/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9943 - accuracy: 0.0552 - val_loss: 2.9987 - val_accuracy: 0.0491\n",
      "Epoch 83/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9943 - accuracy: 0.0535 - val_loss: 3.0001 - val_accuracy: 0.0504\n",
      "Epoch 84/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9944 - accuracy: 0.0545 - val_loss: 2.9988 - val_accuracy: 0.0470\n",
      "Epoch 85/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9941 - accuracy: 0.0536 - val_loss: 2.9994 - val_accuracy: 0.0509\n",
      "Epoch 86/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9942 - accuracy: 0.0538 - val_loss: 2.9987 - val_accuracy: 0.0509\n",
      "Epoch 87/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9941 - accuracy: 0.0550 - val_loss: 2.9998 - val_accuracy: 0.0494\n",
      "Epoch 88/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9939 - accuracy: 0.0547 - val_loss: 2.9996 - val_accuracy: 0.0496\n",
      "Epoch 89/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9939 - accuracy: 0.0547 - val_loss: 2.9998 - val_accuracy: 0.0487\n",
      "Epoch 90/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9940 - accuracy: 0.0544 - val_loss: 2.9995 - val_accuracy: 0.0524\n",
      "Epoch 91/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9940 - accuracy: 0.0548 - val_loss: 2.9993 - val_accuracy: 0.0504\n",
      "Epoch 92/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9938 - accuracy: 0.0553 - val_loss: 3.0001 - val_accuracy: 0.0511\n",
      "Epoch 93/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9935 - accuracy: 0.0549 - val_loss: 2.9989 - val_accuracy: 0.0498\n",
      "Epoch 94/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9937 - accuracy: 0.0554 - val_loss: 3.0015 - val_accuracy: 0.0476\n",
      "Epoch 95/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9935 - accuracy: 0.0547 - val_loss: 2.9992 - val_accuracy: 0.0543\n",
      "Epoch 96/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9935 - accuracy: 0.0535 - val_loss: 2.9991 - val_accuracy: 0.0535\n",
      "Epoch 97/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9933 - accuracy: 0.0545 - val_loss: 3.0003 - val_accuracy: 0.0463\n",
      "Epoch 98/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9933 - accuracy: 0.0551 - val_loss: 3.0006 - val_accuracy: 0.0468\n",
      "Epoch 99/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9931 - accuracy: 0.0544 - val_loss: 3.0020 - val_accuracy: 0.0491\n",
      "Epoch 100/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9930 - accuracy: 0.0545 - val_loss: 3.0009 - val_accuracy: 0.0474\n",
      "Epoch 101/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9933 - accuracy: 0.0563 - val_loss: 3.0005 - val_accuracy: 0.0520\n",
      "Epoch 102/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9933 - accuracy: 0.0540 - val_loss: 3.0012 - val_accuracy: 0.0476\n",
      "Epoch 103/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9927 - accuracy: 0.0559 - val_loss: 3.0010 - val_accuracy: 0.0502\n",
      "Epoch 104/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9927 - accuracy: 0.0559 - val_loss: 3.0006 - val_accuracy: 0.0520\n",
      "Epoch 105/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9925 - accuracy: 0.0557 - val_loss: 3.0044 - val_accuracy: 0.0472\n",
      "Epoch 106/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9928 - accuracy: 0.0553 - val_loss: 3.0008 - val_accuracy: 0.0526\n",
      "Epoch 107/1000\n",
      "263/263 [==============================] - 2s 6ms/step - loss: 2.9927 - accuracy: 0.0570 - val_loss: 3.0007 - val_accuracy: 0.0509\n",
      "Epoch 108/1000\n",
      "263/263 [==============================] - 2s 6ms/step - loss: 2.9923 - accuracy: 0.0565 - val_loss: 3.0004 - val_accuracy: 0.0526\n",
      "Epoch 109/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9922 - accuracy: 0.0568 - val_loss: 3.0031 - val_accuracy: 0.0520\n",
      "Epoch 110/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9919 - accuracy: 0.0552 - val_loss: 3.0001 - val_accuracy: 0.0500\n",
      "Epoch 111/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9921 - accuracy: 0.0550 - val_loss: 2.9988 - val_accuracy: 0.0548\n",
      "Epoch 112/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9919 - accuracy: 0.0564 - val_loss: 2.9996 - val_accuracy: 0.0507\n",
      "Epoch 113/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9912 - accuracy: 0.0549 - val_loss: 3.0028 - val_accuracy: 0.0509\n",
      "Epoch 114/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9909 - accuracy: 0.0571 - val_loss: 3.0025 - val_accuracy: 0.0507\n",
      "Epoch 115/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9905 - accuracy: 0.0553 - val_loss: 3.0029 - val_accuracy: 0.0472\n",
      "Epoch 116/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9904 - accuracy: 0.0573 - val_loss: 3.0020 - val_accuracy: 0.0504\n",
      "Epoch 117/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9900 - accuracy: 0.0579 - val_loss: 3.0019 - val_accuracy: 0.0535\n",
      "Epoch 118/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9898 - accuracy: 0.0570 - val_loss: 3.0011 - val_accuracy: 0.0450\n",
      "Epoch 119/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9894 - accuracy: 0.0568 - val_loss: 3.0022 - val_accuracy: 0.0487\n",
      "Epoch 120/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9889 - accuracy: 0.0581 - val_loss: 3.0049 - val_accuracy: 0.0485\n",
      "Epoch 121/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9886 - accuracy: 0.0581 - val_loss: 3.0061 - val_accuracy: 0.0452\n",
      "Epoch 122/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9882 - accuracy: 0.0584 - val_loss: 3.0030 - val_accuracy: 0.0457\n",
      "Epoch 123/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9879 - accuracy: 0.0578 - val_loss: 3.0060 - val_accuracy: 0.0485\n",
      "Epoch 124/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9875 - accuracy: 0.0585 - val_loss: 3.0018 - val_accuracy: 0.0489\n",
      "Epoch 125/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9871 - accuracy: 0.0593 - val_loss: 3.0040 - val_accuracy: 0.0485\n",
      "Epoch 126/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9865 - accuracy: 0.0584 - val_loss: 3.0074 - val_accuracy: 0.0474\n",
      "Epoch 127/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9861 - accuracy: 0.0597 - val_loss: 3.0072 - val_accuracy: 0.0485\n",
      "Epoch 128/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9853 - accuracy: 0.0603 - val_loss: 3.0070 - val_accuracy: 0.0450\n",
      "Epoch 129/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9846 - accuracy: 0.0599 - val_loss: 3.0072 - val_accuracy: 0.0509\n",
      "Epoch 130/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9841 - accuracy: 0.0615 - val_loss: 3.0071 - val_accuracy: 0.0483\n",
      "Epoch 131/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9831 - accuracy: 0.0618 - val_loss: 3.0061 - val_accuracy: 0.0496\n",
      "Epoch 132/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9825 - accuracy: 0.0617 - val_loss: 3.0048 - val_accuracy: 0.0496\n",
      "Epoch 133/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9821 - accuracy: 0.0615 - val_loss: 3.0078 - val_accuracy: 0.0496\n",
      "Epoch 134/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9813 - accuracy: 0.0621 - val_loss: 3.0081 - val_accuracy: 0.0507\n",
      "Epoch 135/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9801 - accuracy: 0.0630 - val_loss: 3.0088 - val_accuracy: 0.0552\n",
      "Epoch 136/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9797 - accuracy: 0.0633 - val_loss: 3.0074 - val_accuracy: 0.0524\n",
      "Epoch 137/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9788 - accuracy: 0.0642 - val_loss: 3.0114 - val_accuracy: 0.0513\n",
      "Epoch 138/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9775 - accuracy: 0.0633 - val_loss: 3.0123 - val_accuracy: 0.0478\n",
      "Epoch 139/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9765 - accuracy: 0.0650 - val_loss: 3.0076 - val_accuracy: 0.0530\n",
      "Epoch 140/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9761 - accuracy: 0.0654 - val_loss: 3.0111 - val_accuracy: 0.0524\n",
      "Epoch 141/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9742 - accuracy: 0.0655 - val_loss: 3.0125 - val_accuracy: 0.0539\n",
      "Epoch 142/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9731 - accuracy: 0.0663 - val_loss: 3.0176 - val_accuracy: 0.0517\n",
      "Epoch 143/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9718 - accuracy: 0.0659 - val_loss: 3.0123 - val_accuracy: 0.0546\n",
      "Epoch 144/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9708 - accuracy: 0.0683 - val_loss: 3.0142 - val_accuracy: 0.0528\n",
      "Epoch 145/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9691 - accuracy: 0.0669 - val_loss: 3.0198 - val_accuracy: 0.0502\n",
      "Epoch 146/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9679 - accuracy: 0.0671 - val_loss: 3.0225 - val_accuracy: 0.0541\n",
      "Epoch 147/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9667 - accuracy: 0.0684 - val_loss: 3.0162 - val_accuracy: 0.0567\n",
      "Epoch 148/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9647 - accuracy: 0.0691 - val_loss: 3.0203 - val_accuracy: 0.0567\n",
      "Epoch 149/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9655 - accuracy: 0.0699 - val_loss: 3.0232 - val_accuracy: 0.0550\n",
      "Epoch 150/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9618 - accuracy: 0.0693 - val_loss: 3.0221 - val_accuracy: 0.0589\n",
      "Epoch 151/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9605 - accuracy: 0.0710 - val_loss: 3.0227 - val_accuracy: 0.0530\n",
      "Epoch 152/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9588 - accuracy: 0.0717 - val_loss: 3.0240 - val_accuracy: 0.0541\n",
      "Epoch 153/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9570 - accuracy: 0.0725 - val_loss: 3.0271 - val_accuracy: 0.0578\n",
      "Epoch 154/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9549 - accuracy: 0.0720 - val_loss: 3.0309 - val_accuracy: 0.0535\n",
      "Epoch 155/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9528 - accuracy: 0.0727 - val_loss: 3.0301 - val_accuracy: 0.0543\n",
      "Epoch 156/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9520 - accuracy: 0.0738 - val_loss: 3.0336 - val_accuracy: 0.0509\n",
      "Epoch 157/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9506 - accuracy: 0.0735 - val_loss: 3.0283 - val_accuracy: 0.0526\n",
      "Epoch 158/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9462 - accuracy: 0.0754 - val_loss: 3.0313 - val_accuracy: 0.0537\n",
      "Epoch 159/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9456 - accuracy: 0.0775 - val_loss: 3.0331 - val_accuracy: 0.0526\n",
      "Epoch 160/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9435 - accuracy: 0.0761 - val_loss: 3.0334 - val_accuracy: 0.0552\n",
      "Epoch 161/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9412 - accuracy: 0.0781 - val_loss: 3.0378 - val_accuracy: 0.0528\n",
      "Epoch 162/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9398 - accuracy: 0.0775 - val_loss: 3.0325 - val_accuracy: 0.0511\n",
      "Epoch 163/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9381 - accuracy: 0.0782 - val_loss: 3.0463 - val_accuracy: 0.0496\n",
      "Epoch 164/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9349 - accuracy: 0.0799 - val_loss: 3.0447 - val_accuracy: 0.0543\n",
      "Epoch 165/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9327 - accuracy: 0.0809 - val_loss: 3.0502 - val_accuracy: 0.0543\n",
      "Epoch 166/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9305 - accuracy: 0.0810 - val_loss: 3.0432 - val_accuracy: 0.0535\n",
      "Epoch 167/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9276 - accuracy: 0.0828 - val_loss: 3.0502 - val_accuracy: 0.0528\n",
      "Epoch 168/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9255 - accuracy: 0.0838 - val_loss: 3.0577 - val_accuracy: 0.0522\n",
      "Epoch 169/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9246 - accuracy: 0.0835 - val_loss: 3.0613 - val_accuracy: 0.0520\n",
      "Epoch 170/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9217 - accuracy: 0.0844 - val_loss: 3.0624 - val_accuracy: 0.0535\n",
      "Epoch 171/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9197 - accuracy: 0.0852 - val_loss: 3.0621 - val_accuracy: 0.0513\n",
      "Epoch 172/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9153 - accuracy: 0.0865 - val_loss: 3.0707 - val_accuracy: 0.0513\n",
      "Epoch 173/1000\n",
      "263/263 [==============================] - 1s 6ms/step - loss: 2.9120 - accuracy: 0.0875 - val_loss: 3.0672 - val_accuracy: 0.0507\n",
      "Epoch 174/1000\n",
      "263/263 [==============================] - 1s 6ms/step - loss: 2.9089 - accuracy: 0.0879 - val_loss: 3.0690 - val_accuracy: 0.0494\n",
      "Epoch 175/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9072 - accuracy: 0.0894 - val_loss: 3.0774 - val_accuracy: 0.0517\n",
      "Epoch 176/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9075 - accuracy: 0.0896 - val_loss: 3.0744 - val_accuracy: 0.0530\n",
      "Epoch 177/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9009 - accuracy: 0.0899 - val_loss: 3.0753 - val_accuracy: 0.0526\n",
      "Epoch 178/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.8999 - accuracy: 0.0924 - val_loss: 3.0772 - val_accuracy: 0.0487\n",
      "Epoch 179/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.8959 - accuracy: 0.0949 - val_loss: 3.0807 - val_accuracy: 0.0509\n",
      "Epoch 180/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.8915 - accuracy: 0.0942 - val_loss: 3.0873 - val_accuracy: 0.0483\n",
      "Epoch 181/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.8899 - accuracy: 0.0949 - val_loss: 3.0795 - val_accuracy: 0.0522\n",
      "Epoch 182/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.8871 - accuracy: 0.0963 - val_loss: 3.0856 - val_accuracy: 0.0541\n",
      "Epoch 183/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.8845 - accuracy: 0.0986 - val_loss: 3.0896 - val_accuracy: 0.0533\n",
      "Epoch 184/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.8813 - accuracy: 0.0977 - val_loss: 3.0963 - val_accuracy: 0.0494\n",
      "Epoch 185/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.8777 - accuracy: 0.0990 - val_loss: 3.0926 - val_accuracy: 0.0485\n",
      "Epoch 186/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.8750 - accuracy: 0.1017 - val_loss: 3.1035 - val_accuracy: 0.0520\n",
      "Epoch 187/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.8746 - accuracy: 0.1015 - val_loss: 3.1063 - val_accuracy: 0.0500\n",
      "Epoch 188/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.8720 - accuracy: 0.1016 - val_loss: 3.1041 - val_accuracy: 0.0500\n",
      "Epoch 189/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.8669 - accuracy: 0.1048 - val_loss: 3.1027 - val_accuracy: 0.0500\n",
      "Epoch 190/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.8625 - accuracy: 0.1070 - val_loss: 3.1167 - val_accuracy: 0.0500\n",
      "Epoch 191/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.8581 - accuracy: 0.1084 - val_loss: 3.1070 - val_accuracy: 0.0522\n",
      "Epoch 192/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.8577 - accuracy: 0.1081 - val_loss: 3.1193 - val_accuracy: 0.0496\n",
      "Epoch 193/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.8546 - accuracy: 0.1093 - val_loss: 3.1217 - val_accuracy: 0.0513\n",
      "Epoch 194/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.8534 - accuracy: 0.1098 - val_loss: 3.1264 - val_accuracy: 0.0485\n",
      "Epoch 195/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.8454 - accuracy: 0.1117 - val_loss: 3.1270 - val_accuracy: 0.0533\n",
      "Epoch 196/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.8440 - accuracy: 0.1127 - val_loss: 3.1433 - val_accuracy: 0.0457\n",
      "Epoch 197/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.8408 - accuracy: 0.1146 - val_loss: 3.1371 - val_accuracy: 0.0498\n",
      "Epoch 198/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.8382 - accuracy: 0.1151 - val_loss: 3.1403 - val_accuracy: 0.0533\n",
      "Epoch 199/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.8355 - accuracy: 0.1143 - val_loss: 3.1502 - val_accuracy: 0.0474\n",
      "Epoch 200/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.8315 - accuracy: 0.1170 - val_loss: 3.1528 - val_accuracy: 0.0524\n",
      "Epoch 201/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.8254 - accuracy: 0.1188 - val_loss: 3.1520 - val_accuracy: 0.0489\n",
      "Epoch 202/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.8238 - accuracy: 0.1198 - val_loss: 3.1575 - val_accuracy: 0.0483\n",
      "Epoch 203/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.8188 - accuracy: 0.1205 - val_loss: 3.1643 - val_accuracy: 0.0485\n",
      "Epoch 204/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.8192 - accuracy: 0.1216 - val_loss: 3.1642 - val_accuracy: 0.0470\n",
      "Epoch 205/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.8113 - accuracy: 0.1227 - val_loss: 3.1716 - val_accuracy: 0.0485\n",
      "Epoch 206/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.8125 - accuracy: 0.1238 - val_loss: 3.1741 - val_accuracy: 0.0498\n",
      "Epoch 207/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.8061 - accuracy: 0.1257 - val_loss: 3.1817 - val_accuracy: 0.0474\n",
      "Epoch 208/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.8038 - accuracy: 0.1256 - val_loss: 3.1723 - val_accuracy: 0.0517\n",
      "Epoch 209/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.7976 - accuracy: 0.1268 - val_loss: 3.1854 - val_accuracy: 0.0504\n",
      "Epoch 210/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.7972 - accuracy: 0.1276 - val_loss: 3.1785 - val_accuracy: 0.0494\n",
      "Epoch 211/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.7903 - accuracy: 0.1308 - val_loss: 3.1912 - val_accuracy: 0.0502\n",
      "Epoch 212/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.7869 - accuracy: 0.1310 - val_loss: 3.1981 - val_accuracy: 0.0509\n",
      "Epoch 213/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.7840 - accuracy: 0.1326 - val_loss: 3.2004 - val_accuracy: 0.0507\n",
      "Epoch 214/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.7865 - accuracy: 0.1310 - val_loss: 3.2095 - val_accuracy: 0.0455\n",
      "Epoch 215/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.7744 - accuracy: 0.1344 - val_loss: 3.2187 - val_accuracy: 0.0502\n",
      "Epoch 216/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.7718 - accuracy: 0.1369 - val_loss: 3.2000 - val_accuracy: 0.0494\n",
      "Epoch 217/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.7672 - accuracy: 0.1377 - val_loss: 3.2090 - val_accuracy: 0.0481\n",
      "Epoch 218/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.7657 - accuracy: 0.1393 - val_loss: 3.2352 - val_accuracy: 0.0487\n",
      "Epoch 219/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.7665 - accuracy: 0.1369 - val_loss: 3.2374 - val_accuracy: 0.0520\n",
      "Epoch 220/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.7601 - accuracy: 0.1394 - val_loss: 3.2399 - val_accuracy: 0.0474\n",
      "Epoch 221/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.7550 - accuracy: 0.1431 - val_loss: 3.2569 - val_accuracy: 0.0498\n",
      "Epoch 222/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.7567 - accuracy: 0.1420 - val_loss: 3.2446 - val_accuracy: 0.0504\n",
      "Epoch 223/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.7471 - accuracy: 0.1446 - val_loss: 3.2646 - val_accuracy: 0.0496\n",
      "Epoch 224/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.7406 - accuracy: 0.1479 - val_loss: 3.2678 - val_accuracy: 0.0504\n",
      "Epoch 225/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.7390 - accuracy: 0.1466 - val_loss: 3.2482 - val_accuracy: 0.0489\n",
      "Epoch 226/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.7385 - accuracy: 0.1480 - val_loss: 3.2543 - val_accuracy: 0.0494\n",
      "Epoch 227/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.7420 - accuracy: 0.1460 - val_loss: 3.2724 - val_accuracy: 0.0533\n",
      "Epoch 228/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.7306 - accuracy: 0.1485 - val_loss: 3.2833 - val_accuracy: 0.0489\n",
      "Epoch 229/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.7292 - accuracy: 0.1496 - val_loss: 3.2889 - val_accuracy: 0.0517\n",
      "Epoch 230/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.7182 - accuracy: 0.1534 - val_loss: 3.2973 - val_accuracy: 0.0487\n",
      "Epoch 231/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.7215 - accuracy: 0.1517 - val_loss: 3.3007 - val_accuracy: 0.0494\n",
      "Epoch 232/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.7126 - accuracy: 0.1557 - val_loss: 3.2961 - val_accuracy: 0.0526\n",
      "Epoch 233/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.7125 - accuracy: 0.1571 - val_loss: 3.3262 - val_accuracy: 0.0463\n",
      "Epoch 234/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.7069 - accuracy: 0.1576 - val_loss: 3.3147 - val_accuracy: 0.0507\n",
      "Epoch 235/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.7023 - accuracy: 0.1587 - val_loss: 3.2941 - val_accuracy: 0.0502\n",
      "Epoch 236/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.7061 - accuracy: 0.1571 - val_loss: 3.3059 - val_accuracy: 0.0487\n",
      "Epoch 237/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.7007 - accuracy: 0.1602 - val_loss: 3.3113 - val_accuracy: 0.0513\n",
      "Epoch 238/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.6899 - accuracy: 0.1639 - val_loss: 3.3297 - val_accuracy: 0.0504\n",
      "Epoch 239/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.6864 - accuracy: 0.1628 - val_loss: 3.3433 - val_accuracy: 0.0520\n",
      "Epoch 240/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.6848 - accuracy: 0.1640 - val_loss: 3.3609 - val_accuracy: 0.0515\n",
      "Epoch 241/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.6859 - accuracy: 0.1635 - val_loss: 3.3429 - val_accuracy: 0.0504\n",
      "Epoch 242/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.6781 - accuracy: 0.1675 - val_loss: 3.3481 - val_accuracy: 0.0491\n",
      "Epoch 243/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.6698 - accuracy: 0.1674 - val_loss: 3.3698 - val_accuracy: 0.0509\n",
      "Epoch 244/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.6841 - accuracy: 0.1666 - val_loss: 3.3643 - val_accuracy: 0.0507\n",
      "Epoch 245/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.6684 - accuracy: 0.1708 - val_loss: 3.3819 - val_accuracy: 0.0491\n",
      "Epoch 246/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.6613 - accuracy: 0.1729 - val_loss: 3.3686 - val_accuracy: 0.0476\n",
      "Epoch 247/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.6619 - accuracy: 0.1717 - val_loss: 3.3756 - val_accuracy: 0.0537\n",
      "Epoch 248/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.6608 - accuracy: 0.1718 - val_loss: 3.3880 - val_accuracy: 0.0487\n",
      "Epoch 249/1000\n",
      "263/263 [==============================] - 1s 6ms/step - loss: 2.6516 - accuracy: 0.1762 - val_loss: 3.4286 - val_accuracy: 0.0517\n",
      "Epoch 250/1000\n",
      "263/263 [==============================] - 2s 6ms/step - loss: 2.6616 - accuracy: 0.1697 - val_loss: 3.3999 - val_accuracy: 0.0463\n",
      "Epoch 251/1000\n",
      "263/263 [==============================] - 1s 6ms/step - loss: 2.6503 - accuracy: 0.1748 - val_loss: 3.4073 - val_accuracy: 0.0522\n",
      "Epoch 252/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.6419 - accuracy: 0.1775 - val_loss: 3.4105 - val_accuracy: 0.0457\n",
      "Epoch 253/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.6363 - accuracy: 0.1809 - val_loss: 3.3988 - val_accuracy: 0.0526\n",
      "Epoch 254/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.6359 - accuracy: 0.1812 - val_loss: 3.4130 - val_accuracy: 0.0515\n",
      "Epoch 255/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.6303 - accuracy: 0.1809 - val_loss: 3.4117 - val_accuracy: 0.0504\n",
      "Epoch 256/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.6276 - accuracy: 0.1842 - val_loss: 3.4544 - val_accuracy: 0.0476\n",
      "Epoch 257/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.6254 - accuracy: 0.1808 - val_loss: 3.4342 - val_accuracy: 0.0478\n",
      "Epoch 258/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.6219 - accuracy: 0.1827 - val_loss: 3.4524 - val_accuracy: 0.0487\n",
      "Epoch 259/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.6136 - accuracy: 0.1868 - val_loss: 3.4622 - val_accuracy: 0.0470\n",
      "Epoch 260/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.6173 - accuracy: 0.1861 - val_loss: 3.4564 - val_accuracy: 0.0517\n",
      "Epoch 261/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.6150 - accuracy: 0.1862 - val_loss: 3.4658 - val_accuracy: 0.0515\n",
      "Epoch 262/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.6028 - accuracy: 0.1906 - val_loss: 3.4805 - val_accuracy: 0.0470\n",
      "Epoch 263/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.6141 - accuracy: 0.1873 - val_loss: 3.5095 - val_accuracy: 0.0483\n",
      "Epoch 264/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.5982 - accuracy: 0.1923 - val_loss: 3.4807 - val_accuracy: 0.0485\n",
      "Epoch 265/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.6139 - accuracy: 0.1866 - val_loss: 3.4828 - val_accuracy: 0.0468\n",
      "Epoch 266/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.5877 - accuracy: 0.1964 - val_loss: 3.4860 - val_accuracy: 0.0520\n",
      "Epoch 267/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.5871 - accuracy: 0.1957 - val_loss: 3.4899 - val_accuracy: 0.0513\n",
      "Epoch 268/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.5859 - accuracy: 0.1953 - val_loss: 3.5180 - val_accuracy: 0.0522\n",
      "Epoch 269/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.5955 - accuracy: 0.1936 - val_loss: 3.5309 - val_accuracy: 0.0476\n",
      "Epoch 270/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.5779 - accuracy: 0.1993 - val_loss: 3.5420 - val_accuracy: 0.0507\n",
      "Epoch 271/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.5936 - accuracy: 0.1929 - val_loss: 3.5183 - val_accuracy: 0.0509\n",
      "Epoch 272/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.5697 - accuracy: 0.2006 - val_loss: 3.5267 - val_accuracy: 0.0496\n",
      "Epoch 273/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.5713 - accuracy: 0.2018 - val_loss: 3.5355 - val_accuracy: 0.0491\n",
      "Epoch 274/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.5662 - accuracy: 0.2027 - val_loss: 3.5412 - val_accuracy: 0.0502\n",
      "Epoch 275/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.5612 - accuracy: 0.2034 - val_loss: 3.5715 - val_accuracy: 0.0478\n",
      "Epoch 276/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.5557 - accuracy: 0.2056 - val_loss: 3.5717 - val_accuracy: 0.0483\n",
      "Epoch 277/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.5511 - accuracy: 0.2072 - val_loss: 3.5708 - val_accuracy: 0.0478\n",
      "Epoch 278/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.5605 - accuracy: 0.2039 - val_loss: 3.5489 - val_accuracy: 0.0494\n",
      "Epoch 279/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.5541 - accuracy: 0.2052 - val_loss: 3.5898 - val_accuracy: 0.0483\n",
      "Epoch 280/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.5607 - accuracy: 0.2045 - val_loss: 3.5932 - val_accuracy: 0.0530\n",
      "Epoch 281/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.5498 - accuracy: 0.2071 - val_loss: 3.5864 - val_accuracy: 0.0491\n",
      "Epoch 282/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.5412 - accuracy: 0.2096 - val_loss: 3.5871 - val_accuracy: 0.0509\n",
      "Epoch 283/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.5372 - accuracy: 0.2098 - val_loss: 3.6178 - val_accuracy: 0.0483\n",
      "Epoch 284/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.5373 - accuracy: 0.2111 - val_loss: 3.6322 - val_accuracy: 0.0448\n",
      "Epoch 285/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.5272 - accuracy: 0.2143 - val_loss: 3.6232 - val_accuracy: 0.0485\n",
      "Epoch 286/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.5310 - accuracy: 0.2129 - val_loss: 3.6193 - val_accuracy: 0.0496\n",
      "Epoch 287/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.5307 - accuracy: 0.2142 - val_loss: 3.6239 - val_accuracy: 0.0498\n",
      "Epoch 288/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.5171 - accuracy: 0.2175 - val_loss: 3.6553 - val_accuracy: 0.0491\n",
      "Epoch 289/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.5101 - accuracy: 0.2207 - val_loss: 3.6458 - val_accuracy: 0.0496\n",
      "Epoch 290/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.5134 - accuracy: 0.2203 - val_loss: 3.6772 - val_accuracy: 0.0500\n",
      "Epoch 291/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.5100 - accuracy: 0.2213 - val_loss: 3.6189 - val_accuracy: 0.0509\n",
      "Epoch 292/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.5020 - accuracy: 0.2227 - val_loss: 3.6801 - val_accuracy: 0.0472\n",
      "Epoch 293/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.5042 - accuracy: 0.2205 - val_loss: 3.6568 - val_accuracy: 0.0472\n",
      "Epoch 294/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.5094 - accuracy: 0.2203 - val_loss: 3.6338 - val_accuracy: 0.0487\n",
      "Epoch 295/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.5087 - accuracy: 0.2220 - val_loss: 3.6593 - val_accuracy: 0.0526\n",
      "Epoch 296/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.4963 - accuracy: 0.2227 - val_loss: 3.6989 - val_accuracy: 0.0465\n",
      "Epoch 297/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.5003 - accuracy: 0.2243 - val_loss: 3.6760 - val_accuracy: 0.0489\n",
      "Epoch 298/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.5053 - accuracy: 0.2226 - val_loss: 3.6966 - val_accuracy: 0.0463\n",
      "Epoch 299/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.4837 - accuracy: 0.2296 - val_loss: 3.7200 - val_accuracy: 0.0507\n",
      "Epoch 300/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.4856 - accuracy: 0.2287 - val_loss: 3.7109 - val_accuracy: 0.0520\n",
      "Epoch 301/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.4810 - accuracy: 0.2297 - val_loss: 3.7433 - val_accuracy: 0.0491\n",
      "Epoch 302/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.4785 - accuracy: 0.2312 - val_loss: 3.7465 - val_accuracy: 0.0520\n",
      "Epoch 303/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.4932 - accuracy: 0.2247 - val_loss: 3.7074 - val_accuracy: 0.0442\n",
      "Epoch 304/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.4802 - accuracy: 0.2310 - val_loss: 3.7446 - val_accuracy: 0.0472\n",
      "Epoch 305/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.4768 - accuracy: 0.2320 - val_loss: 3.7437 - val_accuracy: 0.0487\n",
      "Epoch 306/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.4659 - accuracy: 0.2353 - val_loss: 3.7783 - val_accuracy: 0.0483\n",
      "Epoch 307/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.4580 - accuracy: 0.2365 - val_loss: 3.7695 - val_accuracy: 0.0500\n",
      "Epoch 308/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.4519 - accuracy: 0.2401 - val_loss: 3.7818 - val_accuracy: 0.0468\n",
      "Epoch 309/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.4698 - accuracy: 0.2354 - val_loss: 3.7763 - val_accuracy: 0.0481\n",
      "Epoch 310/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.4451 - accuracy: 0.2424 - val_loss: 3.8254 - val_accuracy: 0.0481\n",
      "Epoch 311/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.4630 - accuracy: 0.2359 - val_loss: 3.7837 - val_accuracy: 0.0496\n",
      "Epoch 312/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.4394 - accuracy: 0.2435 - val_loss: 3.7901 - val_accuracy: 0.0476\n",
      "Epoch 313/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.4444 - accuracy: 0.2426 - val_loss: 3.7923 - val_accuracy: 0.0500\n",
      "Epoch 314/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.4445 - accuracy: 0.2408 - val_loss: 3.7982 - val_accuracy: 0.0481\n",
      "Epoch 315/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.4511 - accuracy: 0.2396 - val_loss: 3.7952 - val_accuracy: 0.0487\n",
      "Epoch 316/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.4327 - accuracy: 0.2470 - val_loss: 3.7952 - val_accuracy: 0.0491\n",
      "Epoch 317/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.4352 - accuracy: 0.2445 - val_loss: 3.8352 - val_accuracy: 0.0496\n",
      "Epoch 318/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.4423 - accuracy: 0.2430 - val_loss: 3.7994 - val_accuracy: 0.0494\n",
      "Epoch 319/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.4288 - accuracy: 0.2465 - val_loss: 3.8426 - val_accuracy: 0.0452\n",
      "Epoch 320/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.4261 - accuracy: 0.2478 - val_loss: 3.8568 - val_accuracy: 0.0478\n",
      "Epoch 321/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.4250 - accuracy: 0.2472 - val_loss: 3.8595 - val_accuracy: 0.0491\n",
      "Epoch 322/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.4166 - accuracy: 0.2507 - val_loss: 3.8388 - val_accuracy: 0.0491\n",
      "Epoch 323/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.4221 - accuracy: 0.2485 - val_loss: 3.8593 - val_accuracy: 0.0470\n",
      "Epoch 324/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.4137 - accuracy: 0.2519 - val_loss: 3.8967 - val_accuracy: 0.0478\n",
      "Epoch 325/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.4133 - accuracy: 0.2530 - val_loss: 3.9154 - val_accuracy: 0.0502\n",
      "Epoch 326/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.4017 - accuracy: 0.2554 - val_loss: 3.9060 - val_accuracy: 0.0491\n",
      "Epoch 327/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.4095 - accuracy: 0.2525 - val_loss: 3.9084 - val_accuracy: 0.0485\n",
      "Epoch 328/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.4360 - accuracy: 0.2450 - val_loss: 3.9187 - val_accuracy: 0.0491\n",
      "Epoch 329/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.4018 - accuracy: 0.2540 - val_loss: 3.9159 - val_accuracy: 0.0489\n",
      "Epoch 330/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.3929 - accuracy: 0.2585 - val_loss: 3.9055 - val_accuracy: 0.0496\n",
      "Epoch 331/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.3877 - accuracy: 0.2598 - val_loss: 3.9194 - val_accuracy: 0.0491\n",
      "Epoch 332/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.3800 - accuracy: 0.2622 - val_loss: 3.9485 - val_accuracy: 0.0515\n",
      "Epoch 333/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.3904 - accuracy: 0.2585 - val_loss: 3.9623 - val_accuracy: 0.0476\n",
      "Epoch 334/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.4115 - accuracy: 0.2508 - val_loss: 3.9148 - val_accuracy: 0.0468\n",
      "Epoch 335/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.3850 - accuracy: 0.2599 - val_loss: 3.9037 - val_accuracy: 0.0461\n",
      "Epoch 336/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.3779 - accuracy: 0.2616 - val_loss: 3.9576 - val_accuracy: 0.0468\n",
      "Epoch 337/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.3750 - accuracy: 0.2637 - val_loss: 3.9820 - val_accuracy: 0.0485\n",
      "Epoch 338/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.3900 - accuracy: 0.2586 - val_loss: 3.9627 - val_accuracy: 0.0489\n",
      "Epoch 339/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.3917 - accuracy: 0.2579 - val_loss: 3.9589 - val_accuracy: 0.0483\n",
      "Epoch 340/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.3706 - accuracy: 0.2650 - val_loss: 4.0025 - val_accuracy: 0.0461\n",
      "Epoch 341/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.3747 - accuracy: 0.2621 - val_loss: 4.0019 - val_accuracy: 0.0485\n",
      "Epoch 342/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.3785 - accuracy: 0.2624 - val_loss: 4.0171 - val_accuracy: 0.0448\n",
      "Epoch 343/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.3576 - accuracy: 0.2693 - val_loss: 3.9996 - val_accuracy: 0.0448\n",
      "Epoch 344/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.3465 - accuracy: 0.2741 - val_loss: 3.9872 - val_accuracy: 0.0474\n",
      "Epoch 345/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.3555 - accuracy: 0.2704 - val_loss: 4.0537 - val_accuracy: 0.0491\n",
      "Epoch 346/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.3553 - accuracy: 0.2679 - val_loss: 4.0551 - val_accuracy: 0.0463\n",
      "Epoch 347/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.3637 - accuracy: 0.2661 - val_loss: 4.0392 - val_accuracy: 0.0498\n",
      "Epoch 348/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.3769 - accuracy: 0.2618 - val_loss: 4.0430 - val_accuracy: 0.0494\n",
      "Epoch 349/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.3471 - accuracy: 0.2728 - val_loss: 4.0841 - val_accuracy: 0.0504\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([LSTM(128, input_shape=(32, 20)),\n",
    "                    Dense(128, activation='sigmoid'),\n",
    "                    Dense(20, activation='softmax')])\n",
    "train(model=model,\n",
    "      patience_train=5,\n",
    "      patience_val=None,\n",
    "      learning_rate=.001,\n",
    "      epochs=1000,\n",
    "      batch_size=128,\n",
    "      # cont_train=True,\n",
    "      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "VJXnoEyW5Aq8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 29921,
     "status": "ok",
     "timestamp": 1688893773141,
     "user": {
      "displayName": "Yoni Krichevsky",
      "userId": "07735752940575548299"
     },
     "user_tz": -180
    },
    "id": "VJXnoEyW5Aq8",
    "outputId": "a0a406a6-8aba-4a9b-f44f-efe425525e86"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patience_train=5, patience_val=None, learning_rate=0.001, epochs=1000, batch_size=128, cont_train=False, X_train.shape=(33566, 32, 20), y_train.shape=(33566,), X_val.shape=(4619, 32, 20), y_val.shape=(4619,)\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_7 (LSTM)               (None, 64)                21760     \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 20)                1300      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 27,220\n",
      "Trainable params: 27,220\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Input shape (None, 32, 20), output shape (None, 20)\n",
      "Epoch 1/1000\n",
      "263/263 [==============================] - 4s 7ms/step - loss: 3.0040 - accuracy: 0.0505 - val_loss: 3.0007 - val_accuracy: 0.0465\n",
      "Epoch 2/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9994 - accuracy: 0.0515 - val_loss: 2.9982 - val_accuracy: 0.0487\n",
      "Epoch 3/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9996 - accuracy: 0.0498 - val_loss: 2.9967 - val_accuracy: 0.0511\n",
      "Epoch 4/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9985 - accuracy: 0.0503 - val_loss: 3.0002 - val_accuracy: 0.0498\n",
      "Epoch 5/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9986 - accuracy: 0.0515 - val_loss: 2.9999 - val_accuracy: 0.0463\n",
      "Epoch 6/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9984 - accuracy: 0.0484 - val_loss: 2.9995 - val_accuracy: 0.0483\n",
      "Epoch 7/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9984 - accuracy: 0.0499 - val_loss: 2.9977 - val_accuracy: 0.0513\n",
      "Epoch 8/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9979 - accuracy: 0.0517 - val_loss: 2.9999 - val_accuracy: 0.0502\n",
      "Epoch 9/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9978 - accuracy: 0.0508 - val_loss: 2.9997 - val_accuracy: 0.0552\n",
      "Epoch 10/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9976 - accuracy: 0.0513 - val_loss: 2.9977 - val_accuracy: 0.0487\n",
      "Epoch 11/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9974 - accuracy: 0.0517 - val_loss: 2.9983 - val_accuracy: 0.0485\n",
      "Epoch 12/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9973 - accuracy: 0.0542 - val_loss: 2.9993 - val_accuracy: 0.0459\n",
      "Epoch 13/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9969 - accuracy: 0.0526 - val_loss: 2.9977 - val_accuracy: 0.0468\n",
      "Epoch 14/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9969 - accuracy: 0.0498 - val_loss: 2.9983 - val_accuracy: 0.0520\n",
      "Epoch 15/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9967 - accuracy: 0.0512 - val_loss: 2.9989 - val_accuracy: 0.0422\n",
      "Epoch 16/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9967 - accuracy: 0.0517 - val_loss: 2.9984 - val_accuracy: 0.0515\n",
      "Epoch 17/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9965 - accuracy: 0.0524 - val_loss: 2.9975 - val_accuracy: 0.0498\n",
      "Epoch 18/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9964 - accuracy: 0.0535 - val_loss: 2.9986 - val_accuracy: 0.0433\n",
      "Epoch 19/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9956 - accuracy: 0.0544 - val_loss: 2.9977 - val_accuracy: 0.0483\n",
      "Epoch 20/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9958 - accuracy: 0.0539 - val_loss: 2.9969 - val_accuracy: 0.0524\n",
      "Epoch 21/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9956 - accuracy: 0.0520 - val_loss: 2.9980 - val_accuracy: 0.0500\n",
      "Epoch 22/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9954 - accuracy: 0.0529 - val_loss: 2.9980 - val_accuracy: 0.0535\n",
      "Epoch 23/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9950 - accuracy: 0.0554 - val_loss: 2.9996 - val_accuracy: 0.0520\n",
      "Epoch 24/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9953 - accuracy: 0.0542 - val_loss: 2.9967 - val_accuracy: 0.0485\n",
      "Epoch 25/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9951 - accuracy: 0.0517 - val_loss: 2.9976 - val_accuracy: 0.0513\n",
      "Epoch 26/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9948 - accuracy: 0.0552 - val_loss: 2.9971 - val_accuracy: 0.0552\n",
      "Epoch 27/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9947 - accuracy: 0.0533 - val_loss: 2.9970 - val_accuracy: 0.0541\n",
      "Epoch 28/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9944 - accuracy: 0.0544 - val_loss: 2.9977 - val_accuracy: 0.0498\n",
      "Epoch 29/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9944 - accuracy: 0.0557 - val_loss: 2.9974 - val_accuracy: 0.0515\n",
      "Epoch 30/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9940 - accuracy: 0.0548 - val_loss: 2.9978 - val_accuracy: 0.0511\n",
      "Epoch 31/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9940 - accuracy: 0.0545 - val_loss: 3.0002 - val_accuracy: 0.0468\n",
      "Epoch 32/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9939 - accuracy: 0.0542 - val_loss: 2.9974 - val_accuracy: 0.0483\n",
      "Epoch 33/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9933 - accuracy: 0.0562 - val_loss: 3.0000 - val_accuracy: 0.0543\n",
      "Epoch 34/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9936 - accuracy: 0.0554 - val_loss: 2.9998 - val_accuracy: 0.0520\n",
      "Epoch 35/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9931 - accuracy: 0.0581 - val_loss: 2.9987 - val_accuracy: 0.0563\n",
      "Epoch 36/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9926 - accuracy: 0.0583 - val_loss: 2.9996 - val_accuracy: 0.0500\n",
      "Epoch 37/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9929 - accuracy: 0.0602 - val_loss: 2.9983 - val_accuracy: 0.0543\n",
      "Epoch 38/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9923 - accuracy: 0.0564 - val_loss: 3.0001 - val_accuracy: 0.0517\n",
      "Epoch 39/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9918 - accuracy: 0.0573 - val_loss: 2.9995 - val_accuracy: 0.0550\n",
      "Epoch 40/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9912 - accuracy: 0.0598 - val_loss: 3.0076 - val_accuracy: 0.0446\n",
      "Epoch 41/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9914 - accuracy: 0.0580 - val_loss: 3.0026 - val_accuracy: 0.0511\n",
      "Epoch 42/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9907 - accuracy: 0.0587 - val_loss: 3.0009 - val_accuracy: 0.0561\n",
      "Epoch 43/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9905 - accuracy: 0.0598 - val_loss: 3.0012 - val_accuracy: 0.0474\n",
      "Epoch 44/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9898 - accuracy: 0.0606 - val_loss: 3.0032 - val_accuracy: 0.0463\n",
      "Epoch 45/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9895 - accuracy: 0.0608 - val_loss: 3.0012 - val_accuracy: 0.0509\n",
      "Epoch 46/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9888 - accuracy: 0.0618 - val_loss: 3.0048 - val_accuracy: 0.0550\n",
      "Epoch 47/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9882 - accuracy: 0.0607 - val_loss: 3.0035 - val_accuracy: 0.0509\n",
      "Epoch 48/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9877 - accuracy: 0.0610 - val_loss: 3.0030 - val_accuracy: 0.0520\n",
      "Epoch 49/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9872 - accuracy: 0.0614 - val_loss: 3.0053 - val_accuracy: 0.0504\n",
      "Epoch 50/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9871 - accuracy: 0.0624 - val_loss: 3.0018 - val_accuracy: 0.0504\n",
      "Epoch 51/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9856 - accuracy: 0.0628 - val_loss: 3.0080 - val_accuracy: 0.0511\n",
      "Epoch 52/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9854 - accuracy: 0.0635 - val_loss: 3.0082 - val_accuracy: 0.0481\n",
      "Epoch 53/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9843 - accuracy: 0.0601 - val_loss: 3.0074 - val_accuracy: 0.0496\n",
      "Epoch 54/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9836 - accuracy: 0.0633 - val_loss: 3.0109 - val_accuracy: 0.0502\n",
      "Epoch 55/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9826 - accuracy: 0.0632 - val_loss: 3.0130 - val_accuracy: 0.0465\n",
      "Epoch 56/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9818 - accuracy: 0.0636 - val_loss: 3.0128 - val_accuracy: 0.0513\n",
      "Epoch 57/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9813 - accuracy: 0.0636 - val_loss: 3.0107 - val_accuracy: 0.0494\n",
      "Epoch 58/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9803 - accuracy: 0.0656 - val_loss: 3.0132 - val_accuracy: 0.0533\n",
      "Epoch 59/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9799 - accuracy: 0.0680 - val_loss: 3.0079 - val_accuracy: 0.0496\n",
      "Epoch 60/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9780 - accuracy: 0.0679 - val_loss: 3.0105 - val_accuracy: 0.0489\n",
      "Epoch 61/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9770 - accuracy: 0.0655 - val_loss: 3.0129 - val_accuracy: 0.0509\n",
      "Epoch 62/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9764 - accuracy: 0.0665 - val_loss: 3.0141 - val_accuracy: 0.0520\n",
      "Epoch 63/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9752 - accuracy: 0.0671 - val_loss: 3.0137 - val_accuracy: 0.0500\n",
      "Epoch 64/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9742 - accuracy: 0.0680 - val_loss: 3.0165 - val_accuracy: 0.0535\n",
      "Epoch 65/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9723 - accuracy: 0.0687 - val_loss: 3.0168 - val_accuracy: 0.0554\n",
      "Epoch 66/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9709 - accuracy: 0.0699 - val_loss: 3.0207 - val_accuracy: 0.0485\n",
      "Epoch 67/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9702 - accuracy: 0.0684 - val_loss: 3.0205 - val_accuracy: 0.0487\n",
      "Epoch 68/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9680 - accuracy: 0.0713 - val_loss: 3.0224 - val_accuracy: 0.0548\n",
      "Epoch 69/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9667 - accuracy: 0.0719 - val_loss: 3.0190 - val_accuracy: 0.0517\n",
      "Epoch 70/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9655 - accuracy: 0.0714 - val_loss: 3.0188 - val_accuracy: 0.0515\n",
      "Epoch 71/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9638 - accuracy: 0.0741 - val_loss: 3.0304 - val_accuracy: 0.0539\n",
      "Epoch 72/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9624 - accuracy: 0.0756 - val_loss: 3.0278 - val_accuracy: 0.0522\n",
      "Epoch 73/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9603 - accuracy: 0.0761 - val_loss: 3.0317 - val_accuracy: 0.0537\n",
      "Epoch 74/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9588 - accuracy: 0.0758 - val_loss: 3.0245 - val_accuracy: 0.0500\n",
      "Epoch 75/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9565 - accuracy: 0.0755 - val_loss: 3.0246 - val_accuracy: 0.0520\n",
      "Epoch 76/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9548 - accuracy: 0.0775 - val_loss: 3.0365 - val_accuracy: 0.0500\n",
      "Epoch 77/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9535 - accuracy: 0.0766 - val_loss: 3.0273 - val_accuracy: 0.0554\n",
      "Epoch 78/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9508 - accuracy: 0.0798 - val_loss: 3.0300 - val_accuracy: 0.0494\n",
      "Epoch 79/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9485 - accuracy: 0.0809 - val_loss: 3.0391 - val_accuracy: 0.0511\n",
      "Epoch 80/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9479 - accuracy: 0.0799 - val_loss: 3.0433 - val_accuracy: 0.0511\n",
      "Epoch 81/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9446 - accuracy: 0.0796 - val_loss: 3.0559 - val_accuracy: 0.0478\n",
      "Epoch 82/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9422 - accuracy: 0.0826 - val_loss: 3.0447 - val_accuracy: 0.0470\n",
      "Epoch 83/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9400 - accuracy: 0.0817 - val_loss: 3.0432 - val_accuracy: 0.0472\n",
      "Epoch 84/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9392 - accuracy: 0.0831 - val_loss: 3.0416 - val_accuracy: 0.0472\n",
      "Epoch 85/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9351 - accuracy: 0.0854 - val_loss: 3.0486 - val_accuracy: 0.0498\n",
      "Epoch 86/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9338 - accuracy: 0.0861 - val_loss: 3.0497 - val_accuracy: 0.0496\n",
      "Epoch 87/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9313 - accuracy: 0.0871 - val_loss: 3.0518 - val_accuracy: 0.0513\n",
      "Epoch 88/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9305 - accuracy: 0.0863 - val_loss: 3.0544 - val_accuracy: 0.0502\n",
      "Epoch 89/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9265 - accuracy: 0.0872 - val_loss: 3.0593 - val_accuracy: 0.0494\n",
      "Epoch 90/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9245 - accuracy: 0.0883 - val_loss: 3.0660 - val_accuracy: 0.0481\n",
      "Epoch 91/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9231 - accuracy: 0.0887 - val_loss: 3.0712 - val_accuracy: 0.0517\n",
      "Epoch 92/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9206 - accuracy: 0.0911 - val_loss: 3.0546 - val_accuracy: 0.0517\n",
      "Epoch 93/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9183 - accuracy: 0.0893 - val_loss: 3.0701 - val_accuracy: 0.0463\n",
      "Epoch 94/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9154 - accuracy: 0.0912 - val_loss: 3.0605 - val_accuracy: 0.0489\n",
      "Epoch 95/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9121 - accuracy: 0.0920 - val_loss: 3.0608 - val_accuracy: 0.0509\n",
      "Epoch 96/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9120 - accuracy: 0.0937 - val_loss: 3.0682 - val_accuracy: 0.0500\n",
      "Epoch 97/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9086 - accuracy: 0.0941 - val_loss: 3.0824 - val_accuracy: 0.0537\n",
      "Epoch 98/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9056 - accuracy: 0.0949 - val_loss: 3.0752 - val_accuracy: 0.0491\n",
      "Epoch 99/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9028 - accuracy: 0.0961 - val_loss: 3.0774 - val_accuracy: 0.0546\n",
      "Epoch 100/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.9003 - accuracy: 0.0955 - val_loss: 3.0929 - val_accuracy: 0.0491\n",
      "Epoch 101/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.8986 - accuracy: 0.0977 - val_loss: 3.0866 - val_accuracy: 0.0528\n",
      "Epoch 102/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.8964 - accuracy: 0.0982 - val_loss: 3.0866 - val_accuracy: 0.0528\n",
      "Epoch 103/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.8927 - accuracy: 0.0992 - val_loss: 3.0853 - val_accuracy: 0.0511\n",
      "Epoch 104/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.8911 - accuracy: 0.0984 - val_loss: 3.0907 - val_accuracy: 0.0524\n",
      "Epoch 105/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.8890 - accuracy: 0.1001 - val_loss: 3.0988 - val_accuracy: 0.0528\n",
      "Epoch 106/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.8862 - accuracy: 0.1024 - val_loss: 3.0837 - val_accuracy: 0.0504\n",
      "Epoch 107/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.8843 - accuracy: 0.1022 - val_loss: 3.0958 - val_accuracy: 0.0498\n",
      "Epoch 108/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.8841 - accuracy: 0.1014 - val_loss: 3.0933 - val_accuracy: 0.0494\n",
      "Epoch 109/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.8795 - accuracy: 0.1035 - val_loss: 3.1046 - val_accuracy: 0.0563\n",
      "Epoch 110/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.8749 - accuracy: 0.1039 - val_loss: 3.1045 - val_accuracy: 0.0533\n",
      "Epoch 111/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.8745 - accuracy: 0.1034 - val_loss: 3.1193 - val_accuracy: 0.0498\n",
      "Epoch 112/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.8732 - accuracy: 0.1043 - val_loss: 3.1017 - val_accuracy: 0.0520\n",
      "Epoch 113/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.8701 - accuracy: 0.1055 - val_loss: 3.1063 - val_accuracy: 0.0517\n",
      "Epoch 114/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.8648 - accuracy: 0.1088 - val_loss: 3.1190 - val_accuracy: 0.0500\n",
      "Epoch 115/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.8638 - accuracy: 0.1093 - val_loss: 3.1193 - val_accuracy: 0.0522\n",
      "Epoch 116/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.8634 - accuracy: 0.1084 - val_loss: 3.1229 - val_accuracy: 0.0515\n",
      "Epoch 117/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.8562 - accuracy: 0.1122 - val_loss: 3.1287 - val_accuracy: 0.0491\n",
      "Epoch 118/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.8564 - accuracy: 0.1119 - val_loss: 3.1259 - val_accuracy: 0.0472\n",
      "Epoch 119/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.8519 - accuracy: 0.1132 - val_loss: 3.1323 - val_accuracy: 0.0535\n",
      "Epoch 120/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.8520 - accuracy: 0.1120 - val_loss: 3.1334 - val_accuracy: 0.0522\n",
      "Epoch 121/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.8483 - accuracy: 0.1139 - val_loss: 3.1388 - val_accuracy: 0.0541\n",
      "Epoch 122/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.8437 - accuracy: 0.1152 - val_loss: 3.1359 - val_accuracy: 0.0543\n",
      "Epoch 123/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.8417 - accuracy: 0.1172 - val_loss: 3.1303 - val_accuracy: 0.0502\n",
      "Epoch 124/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.8422 - accuracy: 0.1154 - val_loss: 3.1370 - val_accuracy: 0.0539\n",
      "Epoch 125/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.8397 - accuracy: 0.1146 - val_loss: 3.1430 - val_accuracy: 0.0489\n",
      "Epoch 126/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.8373 - accuracy: 0.1166 - val_loss: 3.1530 - val_accuracy: 0.0504\n",
      "Epoch 127/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.8322 - accuracy: 0.1199 - val_loss: 3.1507 - val_accuracy: 0.0502\n",
      "Epoch 128/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.8318 - accuracy: 0.1194 - val_loss: 3.1512 - val_accuracy: 0.0526\n",
      "Epoch 129/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.8271 - accuracy: 0.1218 - val_loss: 3.1602 - val_accuracy: 0.0470\n",
      "Epoch 130/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.8264 - accuracy: 0.1216 - val_loss: 3.1740 - val_accuracy: 0.0522\n",
      "Epoch 131/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.8311 - accuracy: 0.1179 - val_loss: 3.1593 - val_accuracy: 0.0552\n",
      "Epoch 132/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.8224 - accuracy: 0.1231 - val_loss: 3.1552 - val_accuracy: 0.0515\n",
      "Epoch 133/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.8190 - accuracy: 0.1243 - val_loss: 3.1615 - val_accuracy: 0.0476\n",
      "Epoch 134/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.8158 - accuracy: 0.1255 - val_loss: 3.1704 - val_accuracy: 0.0520\n",
      "Epoch 135/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.8143 - accuracy: 0.1247 - val_loss: 3.1647 - val_accuracy: 0.0500\n",
      "Epoch 136/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.8128 - accuracy: 0.1259 - val_loss: 3.1852 - val_accuracy: 0.0502\n",
      "Epoch 137/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.8106 - accuracy: 0.1259 - val_loss: 3.1866 - val_accuracy: 0.0515\n",
      "Epoch 138/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.8038 - accuracy: 0.1279 - val_loss: 3.1740 - val_accuracy: 0.0520\n",
      "Epoch 139/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.8007 - accuracy: 0.1294 - val_loss: 3.1952 - val_accuracy: 0.0504\n",
      "Epoch 140/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.8020 - accuracy: 0.1287 - val_loss: 3.1964 - val_accuracy: 0.0528\n",
      "Epoch 141/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.8008 - accuracy: 0.1317 - val_loss: 3.1963 - val_accuracy: 0.0509\n",
      "Epoch 142/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.7967 - accuracy: 0.1300 - val_loss: 3.1950 - val_accuracy: 0.0485\n",
      "Epoch 143/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.7936 - accuracy: 0.1307 - val_loss: 3.2009 - val_accuracy: 0.0524\n",
      "Epoch 144/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.7915 - accuracy: 0.1325 - val_loss: 3.1930 - val_accuracy: 0.0455\n",
      "Epoch 145/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.7935 - accuracy: 0.1313 - val_loss: 3.1953 - val_accuracy: 0.0533\n",
      "Epoch 146/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.7880 - accuracy: 0.1347 - val_loss: 3.1910 - val_accuracy: 0.0489\n",
      "Epoch 147/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.7883 - accuracy: 0.1362 - val_loss: 3.2043 - val_accuracy: 0.0504\n",
      "Epoch 148/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.7826 - accuracy: 0.1354 - val_loss: 3.2331 - val_accuracy: 0.0533\n",
      "Epoch 149/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.7853 - accuracy: 0.1334 - val_loss: 3.2028 - val_accuracy: 0.0502\n",
      "Epoch 150/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.7791 - accuracy: 0.1363 - val_loss: 3.2005 - val_accuracy: 0.0507\n",
      "Epoch 151/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.7767 - accuracy: 0.1375 - val_loss: 3.2160 - val_accuracy: 0.0533\n",
      "Epoch 152/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.7737 - accuracy: 0.1383 - val_loss: 3.2276 - val_accuracy: 0.0530\n",
      "Epoch 153/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.7703 - accuracy: 0.1402 - val_loss: 3.2306 - val_accuracy: 0.0535\n",
      "Epoch 154/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.7722 - accuracy: 0.1390 - val_loss: 3.2285 - val_accuracy: 0.0511\n",
      "Epoch 155/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.7703 - accuracy: 0.1378 - val_loss: 3.2296 - val_accuracy: 0.0502\n",
      "Epoch 156/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.7696 - accuracy: 0.1388 - val_loss: 3.2310 - val_accuracy: 0.0511\n",
      "Epoch 157/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.7625 - accuracy: 0.1413 - val_loss: 3.2275 - val_accuracy: 0.0528\n",
      "Epoch 158/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.7606 - accuracy: 0.1397 - val_loss: 3.2436 - val_accuracy: 0.0511\n",
      "Epoch 159/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.7592 - accuracy: 0.1445 - val_loss: 3.2442 - val_accuracy: 0.0539\n",
      "Epoch 160/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.7555 - accuracy: 0.1441 - val_loss: 3.2387 - val_accuracy: 0.0539\n",
      "Epoch 161/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.7548 - accuracy: 0.1429 - val_loss: 3.2223 - val_accuracy: 0.0530\n",
      "Epoch 162/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.7513 - accuracy: 0.1463 - val_loss: 3.2401 - val_accuracy: 0.0513\n",
      "Epoch 163/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.7494 - accuracy: 0.1474 - val_loss: 3.2381 - val_accuracy: 0.0485\n",
      "Epoch 164/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.7506 - accuracy: 0.1445 - val_loss: 3.2596 - val_accuracy: 0.0485\n",
      "Epoch 165/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.7464 - accuracy: 0.1480 - val_loss: 3.2656 - val_accuracy: 0.0502\n",
      "Epoch 166/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.7522 - accuracy: 0.1448 - val_loss: 3.2744 - val_accuracy: 0.0530\n",
      "Epoch 167/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.7421 - accuracy: 0.1500 - val_loss: 3.2734 - val_accuracy: 0.0543\n",
      "Epoch 168/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.7437 - accuracy: 0.1466 - val_loss: 3.2709 - val_accuracy: 0.0530\n",
      "Epoch 169/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.7394 - accuracy: 0.1491 - val_loss: 3.2678 - val_accuracy: 0.0513\n",
      "Epoch 170/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.7339 - accuracy: 0.1504 - val_loss: 3.2830 - val_accuracy: 0.0502\n",
      "Epoch 171/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.7327 - accuracy: 0.1528 - val_loss: 3.2576 - val_accuracy: 0.0533\n",
      "Epoch 172/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.7364 - accuracy: 0.1509 - val_loss: 3.2471 - val_accuracy: 0.0487\n",
      "Epoch 173/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.7330 - accuracy: 0.1519 - val_loss: 3.2834 - val_accuracy: 0.0507\n",
      "Epoch 174/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.7275 - accuracy: 0.1520 - val_loss: 3.2863 - val_accuracy: 0.0498\n",
      "Epoch 175/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.7299 - accuracy: 0.1510 - val_loss: 3.2869 - val_accuracy: 0.0522\n",
      "Epoch 176/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.7230 - accuracy: 0.1550 - val_loss: 3.2805 - val_accuracy: 0.0533\n",
      "Epoch 177/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.7254 - accuracy: 0.1533 - val_loss: 3.3260 - val_accuracy: 0.0520\n",
      "Epoch 178/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.7232 - accuracy: 0.1541 - val_loss: 3.2828 - val_accuracy: 0.0491\n",
      "Epoch 179/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.7193 - accuracy: 0.1561 - val_loss: 3.2995 - val_accuracy: 0.0465\n",
      "Epoch 180/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.7205 - accuracy: 0.1566 - val_loss: 3.2918 - val_accuracy: 0.0509\n",
      "Epoch 181/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.7126 - accuracy: 0.1569 - val_loss: 3.3099 - val_accuracy: 0.0498\n",
      "Epoch 182/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.7101 - accuracy: 0.1586 - val_loss: 3.3085 - val_accuracy: 0.0515\n",
      "Epoch 183/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.7069 - accuracy: 0.1592 - val_loss: 3.3023 - val_accuracy: 0.0522\n",
      "Epoch 184/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.7106 - accuracy: 0.1566 - val_loss: 3.2899 - val_accuracy: 0.0528\n",
      "Epoch 185/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.7141 - accuracy: 0.1558 - val_loss: 3.2977 - val_accuracy: 0.0502\n",
      "Epoch 186/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.7065 - accuracy: 0.1587 - val_loss: 3.3413 - val_accuracy: 0.0541\n",
      "Epoch 187/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.7018 - accuracy: 0.1628 - val_loss: 3.3013 - val_accuracy: 0.0496\n",
      "Epoch 188/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.7008 - accuracy: 0.1596 - val_loss: 3.3341 - val_accuracy: 0.0511\n",
      "Epoch 189/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.7013 - accuracy: 0.1616 - val_loss: 3.3455 - val_accuracy: 0.0520\n",
      "Epoch 190/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.6953 - accuracy: 0.1631 - val_loss: 3.3440 - val_accuracy: 0.0520\n",
      "Epoch 191/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.6986 - accuracy: 0.1618 - val_loss: 3.3398 - val_accuracy: 0.0537\n",
      "Epoch 192/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.6984 - accuracy: 0.1620 - val_loss: 3.3343 - val_accuracy: 0.0522\n",
      "Epoch 193/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.6893 - accuracy: 0.1636 - val_loss: 3.3466 - val_accuracy: 0.0502\n",
      "Epoch 194/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.6880 - accuracy: 0.1657 - val_loss: 3.3173 - val_accuracy: 0.0509\n",
      "Epoch 195/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.6851 - accuracy: 0.1648 - val_loss: 3.3296 - val_accuracy: 0.0539\n",
      "Epoch 196/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.6899 - accuracy: 0.1642 - val_loss: 3.3282 - val_accuracy: 0.0500\n",
      "Epoch 197/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.6828 - accuracy: 0.1680 - val_loss: 3.3630 - val_accuracy: 0.0502\n",
      "Epoch 198/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.6918 - accuracy: 0.1636 - val_loss: 3.3610 - val_accuracy: 0.0496\n",
      "Epoch 199/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.6854 - accuracy: 0.1667 - val_loss: 3.3370 - val_accuracy: 0.0496\n",
      "Epoch 200/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.6815 - accuracy: 0.1676 - val_loss: 3.3817 - val_accuracy: 0.0515\n",
      "Epoch 201/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.6778 - accuracy: 0.1704 - val_loss: 3.3601 - val_accuracy: 0.0500\n",
      "Epoch 202/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.6775 - accuracy: 0.1679 - val_loss: 3.3719 - val_accuracy: 0.0496\n",
      "Epoch 203/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.6741 - accuracy: 0.1701 - val_loss: 3.3528 - val_accuracy: 0.0502\n",
      "Epoch 204/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.6746 - accuracy: 0.1707 - val_loss: 3.3770 - val_accuracy: 0.0489\n",
      "Epoch 205/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.6761 - accuracy: 0.1687 - val_loss: 3.3478 - val_accuracy: 0.0509\n",
      "Epoch 206/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.6763 - accuracy: 0.1689 - val_loss: 3.3971 - val_accuracy: 0.0468\n",
      "Epoch 207/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.6735 - accuracy: 0.1698 - val_loss: 3.3832 - val_accuracy: 0.0528\n",
      "Epoch 208/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.6757 - accuracy: 0.1685 - val_loss: 3.3702 - val_accuracy: 0.0509\n",
      "Epoch 209/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.6728 - accuracy: 0.1686 - val_loss: 3.3896 - val_accuracy: 0.0539\n",
      "Epoch 210/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.6690 - accuracy: 0.1716 - val_loss: 3.3865 - val_accuracy: 0.0459\n",
      "Epoch 211/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.6616 - accuracy: 0.1739 - val_loss: 3.3969 - val_accuracy: 0.0511\n",
      "Epoch 212/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.6854 - accuracy: 0.1660 - val_loss: 3.3673 - val_accuracy: 0.0500\n",
      "Epoch 213/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.6605 - accuracy: 0.1737 - val_loss: 3.3589 - val_accuracy: 0.0526\n",
      "Epoch 214/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.6585 - accuracy: 0.1732 - val_loss: 3.3853 - val_accuracy: 0.0500\n",
      "Epoch 215/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.6635 - accuracy: 0.1719 - val_loss: 3.4175 - val_accuracy: 0.0500\n",
      "Epoch 216/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.6594 - accuracy: 0.1729 - val_loss: 3.4121 - val_accuracy: 0.0526\n",
      "Epoch 217/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.6496 - accuracy: 0.1762 - val_loss: 3.4239 - val_accuracy: 0.0474\n",
      "Epoch 218/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.6685 - accuracy: 0.1718 - val_loss: 3.4196 - val_accuracy: 0.0554\n",
      "Epoch 219/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.6489 - accuracy: 0.1777 - val_loss: 3.4213 - val_accuracy: 0.0507\n",
      "Epoch 220/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.6442 - accuracy: 0.1782 - val_loss: 3.4498 - val_accuracy: 0.0504\n",
      "Epoch 221/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.6650 - accuracy: 0.1720 - val_loss: 3.3919 - val_accuracy: 0.0485\n",
      "Epoch 222/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.6541 - accuracy: 0.1792 - val_loss: 3.3794 - val_accuracy: 0.0522\n",
      "Epoch 223/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.6464 - accuracy: 0.1757 - val_loss: 3.3916 - val_accuracy: 0.0500\n",
      "Epoch 224/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.6454 - accuracy: 0.1783 - val_loss: 3.4015 - val_accuracy: 0.0494\n",
      "Epoch 225/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.6396 - accuracy: 0.1801 - val_loss: 3.3771 - val_accuracy: 0.0509\n",
      "Epoch 226/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.6458 - accuracy: 0.1767 - val_loss: 3.4237 - val_accuracy: 0.0452\n",
      "Epoch 227/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.6279 - accuracy: 0.1827 - val_loss: 3.4538 - val_accuracy: 0.0533\n",
      "Epoch 228/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.6354 - accuracy: 0.1805 - val_loss: 3.4405 - val_accuracy: 0.0511\n",
      "Epoch 229/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.6315 - accuracy: 0.1815 - val_loss: 3.4453 - val_accuracy: 0.0496\n",
      "Epoch 230/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.6306 - accuracy: 0.1816 - val_loss: 3.4769 - val_accuracy: 0.0478\n",
      "Epoch 231/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.6396 - accuracy: 0.1808 - val_loss: 3.4838 - val_accuracy: 0.0481\n",
      "Epoch 232/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 2.6333 - accuracy: 0.1809 - val_loss: 3.4523 - val_accuracy: 0.0502\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([LSTM(64, input_shape=(32, 20)),\n",
    "                    Dense(64, activation='sigmoid'),\n",
    "                    Dense(20, activation='softmax')])\n",
    "train(model=model,\n",
    "      patience_train=5,\n",
    "      patience_val=None,\n",
    "      learning_rate=.001,\n",
    "      epochs=1000,\n",
    "      batch_size=128,\n",
    "      # cont_train=True,\n",
    "      )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1Xx2PnKs73WZ",
   "metadata": {
    "id": "1Xx2PnKs73WZ"
   },
   "source": [
    "## 4 layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "mS4ugzu473G3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 86342,
     "status": "ok",
     "timestamp": 1688894266333,
     "user": {
      "displayName": "Yoni Krichevsky",
      "userId": "07735752940575548299"
     },
     "user_tz": -180
    },
    "id": "mS4ugzu473G3",
    "outputId": "a6faf1c9-af5c-41cf-9c11-9361c32aa995"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patience_train=5, patience_val=None, learning_rate=0.001, epochs=1000, batch_size=128, cont_train=False, X_train.shape=(33566, 32, 20), y_train.shape=(33566,), X_val.shape=(4619, 32, 20), y_val.shape=(4619,)\n",
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_10 (LSTM)              (None, 32, 128)           76288     \n",
      "                                                                 \n",
      " lstm_11 (LSTM)              (None, 128)               131584    \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 20)                2580      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 243,476\n",
      "Trainable params: 243,476\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Input shape (None, 32, 20), output shape (None, 20)\n",
      "Epoch 1/1000\n",
      "263/263 [==============================] - 6s 10ms/step - loss: 3.0063 - accuracy: 0.0502 - val_loss: 3.0034 - val_accuracy: 0.0478\n",
      "Epoch 2/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 3.0026 - accuracy: 0.0514 - val_loss: 3.0027 - val_accuracy: 0.0502\n",
      "Epoch 3/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 3.0028 - accuracy: 0.0500 - val_loss: 3.0015 - val_accuracy: 0.0504\n",
      "Epoch 4/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 3.0017 - accuracy: 0.0503 - val_loss: 3.0119 - val_accuracy: 0.0463\n",
      "Epoch 5/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 3.0008 - accuracy: 0.0486 - val_loss: 2.9997 - val_accuracy: 0.0463\n",
      "Epoch 6/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 2.9990 - accuracy: 0.0502 - val_loss: 2.9986 - val_accuracy: 0.0463\n",
      "Epoch 7/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.9981 - accuracy: 0.0495 - val_loss: 3.0001 - val_accuracy: 0.0463\n",
      "Epoch 8/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.9974 - accuracy: 0.0498 - val_loss: 2.9972 - val_accuracy: 0.0504\n",
      "Epoch 9/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.9967 - accuracy: 0.0501 - val_loss: 2.9964 - val_accuracy: 0.0509\n",
      "Epoch 10/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.9962 - accuracy: 0.0501 - val_loss: 2.9961 - val_accuracy: 0.0487\n",
      "Epoch 11/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.9961 - accuracy: 0.0499 - val_loss: 2.9957 - val_accuracy: 0.0520\n",
      "Epoch 12/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.9959 - accuracy: 0.0504 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 13/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.9958 - accuracy: 0.0512 - val_loss: 2.9958 - val_accuracy: 0.0517\n",
      "Epoch 14/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 2.9958 - accuracy: 0.0512 - val_loss: 2.9958 - val_accuracy: 0.0517\n",
      "Epoch 15/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.9958 - accuracy: 0.0504 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 16/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.9958 - accuracy: 0.0502 - val_loss: 2.9960 - val_accuracy: 0.0517\n",
      "Epoch 17/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.9958 - accuracy: 0.0511 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 18/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.9958 - accuracy: 0.0496 - val_loss: 2.9958 - val_accuracy: 0.0517\n",
      "Epoch 19/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.9957 - accuracy: 0.0496 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 20/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.9957 - accuracy: 0.0506 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 21/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.9958 - accuracy: 0.0510 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 22/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.9957 - accuracy: 0.0506 - val_loss: 2.9958 - val_accuracy: 0.0517\n",
      "Epoch 23/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.9958 - accuracy: 0.0494 - val_loss: 2.9958 - val_accuracy: 0.0517\n",
      "Epoch 24/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.9957 - accuracy: 0.0502 - val_loss: 2.9958 - val_accuracy: 0.0517\n",
      "Epoch 25/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.9957 - accuracy: 0.0505 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 26/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.9957 - accuracy: 0.0489 - val_loss: 2.9960 - val_accuracy: 0.0517\n",
      "Epoch 27/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.9957 - accuracy: 0.0496 - val_loss: 2.9959 - val_accuracy: 0.0522\n",
      "Epoch 28/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.9957 - accuracy: 0.0516 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 29/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.9957 - accuracy: 0.0505 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 30/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.9957 - accuracy: 0.0500 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 31/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.9957 - accuracy: 0.0501 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 32/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.9957 - accuracy: 0.0505 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 33/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.9957 - accuracy: 0.0506 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 34/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 35/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.9957 - accuracy: 0.0493 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 36/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.9957 - accuracy: 0.0509 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 37/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.9957 - accuracy: 0.0504 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 38/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.9957 - accuracy: 0.0492 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 39/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.9957 - accuracy: 0.0513 - val_loss: 2.9959 - val_accuracy: 0.0522\n",
      "Epoch 40/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.9957 - accuracy: 0.0504 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 41/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.9957 - accuracy: 0.0512 - val_loss: 2.9959 - val_accuracy: 0.0522\n",
      "Epoch 42/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.9957 - accuracy: 0.0487 - val_loss: 2.9959 - val_accuracy: 0.0522\n",
      "Epoch 43/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.9957 - accuracy: 0.0491 - val_loss: 2.9960 - val_accuracy: 0.0517\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([LSTM(128, input_shape=(32, 20), return_sequences=True),\n",
    "                    LSTM(128, input_shape=(32, 20)),\n",
    "                    Dense(128, activation='sigmoid'),\n",
    "                    Dense(128, activation='sigmoid'),\n",
    "                    Dense(20, activation='softmax')])\n",
    "train(model=model,\n",
    "      patience_train=5,\n",
    "      patience_val=None,\n",
    "      learning_rate=.001,\n",
    "      epochs=1000,\n",
    "      batch_size=128,\n",
    "      # cont_train=True,\n",
    "      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "X5W-c2ut8839",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 400967,
     "status": "ok",
     "timestamp": 1688894841512,
     "user": {
      "displayName": "Yoni Krichevsky",
      "userId": "07735752940575548299"
     },
     "user_tz": -180
    },
    "id": "X5W-c2ut8839",
    "outputId": "6026d596-c641-472e-dd5d-58bd69582908"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patience_train=5, patience_val=None, learning_rate=0.001, epochs=1000, batch_size=128, cont_train=False, X_train.shape=(33566, 32, 20), y_train.shape=(33566,), X_val.shape=(4619, 32, 20), y_val.shape=(4619,)\n",
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_12 (LSTM)              (None, 32, 64)            21760     \n",
      "                                                                 \n",
      " lstm_13 (LSTM)              (None, 64)                33024     \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 20)                1300      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 64,404\n",
      "Trainable params: 64,404\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Input shape (None, 32, 20), output shape (None, 20)\n",
      "Epoch 1/1000\n",
      "263/263 [==============================] - 6s 10ms/step - loss: 3.0019 - accuracy: 0.0501 - val_loss: 3.0021 - val_accuracy: 0.0522\n",
      "Epoch 2/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.9996 - accuracy: 0.0503 - val_loss: 2.9994 - val_accuracy: 0.0522\n",
      "Epoch 3/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.9993 - accuracy: 0.0506 - val_loss: 2.9992 - val_accuracy: 0.0507\n",
      "Epoch 4/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 3.0001 - accuracy: 0.0475 - val_loss: 2.9982 - val_accuracy: 0.0474\n",
      "Epoch 5/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.9991 - accuracy: 0.0496 - val_loss: 2.9985 - val_accuracy: 0.0483\n",
      "Epoch 6/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.9985 - accuracy: 0.0515 - val_loss: 3.0002 - val_accuracy: 0.0520\n",
      "Epoch 7/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.9979 - accuracy: 0.0510 - val_loss: 2.9991 - val_accuracy: 0.0543\n",
      "Epoch 8/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.9979 - accuracy: 0.0500 - val_loss: 2.9989 - val_accuracy: 0.0472\n",
      "Epoch 9/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.9977 - accuracy: 0.0472 - val_loss: 2.9972 - val_accuracy: 0.0485\n",
      "Epoch 10/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.9978 - accuracy: 0.0505 - val_loss: 2.9984 - val_accuracy: 0.0494\n",
      "Epoch 11/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.9971 - accuracy: 0.0508 - val_loss: 2.9978 - val_accuracy: 0.0507\n",
      "Epoch 12/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.9971 - accuracy: 0.0523 - val_loss: 2.9970 - val_accuracy: 0.0537\n",
      "Epoch 13/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.9971 - accuracy: 0.0518 - val_loss: 2.9964 - val_accuracy: 0.0522\n",
      "Epoch 14/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.9965 - accuracy: 0.0511 - val_loss: 2.9969 - val_accuracy: 0.0485\n",
      "Epoch 15/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.9963 - accuracy: 0.0499 - val_loss: 2.9962 - val_accuracy: 0.0461\n",
      "Epoch 16/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.9961 - accuracy: 0.0497 - val_loss: 2.9962 - val_accuracy: 0.0476\n",
      "Epoch 17/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.9960 - accuracy: 0.0498 - val_loss: 2.9963 - val_accuracy: 0.0487\n",
      "Epoch 18/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.9960 - accuracy: 0.0512 - val_loss: 2.9961 - val_accuracy: 0.0468\n",
      "Epoch 19/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.9959 - accuracy: 0.0519 - val_loss: 2.9960 - val_accuracy: 0.0515\n",
      "Epoch 20/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.9959 - accuracy: 0.0507 - val_loss: 2.9958 - val_accuracy: 0.0507\n",
      "Epoch 21/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.9957 - accuracy: 0.0514 - val_loss: 2.9962 - val_accuracy: 0.0537\n",
      "Epoch 22/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.9958 - accuracy: 0.0516 - val_loss: 2.9960 - val_accuracy: 0.0552\n",
      "Epoch 23/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.9957 - accuracy: 0.0515 - val_loss: 2.9960 - val_accuracy: 0.0515\n",
      "Epoch 24/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.9956 - accuracy: 0.0526 - val_loss: 2.9962 - val_accuracy: 0.0541\n",
      "Epoch 25/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.9956 - accuracy: 0.0518 - val_loss: 2.9962 - val_accuracy: 0.0502\n",
      "Epoch 26/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.9956 - accuracy: 0.0504 - val_loss: 2.9962 - val_accuracy: 0.0546\n",
      "Epoch 27/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.9955 - accuracy: 0.0527 - val_loss: 2.9961 - val_accuracy: 0.0491\n",
      "Epoch 28/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.9955 - accuracy: 0.0515 - val_loss: 2.9966 - val_accuracy: 0.0487\n",
      "Epoch 29/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.9955 - accuracy: 0.0517 - val_loss: 2.9964 - val_accuracy: 0.0543\n",
      "Epoch 30/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.9954 - accuracy: 0.0516 - val_loss: 2.9964 - val_accuracy: 0.0507\n",
      "Epoch 31/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.9954 - accuracy: 0.0520 - val_loss: 2.9962 - val_accuracy: 0.0485\n",
      "Epoch 32/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.9952 - accuracy: 0.0522 - val_loss: 2.9965 - val_accuracy: 0.0483\n",
      "Epoch 33/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.9951 - accuracy: 0.0512 - val_loss: 2.9970 - val_accuracy: 0.0502\n",
      "Epoch 34/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.9951 - accuracy: 0.0535 - val_loss: 2.9967 - val_accuracy: 0.0515\n",
      "Epoch 35/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.9952 - accuracy: 0.0525 - val_loss: 2.9964 - val_accuracy: 0.0481\n",
      "Epoch 36/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.9949 - accuracy: 0.0537 - val_loss: 2.9965 - val_accuracy: 0.0541\n",
      "Epoch 37/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.9948 - accuracy: 0.0534 - val_loss: 2.9969 - val_accuracy: 0.0522\n",
      "Epoch 38/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.9948 - accuracy: 0.0550 - val_loss: 2.9969 - val_accuracy: 0.0500\n",
      "Epoch 39/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.9945 - accuracy: 0.0554 - val_loss: 2.9967 - val_accuracy: 0.0530\n",
      "Epoch 40/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.9945 - accuracy: 0.0561 - val_loss: 2.9971 - val_accuracy: 0.0491\n",
      "Epoch 41/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.9944 - accuracy: 0.0548 - val_loss: 2.9978 - val_accuracy: 0.0474\n",
      "Epoch 42/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.9943 - accuracy: 0.0561 - val_loss: 2.9976 - val_accuracy: 0.0533\n",
      "Epoch 43/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.9940 - accuracy: 0.0554 - val_loss: 2.9987 - val_accuracy: 0.0500\n",
      "Epoch 44/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.9937 - accuracy: 0.0549 - val_loss: 2.9975 - val_accuracy: 0.0491\n",
      "Epoch 45/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.9938 - accuracy: 0.0556 - val_loss: 2.9982 - val_accuracy: 0.0509\n",
      "Epoch 46/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.9936 - accuracy: 0.0572 - val_loss: 2.9974 - val_accuracy: 0.0526\n",
      "Epoch 47/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.9931 - accuracy: 0.0573 - val_loss: 2.9977 - val_accuracy: 0.0511\n",
      "Epoch 48/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.9929 - accuracy: 0.0562 - val_loss: 2.9991 - val_accuracy: 0.0511\n",
      "Epoch 49/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.9927 - accuracy: 0.0557 - val_loss: 3.0006 - val_accuracy: 0.0487\n",
      "Epoch 50/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.9923 - accuracy: 0.0565 - val_loss: 2.9991 - val_accuracy: 0.0494\n",
      "Epoch 51/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.9921 - accuracy: 0.0572 - val_loss: 3.0012 - val_accuracy: 0.0491\n",
      "Epoch 52/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.9917 - accuracy: 0.0574 - val_loss: 3.0010 - val_accuracy: 0.0500\n",
      "Epoch 53/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.9915 - accuracy: 0.0589 - val_loss: 2.9993 - val_accuracy: 0.0500\n",
      "Epoch 54/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 2.9906 - accuracy: 0.0590 - val_loss: 3.0017 - val_accuracy: 0.0535\n",
      "Epoch 55/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 2.9902 - accuracy: 0.0586 - val_loss: 3.0017 - val_accuracy: 0.0500\n",
      "Epoch 56/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.9898 - accuracy: 0.0582 - val_loss: 3.0023 - val_accuracy: 0.0517\n",
      "Epoch 57/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.9887 - accuracy: 0.0612 - val_loss: 3.0048 - val_accuracy: 0.0509\n",
      "Epoch 58/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.9884 - accuracy: 0.0605 - val_loss: 3.0038 - val_accuracy: 0.0500\n",
      "Epoch 59/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.9880 - accuracy: 0.0597 - val_loss: 3.0022 - val_accuracy: 0.0498\n",
      "Epoch 60/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.9872 - accuracy: 0.0618 - val_loss: 3.0049 - val_accuracy: 0.0474\n",
      "Epoch 61/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.9863 - accuracy: 0.0618 - val_loss: 3.0049 - val_accuracy: 0.0509\n",
      "Epoch 62/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.9869 - accuracy: 0.0627 - val_loss: 3.0039 - val_accuracy: 0.0546\n",
      "Epoch 63/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.9857 - accuracy: 0.0623 - val_loss: 3.0050 - val_accuracy: 0.0498\n",
      "Epoch 64/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.9846 - accuracy: 0.0626 - val_loss: 3.0065 - val_accuracy: 0.0517\n",
      "Epoch 65/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.9842 - accuracy: 0.0627 - val_loss: 3.0056 - val_accuracy: 0.0489\n",
      "Epoch 66/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.9820 - accuracy: 0.0644 - val_loss: 3.0062 - val_accuracy: 0.0502\n",
      "Epoch 67/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.9805 - accuracy: 0.0652 - val_loss: 3.0118 - val_accuracy: 0.0481\n",
      "Epoch 68/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.9798 - accuracy: 0.0647 - val_loss: 3.0079 - val_accuracy: 0.0507\n",
      "Epoch 69/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.9787 - accuracy: 0.0647 - val_loss: 3.0192 - val_accuracy: 0.0502\n",
      "Epoch 70/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.9777 - accuracy: 0.0669 - val_loss: 3.0116 - val_accuracy: 0.0500\n",
      "Epoch 71/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.9777 - accuracy: 0.0659 - val_loss: 3.0156 - val_accuracy: 0.0496\n",
      "Epoch 72/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.9757 - accuracy: 0.0674 - val_loss: 3.0203 - val_accuracy: 0.0463\n",
      "Epoch 73/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.9742 - accuracy: 0.0666 - val_loss: 3.0211 - val_accuracy: 0.0455\n",
      "Epoch 74/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.9724 - accuracy: 0.0684 - val_loss: 3.0219 - val_accuracy: 0.0463\n",
      "Epoch 75/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.9717 - accuracy: 0.0686 - val_loss: 3.0186 - val_accuracy: 0.0491\n",
      "Epoch 76/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.9694 - accuracy: 0.0688 - val_loss: 3.0197 - val_accuracy: 0.0491\n",
      "Epoch 77/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.9687 - accuracy: 0.0693 - val_loss: 3.0240 - val_accuracy: 0.0461\n",
      "Epoch 78/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.9666 - accuracy: 0.0711 - val_loss: 3.0217 - val_accuracy: 0.0459\n",
      "Epoch 79/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.9657 - accuracy: 0.0719 - val_loss: 3.0288 - val_accuracy: 0.0543\n",
      "Epoch 80/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 2.9625 - accuracy: 0.0738 - val_loss: 3.0241 - val_accuracy: 0.0489\n",
      "Epoch 81/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.9598 - accuracy: 0.0731 - val_loss: 3.0315 - val_accuracy: 0.0474\n",
      "Epoch 82/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.9598 - accuracy: 0.0735 - val_loss: 3.0455 - val_accuracy: 0.0476\n",
      "Epoch 83/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.9576 - accuracy: 0.0736 - val_loss: 3.0309 - val_accuracy: 0.0455\n",
      "Epoch 84/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.9528 - accuracy: 0.0763 - val_loss: 3.0352 - val_accuracy: 0.0520\n",
      "Epoch 85/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.9536 - accuracy: 0.0762 - val_loss: 3.0416 - val_accuracy: 0.0478\n",
      "Epoch 86/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.9486 - accuracy: 0.0787 - val_loss: 3.0471 - val_accuracy: 0.0478\n",
      "Epoch 87/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.9469 - accuracy: 0.0784 - val_loss: 3.0433 - val_accuracy: 0.0485\n",
      "Epoch 88/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.9454 - accuracy: 0.0800 - val_loss: 3.0524 - val_accuracy: 0.0487\n",
      "Epoch 89/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.9431 - accuracy: 0.0797 - val_loss: 3.0506 - val_accuracy: 0.0485\n",
      "Epoch 90/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.9369 - accuracy: 0.0807 - val_loss: 3.0716 - val_accuracy: 0.0459\n",
      "Epoch 91/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.9346 - accuracy: 0.0829 - val_loss: 3.0597 - val_accuracy: 0.0541\n",
      "Epoch 92/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.9317 - accuracy: 0.0840 - val_loss: 3.0596 - val_accuracy: 0.0483\n",
      "Epoch 93/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.9313 - accuracy: 0.0861 - val_loss: 3.0697 - val_accuracy: 0.0511\n",
      "Epoch 94/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.9269 - accuracy: 0.0849 - val_loss: 3.0688 - val_accuracy: 0.0496\n",
      "Epoch 95/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.9250 - accuracy: 0.0856 - val_loss: 3.0704 - val_accuracy: 0.0487\n",
      "Epoch 96/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.9381 - accuracy: 0.0806 - val_loss: 3.0821 - val_accuracy: 0.0522\n",
      "Epoch 97/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.9196 - accuracy: 0.0861 - val_loss: 3.0737 - val_accuracy: 0.0470\n",
      "Epoch 98/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.9154 - accuracy: 0.0888 - val_loss: 3.0871 - val_accuracy: 0.0513\n",
      "Epoch 99/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.9129 - accuracy: 0.0901 - val_loss: 3.1052 - val_accuracy: 0.0478\n",
      "Epoch 100/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.9070 - accuracy: 0.0912 - val_loss: 3.0975 - val_accuracy: 0.0485\n",
      "Epoch 101/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.9022 - accuracy: 0.0936 - val_loss: 3.1085 - val_accuracy: 0.0494\n",
      "Epoch 102/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.8982 - accuracy: 0.0939 - val_loss: 3.1142 - val_accuracy: 0.0526\n",
      "Epoch 103/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.8908 - accuracy: 0.0959 - val_loss: 3.1323 - val_accuracy: 0.0489\n",
      "Epoch 104/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.9011 - accuracy: 0.0941 - val_loss: 3.1154 - val_accuracy: 0.0468\n",
      "Epoch 105/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.8879 - accuracy: 0.0964 - val_loss: 3.1094 - val_accuracy: 0.0476\n",
      "Epoch 106/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.8794 - accuracy: 0.1000 - val_loss: 3.1377 - val_accuracy: 0.0489\n",
      "Epoch 107/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.8786 - accuracy: 0.1007 - val_loss: 3.1241 - val_accuracy: 0.0455\n",
      "Epoch 108/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.8751 - accuracy: 0.1021 - val_loss: 3.1200 - val_accuracy: 0.0489\n",
      "Epoch 109/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.8647 - accuracy: 0.1034 - val_loss: 3.1406 - val_accuracy: 0.0489\n",
      "Epoch 110/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.8661 - accuracy: 0.1036 - val_loss: 3.1588 - val_accuracy: 0.0489\n",
      "Epoch 111/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.8593 - accuracy: 0.1060 - val_loss: 3.1736 - val_accuracy: 0.0481\n",
      "Epoch 112/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.8611 - accuracy: 0.1066 - val_loss: 3.1648 - val_accuracy: 0.0485\n",
      "Epoch 113/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.8505 - accuracy: 0.1095 - val_loss: 3.1614 - val_accuracy: 0.0487\n",
      "Epoch 114/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.8459 - accuracy: 0.1087 - val_loss: 3.1713 - val_accuracy: 0.0539\n",
      "Epoch 115/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.8408 - accuracy: 0.1093 - val_loss: 3.1795 - val_accuracy: 0.0481\n",
      "Epoch 116/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.8306 - accuracy: 0.1122 - val_loss: 3.1941 - val_accuracy: 0.0524\n",
      "Epoch 117/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.8290 - accuracy: 0.1157 - val_loss: 3.2180 - val_accuracy: 0.0507\n",
      "Epoch 118/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.8261 - accuracy: 0.1145 - val_loss: 3.2174 - val_accuracy: 0.0474\n",
      "Epoch 119/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.8192 - accuracy: 0.1174 - val_loss: 3.2612 - val_accuracy: 0.0426\n",
      "Epoch 120/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.8208 - accuracy: 0.1182 - val_loss: 3.2390 - val_accuracy: 0.0476\n",
      "Epoch 121/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.8048 - accuracy: 0.1208 - val_loss: 3.2573 - val_accuracy: 0.0507\n",
      "Epoch 122/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.8048 - accuracy: 0.1212 - val_loss: 3.2435 - val_accuracy: 0.0478\n",
      "Epoch 123/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.8004 - accuracy: 0.1228 - val_loss: 3.2733 - val_accuracy: 0.0539\n",
      "Epoch 124/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.8020 - accuracy: 0.1227 - val_loss: 3.2841 - val_accuracy: 0.0541\n",
      "Epoch 125/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.7922 - accuracy: 0.1270 - val_loss: 3.2932 - val_accuracy: 0.0485\n",
      "Epoch 126/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.7837 - accuracy: 0.1262 - val_loss: 3.2480 - val_accuracy: 0.0513\n",
      "Epoch 127/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.7913 - accuracy: 0.1265 - val_loss: 3.2634 - val_accuracy: 0.0478\n",
      "Epoch 128/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.7671 - accuracy: 0.1324 - val_loss: 3.3322 - val_accuracy: 0.0502\n",
      "Epoch 129/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.7639 - accuracy: 0.1345 - val_loss: 3.3606 - val_accuracy: 0.0500\n",
      "Epoch 130/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.7595 - accuracy: 0.1352 - val_loss: 3.3254 - val_accuracy: 0.0485\n",
      "Epoch 131/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.7692 - accuracy: 0.1341 - val_loss: 3.2934 - val_accuracy: 0.0496\n",
      "Epoch 132/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 2.7526 - accuracy: 0.1373 - val_loss: 3.3500 - val_accuracy: 0.0526\n",
      "Epoch 133/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 2.7441 - accuracy: 0.1403 - val_loss: 3.3713 - val_accuracy: 0.0504\n",
      "Epoch 134/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 2.7565 - accuracy: 0.1357 - val_loss: 3.3647 - val_accuracy: 0.0494\n",
      "Epoch 135/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.7314 - accuracy: 0.1430 - val_loss: 3.3920 - val_accuracy: 0.0517\n",
      "Epoch 136/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.7356 - accuracy: 0.1426 - val_loss: 3.4084 - val_accuracy: 0.0509\n",
      "Epoch 137/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.7261 - accuracy: 0.1431 - val_loss: 3.3974 - val_accuracy: 0.0504\n",
      "Epoch 138/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.7177 - accuracy: 0.1468 - val_loss: 3.3808 - val_accuracy: 0.0500\n",
      "Epoch 139/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.7223 - accuracy: 0.1447 - val_loss: 3.3596 - val_accuracy: 0.0504\n",
      "Epoch 140/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.7153 - accuracy: 0.1477 - val_loss: 3.4289 - val_accuracy: 0.0520\n",
      "Epoch 141/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 2.7037 - accuracy: 0.1520 - val_loss: 3.4033 - val_accuracy: 0.0524\n",
      "Epoch 142/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.7032 - accuracy: 0.1526 - val_loss: 3.4534 - val_accuracy: 0.0548\n",
      "Epoch 143/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.6914 - accuracy: 0.1569 - val_loss: 3.4894 - val_accuracy: 0.0489\n",
      "Epoch 144/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.6876 - accuracy: 0.1554 - val_loss: 3.4642 - val_accuracy: 0.0494\n",
      "Epoch 145/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.6828 - accuracy: 0.1568 - val_loss: 3.4814 - val_accuracy: 0.0522\n",
      "Epoch 146/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.6744 - accuracy: 0.1580 - val_loss: 3.5235 - val_accuracy: 0.0502\n",
      "Epoch 147/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 2.6707 - accuracy: 0.1598 - val_loss: 3.4914 - val_accuracy: 0.0511\n",
      "Epoch 148/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.6711 - accuracy: 0.1596 - val_loss: 3.5478 - val_accuracy: 0.0543\n",
      "Epoch 149/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.6549 - accuracy: 0.1641 - val_loss: 3.5417 - val_accuracy: 0.0485\n",
      "Epoch 150/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.6524 - accuracy: 0.1658 - val_loss: 3.5136 - val_accuracy: 0.0517\n",
      "Epoch 151/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.6690 - accuracy: 0.1599 - val_loss: 3.5147 - val_accuracy: 0.0517\n",
      "Epoch 152/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.6533 - accuracy: 0.1667 - val_loss: 3.5274 - val_accuracy: 0.0489\n",
      "Epoch 153/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.6547 - accuracy: 0.1679 - val_loss: 3.5452 - val_accuracy: 0.0539\n",
      "Epoch 154/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.6389 - accuracy: 0.1709 - val_loss: 3.5579 - val_accuracy: 0.0522\n",
      "Epoch 155/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.6431 - accuracy: 0.1721 - val_loss: 3.5750 - val_accuracy: 0.0481\n",
      "Epoch 156/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.6285 - accuracy: 0.1738 - val_loss: 3.5765 - val_accuracy: 0.0489\n",
      "Epoch 157/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.6115 - accuracy: 0.1773 - val_loss: 3.5387 - val_accuracy: 0.0494\n",
      "Epoch 158/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.6065 - accuracy: 0.1798 - val_loss: 3.6048 - val_accuracy: 0.0470\n",
      "Epoch 159/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.6077 - accuracy: 0.1790 - val_loss: 3.6657 - val_accuracy: 0.0535\n",
      "Epoch 160/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 2.5988 - accuracy: 0.1834 - val_loss: 3.6173 - val_accuracy: 0.0509\n",
      "Epoch 161/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 2.6043 - accuracy: 0.1794 - val_loss: 3.6445 - val_accuracy: 0.0500\n",
      "Epoch 162/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.5866 - accuracy: 0.1861 - val_loss: 3.6945 - val_accuracy: 0.0541\n",
      "Epoch 163/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.5863 - accuracy: 0.1845 - val_loss: 3.6852 - val_accuracy: 0.0496\n",
      "Epoch 164/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.6504 - accuracy: 0.1725 - val_loss: 3.2906 - val_accuracy: 0.0511\n",
      "Epoch 165/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.7129 - accuracy: 0.1507 - val_loss: 3.6782 - val_accuracy: 0.0491\n",
      "Epoch 166/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.5786 - accuracy: 0.1882 - val_loss: 3.6624 - val_accuracy: 0.0476\n",
      "Epoch 167/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.5714 - accuracy: 0.1897 - val_loss: 3.7152 - val_accuracy: 0.0504\n",
      "Epoch 168/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.5662 - accuracy: 0.1902 - val_loss: 3.7378 - val_accuracy: 0.0485\n",
      "Epoch 169/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.5764 - accuracy: 0.1887 - val_loss: 3.6871 - val_accuracy: 0.0494\n",
      "Epoch 170/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.5674 - accuracy: 0.1915 - val_loss: 3.7270 - val_accuracy: 0.0509\n",
      "Epoch 171/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.5360 - accuracy: 0.2009 - val_loss: 3.7641 - val_accuracy: 0.0528\n",
      "Epoch 172/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.5303 - accuracy: 0.2037 - val_loss: 3.7699 - val_accuracy: 0.0522\n",
      "Epoch 173/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.5557 - accuracy: 0.1963 - val_loss: 3.7493 - val_accuracy: 0.0515\n",
      "Epoch 174/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.5702 - accuracy: 0.1922 - val_loss: 3.7821 - val_accuracy: 0.0539\n",
      "Epoch 175/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.5906 - accuracy: 0.1887 - val_loss: 3.8164 - val_accuracy: 0.0487\n",
      "Epoch 176/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.5258 - accuracy: 0.2059 - val_loss: 3.7503 - val_accuracy: 0.0476\n",
      "Epoch 177/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.5315 - accuracy: 0.2020 - val_loss: 3.7762 - val_accuracy: 0.0515\n",
      "Epoch 178/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.5249 - accuracy: 0.2041 - val_loss: 3.7966 - val_accuracy: 0.0502\n",
      "Epoch 179/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.5233 - accuracy: 0.2034 - val_loss: 3.8359 - val_accuracy: 0.0533\n",
      "Epoch 180/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.5008 - accuracy: 0.2096 - val_loss: 3.8400 - val_accuracy: 0.0559\n",
      "Epoch 181/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.4952 - accuracy: 0.2121 - val_loss: 3.8243 - val_accuracy: 0.0524\n",
      "Epoch 182/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.4973 - accuracy: 0.2135 - val_loss: 3.8622 - val_accuracy: 0.0513\n",
      "Epoch 183/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.4781 - accuracy: 0.2169 - val_loss: 3.9195 - val_accuracy: 0.0576\n",
      "Epoch 184/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.4783 - accuracy: 0.2176 - val_loss: 3.9058 - val_accuracy: 0.0476\n",
      "Epoch 185/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.4940 - accuracy: 0.2135 - val_loss: 3.9043 - val_accuracy: 0.0474\n",
      "Epoch 186/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.4934 - accuracy: 0.2138 - val_loss: 3.8809 - val_accuracy: 0.0520\n",
      "Epoch 187/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 2.4698 - accuracy: 0.2196 - val_loss: 3.9101 - val_accuracy: 0.0468\n",
      "Epoch 188/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 2.4856 - accuracy: 0.2151 - val_loss: 3.9495 - val_accuracy: 0.0504\n",
      "Epoch 189/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 2.4477 - accuracy: 0.2266 - val_loss: 3.9582 - val_accuracy: 0.0515\n",
      "Epoch 190/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 2.4454 - accuracy: 0.2267 - val_loss: 3.9685 - val_accuracy: 0.0483\n",
      "Epoch 191/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 2.4666 - accuracy: 0.2230 - val_loss: 3.9154 - val_accuracy: 0.0522\n",
      "Epoch 192/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 2.4640 - accuracy: 0.2224 - val_loss: 3.9183 - val_accuracy: 0.0494\n",
      "Epoch 193/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 2.4467 - accuracy: 0.2276 - val_loss: 3.9922 - val_accuracy: 0.0491\n",
      "Epoch 194/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 2.4440 - accuracy: 0.2273 - val_loss: 4.0182 - val_accuracy: 0.0502\n",
      "Epoch 195/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 2.4271 - accuracy: 0.2315 - val_loss: 4.0365 - val_accuracy: 0.0537\n",
      "Epoch 196/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 2.4191 - accuracy: 0.2348 - val_loss: 4.0323 - val_accuracy: 0.0500\n",
      "Epoch 197/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 2.4058 - accuracy: 0.2401 - val_loss: 4.0610 - val_accuracy: 0.0498\n",
      "Epoch 198/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 2.4269 - accuracy: 0.2353 - val_loss: 3.9927 - val_accuracy: 0.0504\n",
      "Epoch 199/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 2.4237 - accuracy: 0.2349 - val_loss: 4.0636 - val_accuracy: 0.0537\n",
      "Epoch 200/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 2.4212 - accuracy: 0.2354 - val_loss: 4.0170 - val_accuracy: 0.0520\n",
      "Epoch 201/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 2.3957 - accuracy: 0.2442 - val_loss: 4.1535 - val_accuracy: 0.0513\n",
      "Epoch 202/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 2.3873 - accuracy: 0.2475 - val_loss: 4.0389 - val_accuracy: 0.0530\n",
      "Epoch 203/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 2.3928 - accuracy: 0.2439 - val_loss: 4.0785 - val_accuracy: 0.0509\n",
      "Epoch 204/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 2.3914 - accuracy: 0.2433 - val_loss: 4.1990 - val_accuracy: 0.0522\n",
      "Epoch 205/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 2.3998 - accuracy: 0.2414 - val_loss: 4.1566 - val_accuracy: 0.0491\n",
      "Epoch 206/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 2.4160 - accuracy: 0.2382 - val_loss: 4.1493 - val_accuracy: 0.0515\n",
      "Epoch 207/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 2.4004 - accuracy: 0.2418 - val_loss: 4.1682 - val_accuracy: 0.0524\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([LSTM(64, input_shape=(32, 20), return_sequences=True),\n",
    "                    LSTM(64, input_shape=(32, 20)),\n",
    "                    Dense(64, activation='sigmoid'),\n",
    "                    Dense(64, activation='sigmoid'),\n",
    "                    Dense(20, activation='softmax')])\n",
    "train(model=model,\n",
    "      patience_train=5,\n",
    "      patience_val=None,\n",
    "      learning_rate=.001,\n",
    "      epochs=1000,\n",
    "      batch_size=128,\n",
    "      # cont_train=True,\n",
    "      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "82_Zisf8-2-n",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 408,
     "status": "ok",
     "timestamp": 1688895661330,
     "user": {
      "displayName": "Yoni Krichevsky",
      "userId": "07735752940575548299"
     },
     "user_tz": -180
    },
    "id": "82_Zisf8-2-n",
    "outputId": "86ce72bd-e43c-43a5-f811-88cb2f90dd28"
   },
   "outputs": [
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patience_train=5, patience_val=None, learning_rate=0.0001, epochs=1000, batch_size=128, cont_train=False, X_train.shape=(33566, 32, 20), y_train.shape=(33566,), X_val.shape=(4619, 32, 20), y_val.shape=(4619,)\n",
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_12 (LSTM)              (None, 32, 64)            21760     \n",
      "                                                                 \n",
      " lstm_13 (LSTM)              (None, 64)                33024     \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 20)                1300      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 64,404\n",
      "Trainable params: 64,404\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Input shape (None, 32, 20), output shape (None, 20)\n",
      "Epoch 1/1000\n",
      "263/263 [==============================] - 7s 12ms/step - loss: 2.2806 - accuracy: 0.2819 - val_loss: 4.2353 - val_accuracy: 0.0530\n",
      "Epoch 2/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 2.2522 - accuracy: 0.2907 - val_loss: 4.2413 - val_accuracy: 0.0541\n",
      "Epoch 3/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 2.2414 - accuracy: 0.2949 - val_loss: 4.2602 - val_accuracy: 0.0533\n",
      "Epoch 4/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 2.2332 - accuracy: 0.2979 - val_loss: 4.2795 - val_accuracy: 0.0552\n",
      "Epoch 5/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 2.2268 - accuracy: 0.3002 - val_loss: 4.2928 - val_accuracy: 0.0526\n",
      "Epoch 6/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 2.2218 - accuracy: 0.3008 - val_loss: 4.2928 - val_accuracy: 0.0524\n",
      "Epoch 7/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 2.2167 - accuracy: 0.3032 - val_loss: 4.3238 - val_accuracy: 0.0541\n",
      "Epoch 8/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 2.2127 - accuracy: 0.3043 - val_loss: 4.3163 - val_accuracy: 0.0526\n",
      "Epoch 9/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 2.2089 - accuracy: 0.3067 - val_loss: 4.3429 - val_accuracy: 0.0515\n",
      "Epoch 10/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 2.2045 - accuracy: 0.3086 - val_loss: 4.3402 - val_accuracy: 0.0511\n",
      "Epoch 11/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.2010 - accuracy: 0.3092 - val_loss: 4.3612 - val_accuracy: 0.0520\n",
      "Epoch 12/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.1981 - accuracy: 0.3107 - val_loss: 4.3745 - val_accuracy: 0.0504\n",
      "Epoch 13/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 2.1944 - accuracy: 0.3112 - val_loss: 4.3736 - val_accuracy: 0.0500\n",
      "Epoch 14/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 2.1912 - accuracy: 0.3133 - val_loss: 4.3936 - val_accuracy: 0.0520\n",
      "Epoch 15/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 2.1882 - accuracy: 0.3136 - val_loss: 4.3907 - val_accuracy: 0.0520\n",
      "Epoch 16/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 2.1853 - accuracy: 0.3148 - val_loss: 4.3956 - val_accuracy: 0.0491\n",
      "Epoch 17/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 2.1822 - accuracy: 0.3165 - val_loss: 4.4070 - val_accuracy: 0.0494\n",
      "Epoch 18/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 2.1796 - accuracy: 0.3166 - val_loss: 4.4359 - val_accuracy: 0.0507\n",
      "Epoch 19/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 2.1774 - accuracy: 0.3174 - val_loss: 4.4327 - val_accuracy: 0.0494\n",
      "Epoch 20/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 2.1740 - accuracy: 0.3192 - val_loss: 4.4369 - val_accuracy: 0.0481\n",
      "Epoch 21/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 2.1709 - accuracy: 0.3189 - val_loss: 4.4511 - val_accuracy: 0.0498\n",
      "Epoch 22/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 2.1685 - accuracy: 0.3206 - val_loss: 4.4647 - val_accuracy: 0.0511\n",
      "Epoch 23/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 2.1659 - accuracy: 0.3210 - val_loss: 4.4730 - val_accuracy: 0.0511\n",
      "Epoch 24/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 2.1635 - accuracy: 0.3218 - val_loss: 4.4623 - val_accuracy: 0.0511\n",
      "Epoch 25/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 2.1618 - accuracy: 0.3226 - val_loss: 4.4892 - val_accuracy: 0.0491\n",
      "Epoch 26/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 2.1589 - accuracy: 0.3239 - val_loss: 4.5000 - val_accuracy: 0.0489\n",
      "Epoch 27/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 2.1562 - accuracy: 0.3238 - val_loss: 4.5097 - val_accuracy: 0.0502\n",
      "Epoch 28/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 2.1539 - accuracy: 0.3237 - val_loss: 4.5179 - val_accuracy: 0.0500\n",
      "Epoch 29/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 2.1514 - accuracy: 0.3267 - val_loss: 4.5284 - val_accuracy: 0.0507\n",
      "Epoch 30/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 2.1498 - accuracy: 0.3262 - val_loss: 4.5370 - val_accuracy: 0.0498\n",
      "Epoch 31/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 2.1476 - accuracy: 0.3270 - val_loss: 4.5482 - val_accuracy: 0.0483\n",
      "Epoch 32/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 2.1447 - accuracy: 0.3274 - val_loss: 4.5434 - val_accuracy: 0.0483\n",
      "Epoch 33/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 2.1417 - accuracy: 0.3297 - val_loss: 4.5559 - val_accuracy: 0.0485\n",
      "Epoch 34/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 2.1396 - accuracy: 0.3298 - val_loss: 4.5746 - val_accuracy: 0.0485\n",
      "Epoch 35/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 2.1376 - accuracy: 0.3314 - val_loss: 4.5762 - val_accuracy: 0.0478\n",
      "Epoch 36/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 2.1365 - accuracy: 0.3316 - val_loss: 4.5947 - val_accuracy: 0.0470\n",
      "Epoch 37/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 2.1331 - accuracy: 0.3316 - val_loss: 4.6167 - val_accuracy: 0.0504\n",
      "Epoch 38/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 2.1306 - accuracy: 0.3322 - val_loss: 4.6073 - val_accuracy: 0.0470\n",
      "Epoch 39/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 2.1315 - accuracy: 0.3314 - val_loss: 4.6071 - val_accuracy: 0.0507\n",
      "Epoch 40/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 2.1274 - accuracy: 0.3336 - val_loss: 4.6291 - val_accuracy: 0.0489\n",
      "Epoch 41/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 2.1248 - accuracy: 0.3344 - val_loss: 4.6285 - val_accuracy: 0.0483\n",
      "Epoch 42/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 2.1229 - accuracy: 0.3358 - val_loss: 4.6337 - val_accuracy: 0.0481\n",
      "Epoch 43/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 2.1207 - accuracy: 0.3358 - val_loss: 4.6522 - val_accuracy: 0.0485\n",
      "Epoch 44/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 2.1183 - accuracy: 0.3378 - val_loss: 4.6629 - val_accuracy: 0.0502\n",
      "Epoch 45/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 2.1163 - accuracy: 0.3376 - val_loss: 4.6742 - val_accuracy: 0.0520\n",
      "Epoch 46/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 2.1156 - accuracy: 0.3376 - val_loss: 4.6630 - val_accuracy: 0.0494\n",
      "Epoch 47/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 2.1146 - accuracy: 0.3389 - val_loss: 4.6949 - val_accuracy: 0.0511\n",
      "Epoch 48/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 2.1107 - accuracy: 0.3392 - val_loss: 4.6981 - val_accuracy: 0.0500\n",
      "Epoch 49/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 2.1089 - accuracy: 0.3403 - val_loss: 4.7022 - val_accuracy: 0.0513\n",
      "Epoch 50/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.1066 - accuracy: 0.3411 - val_loss: 4.7183 - val_accuracy: 0.0515\n",
      "Epoch 51/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 2.1051 - accuracy: 0.3416 - val_loss: 4.7318 - val_accuracy: 0.0515\n",
      "Epoch 52/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 2.1027 - accuracy: 0.3425 - val_loss: 4.7501 - val_accuracy: 0.0513\n",
      "Epoch 53/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 2.1001 - accuracy: 0.3434 - val_loss: 4.7402 - val_accuracy: 0.0504\n",
      "Epoch 54/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 2.0991 - accuracy: 0.3429 - val_loss: 4.7327 - val_accuracy: 0.0515\n",
      "Epoch 55/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 2.0966 - accuracy: 0.3437 - val_loss: 4.7749 - val_accuracy: 0.0517\n",
      "Epoch 56/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 2.0958 - accuracy: 0.3449 - val_loss: 4.7642 - val_accuracy: 0.0507\n",
      "Epoch 57/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 2.0930 - accuracy: 0.3443 - val_loss: 4.7623 - val_accuracy: 0.0502\n",
      "Epoch 58/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 2.0914 - accuracy: 0.3461 - val_loss: 4.7870 - val_accuracy: 0.0511\n",
      "Epoch 59/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 2.0900 - accuracy: 0.3467 - val_loss: 4.7977 - val_accuracy: 0.0487\n",
      "Epoch 60/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 2.0874 - accuracy: 0.3473 - val_loss: 4.7953 - val_accuracy: 0.0537\n",
      "Epoch 61/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 2.0860 - accuracy: 0.3480 - val_loss: 4.7971 - val_accuracy: 0.0515\n",
      "Epoch 62/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 2.0846 - accuracy: 0.3479 - val_loss: 4.8105 - val_accuracy: 0.0522\n",
      "Epoch 63/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 2.0826 - accuracy: 0.3488 - val_loss: 4.8125 - val_accuracy: 0.0541\n",
      "Epoch 64/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 2.0807 - accuracy: 0.3498 - val_loss: 4.8364 - val_accuracy: 0.0522\n",
      "Epoch 65/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 2.0778 - accuracy: 0.3506 - val_loss: 4.8456 - val_accuracy: 0.0507\n",
      "Epoch 66/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 2.0767 - accuracy: 0.3510 - val_loss: 4.8546 - val_accuracy: 0.0520\n",
      "Epoch 67/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 2.0769 - accuracy: 0.3506 - val_loss: 4.8439 - val_accuracy: 0.0517\n",
      "Epoch 68/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 2.0727 - accuracy: 0.3522 - val_loss: 4.8737 - val_accuracy: 0.0517\n",
      "Epoch 69/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 2.0710 - accuracy: 0.3533 - val_loss: 4.8913 - val_accuracy: 0.0500\n",
      "Epoch 70/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 2.0696 - accuracy: 0.3520 - val_loss: 4.8863 - val_accuracy: 0.0500\n",
      "Epoch 71/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 2.0676 - accuracy: 0.3540 - val_loss: 4.8872 - val_accuracy: 0.0513\n",
      "Epoch 72/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 2.0656 - accuracy: 0.3537 - val_loss: 4.9067 - val_accuracy: 0.0498\n",
      "Epoch 73/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 2.0644 - accuracy: 0.3550 - val_loss: 4.9142 - val_accuracy: 0.0528\n",
      "Epoch 74/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 2.0626 - accuracy: 0.3555 - val_loss: 4.9159 - val_accuracy: 0.0515\n",
      "Epoch 75/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 2.0603 - accuracy: 0.3566 - val_loss: 4.9349 - val_accuracy: 0.0530\n",
      "Epoch 76/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 2.0595 - accuracy: 0.3561 - val_loss: 4.9290 - val_accuracy: 0.0524\n",
      "Epoch 77/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 2.0574 - accuracy: 0.3568 - val_loss: 4.9385 - val_accuracy: 0.0528\n",
      "Epoch 78/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 2.0549 - accuracy: 0.3580 - val_loss: 4.9530 - val_accuracy: 0.0513\n",
      "Epoch 79/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 2.0534 - accuracy: 0.3591 - val_loss: 4.9681 - val_accuracy: 0.0528\n",
      "Epoch 80/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 2.0525 - accuracy: 0.3581 - val_loss: 4.9600 - val_accuracy: 0.0509\n",
      "Epoch 81/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 2.0508 - accuracy: 0.3605 - val_loss: 4.9733 - val_accuracy: 0.0530\n",
      "Epoch 82/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 2.0496 - accuracy: 0.3602 - val_loss: 4.9797 - val_accuracy: 0.0517\n",
      "Epoch 83/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 2.0469 - accuracy: 0.3611 - val_loss: 4.9885 - val_accuracy: 0.0520\n",
      "Epoch 84/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 2.0453 - accuracy: 0.3615 - val_loss: 4.9942 - val_accuracy: 0.0533\n",
      "Epoch 85/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 2.0442 - accuracy: 0.3617 - val_loss: 4.9950 - val_accuracy: 0.0524\n",
      "Epoch 86/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 2.0427 - accuracy: 0.3614 - val_loss: 5.0236 - val_accuracy: 0.0507\n",
      "Epoch 87/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 2.0403 - accuracy: 0.3624 - val_loss: 5.0377 - val_accuracy: 0.0511\n",
      "Epoch 88/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 2.0389 - accuracy: 0.3627 - val_loss: 5.0190 - val_accuracy: 0.0528\n",
      "Epoch 89/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 2.0374 - accuracy: 0.3649 - val_loss: 5.0326 - val_accuracy: 0.0500\n",
      "Epoch 90/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 2.0362 - accuracy: 0.3638 - val_loss: 5.0550 - val_accuracy: 0.0520\n",
      "Epoch 91/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 2.0334 - accuracy: 0.3654 - val_loss: 5.0684 - val_accuracy: 0.0522\n",
      "Epoch 92/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 2.0318 - accuracy: 0.3653 - val_loss: 5.0638 - val_accuracy: 0.0517\n",
      "Epoch 93/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 2.0323 - accuracy: 0.3661 - val_loss: 5.0645 - val_accuracy: 0.0494\n",
      "Epoch 94/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 2.0303 - accuracy: 0.3665 - val_loss: 5.0639 - val_accuracy: 0.0498\n",
      "Epoch 95/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 2.0283 - accuracy: 0.3667 - val_loss: 5.0922 - val_accuracy: 0.0515\n",
      "Epoch 96/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 2.0266 - accuracy: 0.3674 - val_loss: 5.1007 - val_accuracy: 0.0509\n",
      "Epoch 97/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 2.0245 - accuracy: 0.3681 - val_loss: 5.1079 - val_accuracy: 0.0509\n",
      "Epoch 98/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 2.0219 - accuracy: 0.3688 - val_loss: 5.1090 - val_accuracy: 0.0513\n",
      "Epoch 99/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 2.0296 - accuracy: 0.3661 - val_loss: 5.0907 - val_accuracy: 0.0515\n",
      "Epoch 100/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 2.0214 - accuracy: 0.3681 - val_loss: 5.1290 - val_accuracy: 0.0513\n",
      "Epoch 101/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 2.0177 - accuracy: 0.3697 - val_loss: 5.1392 - val_accuracy: 0.0498\n",
      "Epoch 102/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 2.0156 - accuracy: 0.3704 - val_loss: 5.1402 - val_accuracy: 0.0507\n",
      "Epoch 103/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 2.0138 - accuracy: 0.3715 - val_loss: 5.1658 - val_accuracy: 0.0498\n",
      "Epoch 104/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 2.0134 - accuracy: 0.3720 - val_loss: 5.1537 - val_accuracy: 0.0500\n",
      "Epoch 105/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 2.0132 - accuracy: 0.3718 - val_loss: 5.1454 - val_accuracy: 0.0524\n",
      "Epoch 106/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 2.0135 - accuracy: 0.3705 - val_loss: 5.1684 - val_accuracy: 0.0500\n",
      "Epoch 107/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 2.0089 - accuracy: 0.3737 - val_loss: 5.1704 - val_accuracy: 0.0511\n",
      "Epoch 108/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 2.0065 - accuracy: 0.3734 - val_loss: 5.1884 - val_accuracy: 0.0502\n",
      "Epoch 109/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 2.0060 - accuracy: 0.3737 - val_loss: 5.1950 - val_accuracy: 0.0496\n",
      "Epoch 110/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 2.0035 - accuracy: 0.3736 - val_loss: 5.1899 - val_accuracy: 0.0513\n",
      "Epoch 111/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 2.0022 - accuracy: 0.3754 - val_loss: 5.2102 - val_accuracy: 0.0522\n",
      "Epoch 112/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 2.0018 - accuracy: 0.3765 - val_loss: 5.2125 - val_accuracy: 0.0509\n",
      "Epoch 113/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 2.0003 - accuracy: 0.3764 - val_loss: 5.2180 - val_accuracy: 0.0498\n",
      "Epoch 114/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.9984 - accuracy: 0.3773 - val_loss: 5.2330 - val_accuracy: 0.0513\n",
      "Epoch 115/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 1.9985 - accuracy: 0.3761 - val_loss: 5.2324 - val_accuracy: 0.0494\n",
      "Epoch 116/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.9950 - accuracy: 0.3773 - val_loss: 5.2374 - val_accuracy: 0.0515\n",
      "Epoch 117/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.9936 - accuracy: 0.3787 - val_loss: 5.2681 - val_accuracy: 0.0513\n",
      "Epoch 118/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.9920 - accuracy: 0.3789 - val_loss: 5.2653 - val_accuracy: 0.0515\n",
      "Epoch 119/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.9923 - accuracy: 0.3782 - val_loss: 5.2895 - val_accuracy: 0.0507\n",
      "Epoch 120/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 1.9894 - accuracy: 0.3798 - val_loss: 5.2767 - val_accuracy: 0.0530\n",
      "Epoch 121/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.9890 - accuracy: 0.3802 - val_loss: 5.2747 - val_accuracy: 0.0511\n",
      "Epoch 122/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.9859 - accuracy: 0.3799 - val_loss: 5.2917 - val_accuracy: 0.0507\n",
      "Epoch 123/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.9891 - accuracy: 0.3794 - val_loss: 5.3039 - val_accuracy: 0.0491\n",
      "Epoch 124/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.9862 - accuracy: 0.3801 - val_loss: 5.3114 - val_accuracy: 0.0530\n",
      "Epoch 125/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.9827 - accuracy: 0.3821 - val_loss: 5.3084 - val_accuracy: 0.0504\n",
      "Epoch 126/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.9809 - accuracy: 0.3826 - val_loss: 5.3312 - val_accuracy: 0.0489\n",
      "Epoch 127/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 1.9788 - accuracy: 0.3835 - val_loss: 5.3226 - val_accuracy: 0.0517\n",
      "Epoch 128/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.9782 - accuracy: 0.3829 - val_loss: 5.3351 - val_accuracy: 0.0511\n",
      "Epoch 129/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 1.9764 - accuracy: 0.3838 - val_loss: 5.3456 - val_accuracy: 0.0504\n",
      "Epoch 130/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.9747 - accuracy: 0.3835 - val_loss: 5.3528 - val_accuracy: 0.0504\n",
      "Epoch 131/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.9730 - accuracy: 0.3856 - val_loss: 5.3553 - val_accuracy: 0.0520\n",
      "Epoch 132/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 1.9726 - accuracy: 0.3855 - val_loss: 5.3535 - val_accuracy: 0.0500\n",
      "Epoch 133/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 1.9714 - accuracy: 0.3866 - val_loss: 5.3710 - val_accuracy: 0.0520\n",
      "Epoch 134/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.9699 - accuracy: 0.3854 - val_loss: 5.3810 - val_accuracy: 0.0528\n",
      "Epoch 135/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.9719 - accuracy: 0.3847 - val_loss: 5.3903 - val_accuracy: 0.0498\n",
      "Epoch 136/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.9683 - accuracy: 0.3863 - val_loss: 5.3924 - val_accuracy: 0.0500\n",
      "Epoch 137/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.9648 - accuracy: 0.3881 - val_loss: 5.3971 - val_accuracy: 0.0515\n",
      "Epoch 138/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.9640 - accuracy: 0.3897 - val_loss: 5.4180 - val_accuracy: 0.0515\n",
      "Epoch 139/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.9652 - accuracy: 0.3879 - val_loss: 5.4223 - val_accuracy: 0.0504\n",
      "Epoch 140/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.9612 - accuracy: 0.3895 - val_loss: 5.4037 - val_accuracy: 0.0520\n",
      "Epoch 141/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.9598 - accuracy: 0.3902 - val_loss: 5.4206 - val_accuracy: 0.0524\n",
      "Epoch 142/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.9577 - accuracy: 0.3905 - val_loss: 5.4427 - val_accuracy: 0.0504\n",
      "Epoch 143/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.9562 - accuracy: 0.3900 - val_loss: 5.4419 - val_accuracy: 0.0526\n",
      "Epoch 144/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 1.9558 - accuracy: 0.3904 - val_loss: 5.4463 - val_accuracy: 0.0498\n",
      "Epoch 145/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.9552 - accuracy: 0.3909 - val_loss: 5.4636 - val_accuracy: 0.0504\n",
      "Epoch 146/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.9529 - accuracy: 0.3919 - val_loss: 5.4726 - val_accuracy: 0.0515\n",
      "Epoch 147/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.9523 - accuracy: 0.3915 - val_loss: 5.4676 - val_accuracy: 0.0498\n",
      "Epoch 148/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.9503 - accuracy: 0.3942 - val_loss: 5.4791 - val_accuracy: 0.0533\n",
      "Epoch 149/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.9500 - accuracy: 0.3920 - val_loss: 5.4731 - val_accuracy: 0.0546\n",
      "Epoch 150/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.9470 - accuracy: 0.3937 - val_loss: 5.4808 - val_accuracy: 0.0500\n",
      "Epoch 151/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.9460 - accuracy: 0.3951 - val_loss: 5.5171 - val_accuracy: 0.0515\n",
      "Epoch 152/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.9457 - accuracy: 0.3950 - val_loss: 5.5007 - val_accuracy: 0.0533\n",
      "Epoch 153/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.9428 - accuracy: 0.3961 - val_loss: 5.5173 - val_accuracy: 0.0517\n",
      "Epoch 154/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.9439 - accuracy: 0.3951 - val_loss: 5.5208 - val_accuracy: 0.0502\n",
      "Epoch 155/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.9416 - accuracy: 0.3957 - val_loss: 5.5419 - val_accuracy: 0.0517\n",
      "Epoch 156/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.9412 - accuracy: 0.3962 - val_loss: 5.5456 - val_accuracy: 0.0522\n",
      "Epoch 157/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.9378 - accuracy: 0.3979 - val_loss: 5.5488 - val_accuracy: 0.0513\n",
      "Epoch 158/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 1.9367 - accuracy: 0.3974 - val_loss: 5.5510 - val_accuracy: 0.0520\n",
      "Epoch 159/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.9351 - accuracy: 0.3983 - val_loss: 5.5460 - val_accuracy: 0.0515\n",
      "Epoch 160/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.9345 - accuracy: 0.3994 - val_loss: 5.5743 - val_accuracy: 0.0520\n",
      "Epoch 161/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 1.9324 - accuracy: 0.3986 - val_loss: 5.5682 - val_accuracy: 0.0546\n",
      "Epoch 162/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 1.9327 - accuracy: 0.3989 - val_loss: 5.5900 - val_accuracy: 0.0515\n",
      "Epoch 163/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.9296 - accuracy: 0.4000 - val_loss: 5.5963 - val_accuracy: 0.0528\n",
      "Epoch 164/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.9309 - accuracy: 0.3996 - val_loss: 5.5772 - val_accuracy: 0.0517\n",
      "Epoch 165/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.9283 - accuracy: 0.3997 - val_loss: 5.6042 - val_accuracy: 0.0517\n",
      "Epoch 166/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.9258 - accuracy: 0.4008 - val_loss: 5.6085 - val_accuracy: 0.0520\n",
      "Epoch 167/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 1.9254 - accuracy: 0.4011 - val_loss: 5.6225 - val_accuracy: 0.0528\n",
      "Epoch 168/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.9233 - accuracy: 0.4019 - val_loss: 5.6261 - val_accuracy: 0.0526\n",
      "Epoch 169/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.9224 - accuracy: 0.4018 - val_loss: 5.6307 - val_accuracy: 0.0526\n",
      "Epoch 170/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.9206 - accuracy: 0.4034 - val_loss: 5.6381 - val_accuracy: 0.0520\n",
      "Epoch 171/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.9214 - accuracy: 0.4035 - val_loss: 5.6433 - val_accuracy: 0.0526\n",
      "Epoch 172/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 1.9193 - accuracy: 0.4030 - val_loss: 5.6474 - val_accuracy: 0.0533\n",
      "Epoch 173/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 1.9163 - accuracy: 0.4039 - val_loss: 5.6590 - val_accuracy: 0.0520\n",
      "Epoch 174/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.9152 - accuracy: 0.4055 - val_loss: 5.6660 - val_accuracy: 0.0535\n",
      "Epoch 175/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.9152 - accuracy: 0.4052 - val_loss: 5.6763 - val_accuracy: 0.0535\n",
      "Epoch 176/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.9161 - accuracy: 0.4049 - val_loss: 5.6591 - val_accuracy: 0.0522\n",
      "Epoch 177/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.9125 - accuracy: 0.4053 - val_loss: 5.6839 - val_accuracy: 0.0511\n",
      "Epoch 178/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 1.9122 - accuracy: 0.4051 - val_loss: 5.6787 - val_accuracy: 0.0507\n",
      "Epoch 179/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.9108 - accuracy: 0.4055 - val_loss: 5.7068 - val_accuracy: 0.0517\n",
      "Epoch 180/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.9105 - accuracy: 0.4057 - val_loss: 5.7125 - val_accuracy: 0.0520\n",
      "Epoch 181/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.9067 - accuracy: 0.4077 - val_loss: 5.7406 - val_accuracy: 0.0526\n",
      "Epoch 182/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.9080 - accuracy: 0.4064 - val_loss: 5.7103 - val_accuracy: 0.0513\n",
      "Epoch 183/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.9110 - accuracy: 0.4054 - val_loss: 5.7356 - val_accuracy: 0.0522\n",
      "Epoch 184/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 1.9050 - accuracy: 0.4075 - val_loss: 5.7452 - val_accuracy: 0.0513\n",
      "Epoch 185/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.9014 - accuracy: 0.4093 - val_loss: 5.7282 - val_accuracy: 0.0537\n",
      "Epoch 186/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.9053 - accuracy: 0.4087 - val_loss: 5.7488 - val_accuracy: 0.0491\n",
      "Epoch 187/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.9016 - accuracy: 0.4080 - val_loss: 5.7429 - val_accuracy: 0.0528\n",
      "Epoch 188/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.8981 - accuracy: 0.4107 - val_loss: 5.7705 - val_accuracy: 0.0517\n",
      "Epoch 189/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 1.8972 - accuracy: 0.4103 - val_loss: 5.7690 - val_accuracy: 0.0513\n",
      "Epoch 190/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 1.8957 - accuracy: 0.4113 - val_loss: 5.7791 - val_accuracy: 0.0511\n",
      "Epoch 191/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.8951 - accuracy: 0.4118 - val_loss: 5.8020 - val_accuracy: 0.0502\n",
      "Epoch 192/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.8941 - accuracy: 0.4106 - val_loss: 5.7931 - val_accuracy: 0.0509\n",
      "Epoch 193/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.8932 - accuracy: 0.4128 - val_loss: 5.7860 - val_accuracy: 0.0530\n",
      "Epoch 194/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.8953 - accuracy: 0.4121 - val_loss: 5.7913 - val_accuracy: 0.0513\n",
      "Epoch 195/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.8896 - accuracy: 0.4132 - val_loss: 5.8142 - val_accuracy: 0.0533\n",
      "Epoch 196/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 1.8917 - accuracy: 0.4126 - val_loss: 5.8165 - val_accuracy: 0.0522\n",
      "Epoch 197/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.8887 - accuracy: 0.4132 - val_loss: 5.8142 - val_accuracy: 0.0526\n",
      "Epoch 198/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.8876 - accuracy: 0.4140 - val_loss: 5.8111 - val_accuracy: 0.0513\n",
      "Epoch 199/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 1.8866 - accuracy: 0.4144 - val_loss: 5.8533 - val_accuracy: 0.0509\n",
      "Epoch 200/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.8840 - accuracy: 0.4146 - val_loss: 5.8367 - val_accuracy: 0.0504\n",
      "Epoch 201/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.8829 - accuracy: 0.4162 - val_loss: 5.8480 - val_accuracy: 0.0517\n",
      "Epoch 202/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 1.8835 - accuracy: 0.4155 - val_loss: 5.8597 - val_accuracy: 0.0517\n",
      "Epoch 203/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.8813 - accuracy: 0.4159 - val_loss: 5.8575 - val_accuracy: 0.0515\n",
      "Epoch 204/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.8804 - accuracy: 0.4172 - val_loss: 5.8756 - val_accuracy: 0.0513\n",
      "Epoch 205/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.8791 - accuracy: 0.4160 - val_loss: 5.8893 - val_accuracy: 0.0509\n",
      "Epoch 206/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 1.8784 - accuracy: 0.4165 - val_loss: 5.8973 - val_accuracy: 0.0520\n",
      "Epoch 207/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.8768 - accuracy: 0.4172 - val_loss: 5.9084 - val_accuracy: 0.0496\n",
      "Epoch 208/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.8794 - accuracy: 0.4159 - val_loss: 5.8974 - val_accuracy: 0.0513\n",
      "Epoch 209/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.8744 - accuracy: 0.4195 - val_loss: 5.9128 - val_accuracy: 0.0520\n",
      "Epoch 210/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.8743 - accuracy: 0.4193 - val_loss: 5.9174 - val_accuracy: 0.0511\n",
      "Epoch 211/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.8725 - accuracy: 0.4193 - val_loss: 5.9280 - val_accuracy: 0.0522\n",
      "Epoch 212/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 1.8706 - accuracy: 0.4194 - val_loss: 5.9284 - val_accuracy: 0.0520\n",
      "Epoch 213/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.8704 - accuracy: 0.4190 - val_loss: 5.9188 - val_accuracy: 0.0517\n",
      "Epoch 214/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.8694 - accuracy: 0.4201 - val_loss: 5.9390 - val_accuracy: 0.0520\n",
      "Epoch 215/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.8781 - accuracy: 0.4169 - val_loss: 5.9523 - val_accuracy: 0.0513\n",
      "Epoch 216/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.8674 - accuracy: 0.4218 - val_loss: 5.9683 - val_accuracy: 0.0513\n",
      "Epoch 217/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.8641 - accuracy: 0.4215 - val_loss: 5.9618 - val_accuracy: 0.0498\n",
      "Epoch 218/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 1.8639 - accuracy: 0.4218 - val_loss: 5.9650 - val_accuracy: 0.0509\n",
      "Epoch 219/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.8622 - accuracy: 0.4222 - val_loss: 5.9791 - val_accuracy: 0.0520\n",
      "Epoch 220/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 1.8622 - accuracy: 0.4237 - val_loss: 5.9892 - val_accuracy: 0.0498\n",
      "Epoch 221/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.8600 - accuracy: 0.4230 - val_loss: 5.9802 - val_accuracy: 0.0504\n",
      "Epoch 222/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.8612 - accuracy: 0.4220 - val_loss: 5.9901 - val_accuracy: 0.0496\n",
      "Epoch 223/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.8602 - accuracy: 0.4224 - val_loss: 6.0058 - val_accuracy: 0.0491\n",
      "Epoch 224/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.8589 - accuracy: 0.4230 - val_loss: 6.0121 - val_accuracy: 0.0520\n",
      "Epoch 225/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.8567 - accuracy: 0.4249 - val_loss: 6.0239 - val_accuracy: 0.0511\n",
      "Epoch 226/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.8567 - accuracy: 0.4240 - val_loss: 6.0370 - val_accuracy: 0.0496\n",
      "Epoch 227/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.8555 - accuracy: 0.4245 - val_loss: 6.0256 - val_accuracy: 0.0494\n",
      "Epoch 228/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.8532 - accuracy: 0.4249 - val_loss: 6.0326 - val_accuracy: 0.0511\n",
      "Epoch 229/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 1.8522 - accuracy: 0.4259 - val_loss: 6.0309 - val_accuracy: 0.0509\n",
      "Epoch 230/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.8506 - accuracy: 0.4256 - val_loss: 6.0489 - val_accuracy: 0.0496\n",
      "Epoch 231/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.8550 - accuracy: 0.4233 - val_loss: 6.0473 - val_accuracy: 0.0507\n",
      "Epoch 232/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.8505 - accuracy: 0.4277 - val_loss: 6.0808 - val_accuracy: 0.0496\n",
      "Epoch 233/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.8473 - accuracy: 0.4256 - val_loss: 6.0697 - val_accuracy: 0.0515\n",
      "Epoch 234/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 1.8494 - accuracy: 0.4252 - val_loss: 6.0785 - val_accuracy: 0.0507\n",
      "Epoch 235/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 1.8478 - accuracy: 0.4269 - val_loss: 6.0746 - val_accuracy: 0.0509\n",
      "Epoch 236/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.8467 - accuracy: 0.4264 - val_loss: 6.0913 - val_accuracy: 0.0500\n",
      "Epoch 237/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.8463 - accuracy: 0.4270 - val_loss: 6.0799 - val_accuracy: 0.0504\n",
      "Epoch 238/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.8433 - accuracy: 0.4293 - val_loss: 6.1163 - val_accuracy: 0.0517\n",
      "Epoch 239/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.8443 - accuracy: 0.4284 - val_loss: 6.0880 - val_accuracy: 0.0507\n",
      "Epoch 240/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.8433 - accuracy: 0.4283 - val_loss: 6.1223 - val_accuracy: 0.0489\n",
      "Epoch 241/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.8424 - accuracy: 0.4282 - val_loss: 6.1249 - val_accuracy: 0.0498\n",
      "Epoch 242/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.8378 - accuracy: 0.4304 - val_loss: 6.1338 - val_accuracy: 0.0511\n",
      "Epoch 243/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.8362 - accuracy: 0.4317 - val_loss: 6.1320 - val_accuracy: 0.0513\n",
      "Epoch 244/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.8357 - accuracy: 0.4297 - val_loss: 6.1514 - val_accuracy: 0.0515\n",
      "Epoch 245/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.8401 - accuracy: 0.4293 - val_loss: 6.1440 - val_accuracy: 0.0500\n",
      "Epoch 246/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.8358 - accuracy: 0.4297 - val_loss: 6.1500 - val_accuracy: 0.0507\n",
      "Epoch 247/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.8366 - accuracy: 0.4313 - val_loss: 6.1594 - val_accuracy: 0.0504\n",
      "Epoch 248/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.8319 - accuracy: 0.4309 - val_loss: 6.1807 - val_accuracy: 0.0496\n",
      "Epoch 249/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.8303 - accuracy: 0.4321 - val_loss: 6.1760 - val_accuracy: 0.0487\n",
      "Epoch 250/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.8300 - accuracy: 0.4323 - val_loss: 6.1809 - val_accuracy: 0.0513\n",
      "Epoch 251/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 1.8327 - accuracy: 0.4318 - val_loss: 6.1909 - val_accuracy: 0.0498\n",
      "Epoch 252/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 1.8283 - accuracy: 0.4332 - val_loss: 6.1910 - val_accuracy: 0.0502\n",
      "Epoch 253/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 1.8291 - accuracy: 0.4329 - val_loss: 6.1852 - val_accuracy: 0.0494\n",
      "Epoch 254/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.8271 - accuracy: 0.4333 - val_loss: 6.2198 - val_accuracy: 0.0489\n",
      "Epoch 255/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.8248 - accuracy: 0.4356 - val_loss: 6.2155 - val_accuracy: 0.0498\n",
      "Epoch 256/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.8245 - accuracy: 0.4351 - val_loss: 6.2445 - val_accuracy: 0.0494\n",
      "Epoch 257/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.8274 - accuracy: 0.4328 - val_loss: 6.2171 - val_accuracy: 0.0502\n",
      "Epoch 258/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.8232 - accuracy: 0.4339 - val_loss: 6.2274 - val_accuracy: 0.0487\n",
      "Epoch 259/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.8276 - accuracy: 0.4323 - val_loss: 6.2350 - val_accuracy: 0.0504\n",
      "Epoch 260/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.8221 - accuracy: 0.4356 - val_loss: 6.2440 - val_accuracy: 0.0496\n",
      "Epoch 261/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.8198 - accuracy: 0.4365 - val_loss: 6.2677 - val_accuracy: 0.0496\n",
      "Epoch 262/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.8179 - accuracy: 0.4361 - val_loss: 6.2657 - val_accuracy: 0.0498\n",
      "Epoch 263/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 1.8181 - accuracy: 0.4359 - val_loss: 6.2504 - val_accuracy: 0.0494\n",
      "Epoch 264/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.8145 - accuracy: 0.4375 - val_loss: 6.2527 - val_accuracy: 0.0496\n",
      "Epoch 265/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.8159 - accuracy: 0.4365 - val_loss: 6.2831 - val_accuracy: 0.0500\n",
      "Epoch 266/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 1.8175 - accuracy: 0.4352 - val_loss: 6.2888 - val_accuracy: 0.0491\n",
      "Epoch 267/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.8161 - accuracy: 0.4367 - val_loss: 6.3015 - val_accuracy: 0.0470\n",
      "Epoch 268/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 1.8145 - accuracy: 0.4375 - val_loss: 6.3104 - val_accuracy: 0.0502\n",
      "Epoch 269/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 1.8105 - accuracy: 0.4390 - val_loss: 6.3039 - val_accuracy: 0.0504\n",
      "Epoch 270/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 1.8112 - accuracy: 0.4382 - val_loss: 6.3078 - val_accuracy: 0.0474\n",
      "Epoch 271/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.8104 - accuracy: 0.4388 - val_loss: 6.3087 - val_accuracy: 0.0494\n",
      "Epoch 272/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.8075 - accuracy: 0.4390 - val_loss: 6.3178 - val_accuracy: 0.0491\n",
      "Epoch 273/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.8069 - accuracy: 0.4396 - val_loss: 6.3272 - val_accuracy: 0.0491\n",
      "Epoch 274/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 1.8071 - accuracy: 0.4391 - val_loss: 6.3570 - val_accuracy: 0.0489\n",
      "Epoch 275/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 1.8075 - accuracy: 0.4393 - val_loss: 6.3507 - val_accuracy: 0.0485\n",
      "Epoch 276/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 1.8065 - accuracy: 0.4405 - val_loss: 6.3832 - val_accuracy: 0.0472\n",
      "Epoch 277/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.8054 - accuracy: 0.4402 - val_loss: 6.3684 - val_accuracy: 0.0489\n",
      "Epoch 278/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.8027 - accuracy: 0.4410 - val_loss: 6.3437 - val_accuracy: 0.0487\n",
      "Epoch 279/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 1.8016 - accuracy: 0.4418 - val_loss: 6.3655 - val_accuracy: 0.0472\n",
      "Epoch 280/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 1.8012 - accuracy: 0.4411 - val_loss: 6.3819 - val_accuracy: 0.0494\n",
      "Epoch 281/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.7995 - accuracy: 0.4415 - val_loss: 6.4103 - val_accuracy: 0.0470\n",
      "Epoch 282/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.7971 - accuracy: 0.4433 - val_loss: 6.3928 - val_accuracy: 0.0483\n",
      "Epoch 283/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.7988 - accuracy: 0.4427 - val_loss: 6.4110 - val_accuracy: 0.0491\n",
      "Epoch 284/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.7989 - accuracy: 0.4429 - val_loss: 6.4095 - val_accuracy: 0.0494\n",
      "Epoch 285/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 1.8014 - accuracy: 0.4409 - val_loss: 6.4153 - val_accuracy: 0.0487\n",
      "Epoch 286/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 1.7938 - accuracy: 0.4443 - val_loss: 6.4414 - val_accuracy: 0.0496\n",
      "Epoch 287/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.7933 - accuracy: 0.4441 - val_loss: 6.4251 - val_accuracy: 0.0483\n",
      "Epoch 288/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.7931 - accuracy: 0.4430 - val_loss: 6.4402 - val_accuracy: 0.0474\n",
      "Epoch 289/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 1.7966 - accuracy: 0.4424 - val_loss: 6.4492 - val_accuracy: 0.0498\n",
      "Epoch 290/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.7936 - accuracy: 0.4438 - val_loss: 6.4545 - val_accuracy: 0.0491\n",
      "Epoch 291/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 1.7921 - accuracy: 0.4438 - val_loss: 6.4609 - val_accuracy: 0.0487\n",
      "Epoch 292/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.7899 - accuracy: 0.4445 - val_loss: 6.4632 - val_accuracy: 0.0487\n",
      "Epoch 293/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.7889 - accuracy: 0.4449 - val_loss: 6.4811 - val_accuracy: 0.0496\n",
      "Epoch 294/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.7896 - accuracy: 0.4457 - val_loss: 6.5014 - val_accuracy: 0.0509\n",
      "Epoch 295/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.7919 - accuracy: 0.4453 - val_loss: 6.4793 - val_accuracy: 0.0496\n",
      "Epoch 296/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.7926 - accuracy: 0.4434 - val_loss: 6.4827 - val_accuracy: 0.0483\n",
      "Epoch 297/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 1.7851 - accuracy: 0.4478 - val_loss: 6.4897 - val_accuracy: 0.0483\n",
      "Epoch 298/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 1.7826 - accuracy: 0.4483 - val_loss: 6.4880 - val_accuracy: 0.0500\n",
      "Epoch 299/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.7869 - accuracy: 0.4473 - val_loss: 6.5139 - val_accuracy: 0.0491\n",
      "Epoch 300/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.7815 - accuracy: 0.4468 - val_loss: 6.5062 - val_accuracy: 0.0500\n",
      "Epoch 301/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.7802 - accuracy: 0.4477 - val_loss: 6.5055 - val_accuracy: 0.0489\n",
      "Epoch 302/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.7790 - accuracy: 0.4497 - val_loss: 6.5503 - val_accuracy: 0.0483\n",
      "Epoch 303/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.7761 - accuracy: 0.4496 - val_loss: 6.5263 - val_accuracy: 0.0498\n",
      "Epoch 304/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.7794 - accuracy: 0.4486 - val_loss: 6.5316 - val_accuracy: 0.0496\n",
      "Epoch 305/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.7771 - accuracy: 0.4502 - val_loss: 6.5385 - val_accuracy: 0.0487\n",
      "Epoch 306/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.7759 - accuracy: 0.4510 - val_loss: 6.5617 - val_accuracy: 0.0491\n",
      "Epoch 307/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.7751 - accuracy: 0.4504 - val_loss: 6.5443 - val_accuracy: 0.0483\n",
      "Epoch 308/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.7783 - accuracy: 0.4479 - val_loss: 6.5871 - val_accuracy: 0.0498\n",
      "Epoch 309/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.7784 - accuracy: 0.4475 - val_loss: 6.5858 - val_accuracy: 0.0513\n",
      "Epoch 310/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 1.7787 - accuracy: 0.4471 - val_loss: 6.5520 - val_accuracy: 0.0496\n",
      "Epoch 311/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.7706 - accuracy: 0.4520 - val_loss: 6.6006 - val_accuracy: 0.0494\n",
      "Epoch 312/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.7717 - accuracy: 0.4510 - val_loss: 6.5901 - val_accuracy: 0.0489\n",
      "Epoch 313/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.7854 - accuracy: 0.4450 - val_loss: 6.5941 - val_accuracy: 0.0481\n",
      "Epoch 314/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 1.7727 - accuracy: 0.4501 - val_loss: 6.5712 - val_accuracy: 0.0494\n",
      "Epoch 315/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.7658 - accuracy: 0.4525 - val_loss: 6.6029 - val_accuracy: 0.0474\n",
      "Epoch 316/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.7660 - accuracy: 0.4533 - val_loss: 6.6128 - val_accuracy: 0.0494\n",
      "Epoch 317/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 1.7671 - accuracy: 0.4510 - val_loss: 6.6110 - val_accuracy: 0.0498\n",
      "Epoch 318/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.7646 - accuracy: 0.4527 - val_loss: 6.6431 - val_accuracy: 0.0472\n",
      "Epoch 319/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.7669 - accuracy: 0.4526 - val_loss: 6.6341 - val_accuracy: 0.0494\n",
      "Epoch 320/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 1.7679 - accuracy: 0.4531 - val_loss: 6.6469 - val_accuracy: 0.0487\n",
      "Epoch 321/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.7657 - accuracy: 0.4536 - val_loss: 6.6199 - val_accuracy: 0.0502\n",
      "Epoch 322/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.7638 - accuracy: 0.4543 - val_loss: 6.6544 - val_accuracy: 0.0500\n",
      "Epoch 323/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.7603 - accuracy: 0.4551 - val_loss: 6.6524 - val_accuracy: 0.0491\n",
      "Epoch 324/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.7567 - accuracy: 0.4567 - val_loss: 6.6625 - val_accuracy: 0.0498\n",
      "Epoch 325/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.7612 - accuracy: 0.4546 - val_loss: 6.6694 - val_accuracy: 0.0500\n",
      "Epoch 326/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.7606 - accuracy: 0.4544 - val_loss: 6.6612 - val_accuracy: 0.0502\n",
      "Epoch 327/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.7663 - accuracy: 0.4529 - val_loss: 6.6776 - val_accuracy: 0.0498\n",
      "Epoch 328/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.7610 - accuracy: 0.4545 - val_loss: 6.6729 - val_accuracy: 0.0509\n",
      "Epoch 329/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.7577 - accuracy: 0.4548 - val_loss: 6.6955 - val_accuracy: 0.0485\n"
     ]
    }
   ],
   "source": [
    "train(model=model,\n",
    "      patience_train=5,\n",
    "      patience_val=None,\n",
    "      learning_rate=.0001,\n",
    "      epochs=1000,\n",
    "      batch_size=128,\n",
    "      # cont_train=True,\n",
    "      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "kjNUJgMbBxxw",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 322491,
     "status": "ok",
     "timestamp": 1688896023616,
     "user": {
      "displayName": "Yoni Krichevsky",
      "userId": "07735752940575548299"
     },
     "user_tz": -180
    },
    "id": "kjNUJgMbBxxw",
    "outputId": "2b2a5700-ecbe-4de0-8b7b-99c043cada80"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patience_train=5, patience_val=None, learning_rate=5e-05, epochs=1000, batch_size=128, cont_train=False, X_train.shape=(33566, 32, 20), y_train.shape=(33566,), X_val.shape=(4619, 32, 20), y_val.shape=(4619,)\n",
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_12 (LSTM)              (None, 32, 64)            21760     \n",
      "                                                                 \n",
      " lstm_13 (LSTM)              (None, 64)                33024     \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 20)                1300      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 64,404\n",
      "Trainable params: 64,404\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Input shape (None, 32, 20), output shape (None, 20)\n",
      "Epoch 1/1000\n",
      "263/263 [==============================] - 7s 11ms/step - loss: 1.7469 - accuracy: 0.4602 - val_loss: 6.6856 - val_accuracy: 0.0489\n",
      "Epoch 2/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 1.7420 - accuracy: 0.4619 - val_loss: 6.7042 - val_accuracy: 0.0494\n",
      "Epoch 3/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 1.7411 - accuracy: 0.4623 - val_loss: 6.7033 - val_accuracy: 0.0504\n",
      "Epoch 4/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.7406 - accuracy: 0.4622 - val_loss: 6.7065 - val_accuracy: 0.0494\n",
      "Epoch 5/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 1.7394 - accuracy: 0.4629 - val_loss: 6.7167 - val_accuracy: 0.0507\n",
      "Epoch 6/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.7388 - accuracy: 0.4627 - val_loss: 6.7193 - val_accuracy: 0.0494\n",
      "Epoch 7/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.7384 - accuracy: 0.4631 - val_loss: 6.7214 - val_accuracy: 0.0485\n",
      "Epoch 8/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.7392 - accuracy: 0.4626 - val_loss: 6.7323 - val_accuracy: 0.0504\n",
      "Epoch 9/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 1.7377 - accuracy: 0.4636 - val_loss: 6.7336 - val_accuracy: 0.0500\n",
      "Epoch 10/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.7366 - accuracy: 0.4632 - val_loss: 6.7562 - val_accuracy: 0.0513\n",
      "Epoch 11/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.7360 - accuracy: 0.4634 - val_loss: 6.7278 - val_accuracy: 0.0500\n",
      "Epoch 12/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.7351 - accuracy: 0.4637 - val_loss: 6.7421 - val_accuracy: 0.0498\n",
      "Epoch 13/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.7352 - accuracy: 0.4644 - val_loss: 6.7467 - val_accuracy: 0.0494\n",
      "Epoch 14/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.7341 - accuracy: 0.4648 - val_loss: 6.7350 - val_accuracy: 0.0496\n",
      "Epoch 15/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 1.7348 - accuracy: 0.4633 - val_loss: 6.7481 - val_accuracy: 0.0502\n",
      "Epoch 16/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.7334 - accuracy: 0.4648 - val_loss: 6.7545 - val_accuracy: 0.0498\n",
      "Epoch 17/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 1.7330 - accuracy: 0.4649 - val_loss: 6.7448 - val_accuracy: 0.0494\n",
      "Epoch 18/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 1.7321 - accuracy: 0.4659 - val_loss: 6.7491 - val_accuracy: 0.0489\n",
      "Epoch 19/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.7316 - accuracy: 0.4652 - val_loss: 6.7519 - val_accuracy: 0.0502\n",
      "Epoch 20/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.7307 - accuracy: 0.4663 - val_loss: 6.7690 - val_accuracy: 0.0496\n",
      "Epoch 21/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.7304 - accuracy: 0.4657 - val_loss: 6.7748 - val_accuracy: 0.0496\n",
      "Epoch 22/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.7301 - accuracy: 0.4657 - val_loss: 6.7724 - val_accuracy: 0.0483\n",
      "Epoch 23/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.7294 - accuracy: 0.4661 - val_loss: 6.7779 - val_accuracy: 0.0498\n",
      "Epoch 24/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.7300 - accuracy: 0.4660 - val_loss: 6.7701 - val_accuracy: 0.0504\n",
      "Epoch 25/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 1.7287 - accuracy: 0.4665 - val_loss: 6.7864 - val_accuracy: 0.0498\n",
      "Epoch 26/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 1.7282 - accuracy: 0.4665 - val_loss: 6.7765 - val_accuracy: 0.0487\n",
      "Epoch 27/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.7280 - accuracy: 0.4663 - val_loss: 6.8015 - val_accuracy: 0.0496\n",
      "Epoch 28/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.7260 - accuracy: 0.4670 - val_loss: 6.7918 - val_accuracy: 0.0494\n",
      "Epoch 29/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.7264 - accuracy: 0.4677 - val_loss: 6.7964 - val_accuracy: 0.0483\n",
      "Epoch 30/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.7253 - accuracy: 0.4678 - val_loss: 6.8038 - val_accuracy: 0.0487\n",
      "Epoch 31/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 1.7247 - accuracy: 0.4681 - val_loss: 6.8157 - val_accuracy: 0.0500\n",
      "Epoch 32/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.7240 - accuracy: 0.4679 - val_loss: 6.8143 - val_accuracy: 0.0500\n",
      "Epoch 33/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.7248 - accuracy: 0.4678 - val_loss: 6.8145 - val_accuracy: 0.0504\n",
      "Epoch 34/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.7236 - accuracy: 0.4681 - val_loss: 6.8081 - val_accuracy: 0.0498\n",
      "Epoch 35/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.7231 - accuracy: 0.4679 - val_loss: 6.8264 - val_accuracy: 0.0491\n",
      "Epoch 36/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.7218 - accuracy: 0.4685 - val_loss: 6.8231 - val_accuracy: 0.0487\n",
      "Epoch 37/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 1.7214 - accuracy: 0.4683 - val_loss: 6.8315 - val_accuracy: 0.0483\n",
      "Epoch 38/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.7214 - accuracy: 0.4686 - val_loss: 6.8348 - val_accuracy: 0.0502\n",
      "Epoch 39/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.7216 - accuracy: 0.4679 - val_loss: 6.8257 - val_accuracy: 0.0494\n",
      "Epoch 40/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.7215 - accuracy: 0.4684 - val_loss: 6.8404 - val_accuracy: 0.0491\n",
      "Epoch 41/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 1.7201 - accuracy: 0.4684 - val_loss: 6.8367 - val_accuracy: 0.0489\n",
      "Epoch 42/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.7184 - accuracy: 0.4698 - val_loss: 6.8510 - val_accuracy: 0.0491\n",
      "Epoch 43/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.7180 - accuracy: 0.4702 - val_loss: 6.8442 - val_accuracy: 0.0491\n",
      "Epoch 44/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 1.7176 - accuracy: 0.4702 - val_loss: 6.8607 - val_accuracy: 0.0494\n",
      "Epoch 45/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.7186 - accuracy: 0.4692 - val_loss: 6.8597 - val_accuracy: 0.0478\n",
      "Epoch 46/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.7176 - accuracy: 0.4697 - val_loss: 6.8717 - val_accuracy: 0.0496\n",
      "Epoch 47/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 1.7177 - accuracy: 0.4694 - val_loss: 6.8599 - val_accuracy: 0.0485\n",
      "Epoch 48/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 1.7165 - accuracy: 0.4699 - val_loss: 6.8596 - val_accuracy: 0.0494\n",
      "Epoch 49/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 1.7149 - accuracy: 0.4707 - val_loss: 6.8732 - val_accuracy: 0.0487\n",
      "Epoch 50/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 1.7144 - accuracy: 0.4705 - val_loss: 6.8690 - val_accuracy: 0.0496\n",
      "Epoch 51/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.7141 - accuracy: 0.4718 - val_loss: 6.8746 - val_accuracy: 0.0494\n",
      "Epoch 52/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.7149 - accuracy: 0.4701 - val_loss: 6.8739 - val_accuracy: 0.0494\n",
      "Epoch 53/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.7136 - accuracy: 0.4722 - val_loss: 6.8798 - val_accuracy: 0.0500\n",
      "Epoch 54/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 1.7126 - accuracy: 0.4713 - val_loss: 6.8940 - val_accuracy: 0.0487\n",
      "Epoch 55/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.7118 - accuracy: 0.4718 - val_loss: 6.8884 - val_accuracy: 0.0489\n",
      "Epoch 56/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 1.7120 - accuracy: 0.4728 - val_loss: 6.8941 - val_accuracy: 0.0494\n",
      "Epoch 57/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.7119 - accuracy: 0.4719 - val_loss: 6.8966 - val_accuracy: 0.0496\n",
      "Epoch 58/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.7113 - accuracy: 0.4714 - val_loss: 6.9006 - val_accuracy: 0.0483\n",
      "Epoch 59/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.7105 - accuracy: 0.4724 - val_loss: 6.9002 - val_accuracy: 0.0487\n",
      "Epoch 60/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 1.7091 - accuracy: 0.4740 - val_loss: 6.9097 - val_accuracy: 0.0491\n",
      "Epoch 61/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.7109 - accuracy: 0.4727 - val_loss: 6.8936 - val_accuracy: 0.0489\n",
      "Epoch 62/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 1.7118 - accuracy: 0.4716 - val_loss: 6.9154 - val_accuracy: 0.0494\n",
      "Epoch 63/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 1.7083 - accuracy: 0.4725 - val_loss: 6.9115 - val_accuracy: 0.0509\n",
      "Epoch 64/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 1.7065 - accuracy: 0.4737 - val_loss: 6.9168 - val_accuracy: 0.0496\n",
      "Epoch 65/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 1.7063 - accuracy: 0.4743 - val_loss: 6.9190 - val_accuracy: 0.0491\n",
      "Epoch 66/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.7066 - accuracy: 0.4735 - val_loss: 6.9245 - val_accuracy: 0.0494\n",
      "Epoch 67/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.7060 - accuracy: 0.4737 - val_loss: 6.9370 - val_accuracy: 0.0500\n",
      "Epoch 68/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.7053 - accuracy: 0.4731 - val_loss: 6.9337 - val_accuracy: 0.0474\n",
      "Epoch 69/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.7063 - accuracy: 0.4741 - val_loss: 6.9252 - val_accuracy: 0.0498\n",
      "Epoch 70/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 1.7067 - accuracy: 0.4739 - val_loss: 6.9249 - val_accuracy: 0.0498\n",
      "Epoch 71/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 1.7052 - accuracy: 0.4734 - val_loss: 6.9349 - val_accuracy: 0.0498\n",
      "Epoch 72/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.7034 - accuracy: 0.4745 - val_loss: 6.9487 - val_accuracy: 0.0491\n",
      "Epoch 73/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.7028 - accuracy: 0.4748 - val_loss: 6.9562 - val_accuracy: 0.0481\n",
      "Epoch 74/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 1.7030 - accuracy: 0.4745 - val_loss: 6.9454 - val_accuracy: 0.0496\n",
      "Epoch 75/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.7014 - accuracy: 0.4748 - val_loss: 6.9512 - val_accuracy: 0.0496\n",
      "Epoch 76/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 1.7013 - accuracy: 0.4757 - val_loss: 6.9521 - val_accuracy: 0.0487\n",
      "Epoch 77/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.7026 - accuracy: 0.4743 - val_loss: 6.9561 - val_accuracy: 0.0498\n",
      "Epoch 78/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.7029 - accuracy: 0.4743 - val_loss: 6.9700 - val_accuracy: 0.0483\n",
      "Epoch 79/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 1.7001 - accuracy: 0.4755 - val_loss: 6.9590 - val_accuracy: 0.0500\n",
      "Epoch 80/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 1.6998 - accuracy: 0.4763 - val_loss: 6.9690 - val_accuracy: 0.0487\n",
      "Epoch 81/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.6994 - accuracy: 0.4758 - val_loss: 6.9661 - val_accuracy: 0.0489\n",
      "Epoch 82/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.6977 - accuracy: 0.4761 - val_loss: 6.9768 - val_accuracy: 0.0489\n",
      "Epoch 83/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.6994 - accuracy: 0.4754 - val_loss: 6.9700 - val_accuracy: 0.0496\n",
      "Epoch 84/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.6991 - accuracy: 0.4766 - val_loss: 6.9723 - val_accuracy: 0.0498\n",
      "Epoch 85/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.6969 - accuracy: 0.4776 - val_loss: 6.9817 - val_accuracy: 0.0491\n",
      "Epoch 86/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.6965 - accuracy: 0.4767 - val_loss: 6.9798 - val_accuracy: 0.0496\n",
      "Epoch 87/1000\n",
      "263/263 [==============================] - 3s 10ms/step - loss: 1.6973 - accuracy: 0.4768 - val_loss: 6.9876 - val_accuracy: 0.0485\n",
      "Epoch 88/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 1.6963 - accuracy: 0.4768 - val_loss: 6.9864 - val_accuracy: 0.0489\n",
      "Epoch 89/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.6957 - accuracy: 0.4773 - val_loss: 7.0000 - val_accuracy: 0.0481\n",
      "Epoch 90/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.6971 - accuracy: 0.4761 - val_loss: 6.9949 - val_accuracy: 0.0498\n",
      "Epoch 91/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.6944 - accuracy: 0.4771 - val_loss: 6.9996 - val_accuracy: 0.0496\n",
      "Epoch 92/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.6942 - accuracy: 0.4775 - val_loss: 7.0094 - val_accuracy: 0.0494\n",
      "Epoch 93/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 1.6936 - accuracy: 0.4781 - val_loss: 7.0129 - val_accuracy: 0.0483\n",
      "Epoch 94/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 1.6930 - accuracy: 0.4778 - val_loss: 7.0119 - val_accuracy: 0.0491\n",
      "Epoch 95/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 1.6923 - accuracy: 0.4785 - val_loss: 7.0134 - val_accuracy: 0.0494\n",
      "Epoch 96/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 1.6933 - accuracy: 0.4776 - val_loss: 7.0235 - val_accuracy: 0.0498\n",
      "Epoch 97/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.6915 - accuracy: 0.4786 - val_loss: 7.0278 - val_accuracy: 0.0483\n",
      "Epoch 98/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 1.6905 - accuracy: 0.4793 - val_loss: 7.0330 - val_accuracy: 0.0489\n",
      "Epoch 99/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 1.6912 - accuracy: 0.4785 - val_loss: 7.0171 - val_accuracy: 0.0483\n",
      "Epoch 100/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 1.6898 - accuracy: 0.4801 - val_loss: 7.0221 - val_accuracy: 0.0507\n",
      "Epoch 101/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 1.6916 - accuracy: 0.4772 - val_loss: 7.0356 - val_accuracy: 0.0483\n",
      "Epoch 102/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.6898 - accuracy: 0.4790 - val_loss: 7.0474 - val_accuracy: 0.0491\n",
      "Epoch 103/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.6885 - accuracy: 0.4794 - val_loss: 7.0501 - val_accuracy: 0.0494\n",
      "Epoch 104/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 1.6890 - accuracy: 0.4793 - val_loss: 7.0517 - val_accuracy: 0.0491\n",
      "Epoch 105/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.6876 - accuracy: 0.4784 - val_loss: 7.0459 - val_accuracy: 0.0485\n",
      "Epoch 106/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.6864 - accuracy: 0.4798 - val_loss: 7.0530 - val_accuracy: 0.0494\n",
      "Epoch 107/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 1.6855 - accuracy: 0.4809 - val_loss: 7.0409 - val_accuracy: 0.0483\n",
      "Epoch 108/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.6864 - accuracy: 0.4792 - val_loss: 7.0626 - val_accuracy: 0.0478\n",
      "Epoch 109/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 1.6860 - accuracy: 0.4799 - val_loss: 7.0534 - val_accuracy: 0.0483\n",
      "Epoch 110/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 1.6895 - accuracy: 0.4789 - val_loss: 7.0517 - val_accuracy: 0.0496\n",
      "Epoch 111/1000\n",
      "263/263 [==============================] - 3s 10ms/step - loss: 1.6857 - accuracy: 0.4813 - val_loss: 7.0715 - val_accuracy: 0.0487\n",
      "Epoch 112/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 1.6844 - accuracy: 0.4802 - val_loss: 7.0733 - val_accuracy: 0.0489\n",
      "Epoch 113/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.6829 - accuracy: 0.4809 - val_loss: 7.0697 - val_accuracy: 0.0496\n",
      "Epoch 114/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.6846 - accuracy: 0.4794 - val_loss: 7.0697 - val_accuracy: 0.0478\n",
      "Epoch 115/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 1.6838 - accuracy: 0.4799 - val_loss: 7.0705 - val_accuracy: 0.0491\n",
      "Epoch 116/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 1.6821 - accuracy: 0.4818 - val_loss: 7.0783 - val_accuracy: 0.0476\n",
      "Epoch 117/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 1.6810 - accuracy: 0.4812 - val_loss: 7.0895 - val_accuracy: 0.0472\n",
      "Epoch 118/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.6815 - accuracy: 0.4817 - val_loss: 7.0855 - val_accuracy: 0.0472\n",
      "Epoch 119/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 1.6800 - accuracy: 0.4813 - val_loss: 7.0862 - val_accuracy: 0.0476\n",
      "Epoch 120/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 1.6796 - accuracy: 0.4818 - val_loss: 7.0981 - val_accuracy: 0.0485\n",
      "Epoch 121/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.6802 - accuracy: 0.4816 - val_loss: 7.0910 - val_accuracy: 0.0478\n",
      "Epoch 122/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.6798 - accuracy: 0.4821 - val_loss: 7.1039 - val_accuracy: 0.0476\n",
      "Epoch 123/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.6785 - accuracy: 0.4824 - val_loss: 7.1054 - val_accuracy: 0.0491\n",
      "Epoch 124/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.6807 - accuracy: 0.4822 - val_loss: 7.1034 - val_accuracy: 0.0487\n",
      "Epoch 125/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 1.6794 - accuracy: 0.4814 - val_loss: 7.1179 - val_accuracy: 0.0474\n",
      "Epoch 126/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 1.6769 - accuracy: 0.4829 - val_loss: 7.1147 - val_accuracy: 0.0496\n",
      "Epoch 127/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 1.6769 - accuracy: 0.4825 - val_loss: 7.1157 - val_accuracy: 0.0487\n",
      "Epoch 128/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.6769 - accuracy: 0.4826 - val_loss: 7.1248 - val_accuracy: 0.0489\n",
      "Epoch 129/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.6756 - accuracy: 0.4828 - val_loss: 7.1195 - val_accuracy: 0.0502\n",
      "Epoch 130/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 1.6762 - accuracy: 0.4840 - val_loss: 7.1262 - val_accuracy: 0.0491\n",
      "Epoch 131/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.6759 - accuracy: 0.4830 - val_loss: 7.1257 - val_accuracy: 0.0478\n",
      "Epoch 132/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 1.6751 - accuracy: 0.4830 - val_loss: 7.1567 - val_accuracy: 0.0476\n",
      "Epoch 133/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.6782 - accuracy: 0.4826 - val_loss: 7.1469 - val_accuracy: 0.0487\n",
      "Epoch 134/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.6738 - accuracy: 0.4837 - val_loss: 7.1401 - val_accuracy: 0.0485\n",
      "Epoch 135/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.6807 - accuracy: 0.4803 - val_loss: 7.1463 - val_accuracy: 0.0498\n",
      "Epoch 136/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.6741 - accuracy: 0.4830 - val_loss: 7.1447 - val_accuracy: 0.0487\n",
      "Epoch 137/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.6711 - accuracy: 0.4841 - val_loss: 7.1489 - val_accuracy: 0.0478\n",
      "Epoch 138/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.6700 - accuracy: 0.4850 - val_loss: 7.1551 - val_accuracy: 0.0498\n",
      "Epoch 139/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.6703 - accuracy: 0.4842 - val_loss: 7.1481 - val_accuracy: 0.0483\n",
      "Epoch 140/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.6722 - accuracy: 0.4833 - val_loss: 7.1620 - val_accuracy: 0.0489\n",
      "Epoch 141/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.6705 - accuracy: 0.4846 - val_loss: 7.1643 - val_accuracy: 0.0481\n",
      "Epoch 142/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 1.6703 - accuracy: 0.4849 - val_loss: 7.1647 - val_accuracy: 0.0485\n",
      "Epoch 143/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 1.6700 - accuracy: 0.4852 - val_loss: 7.1567 - val_accuracy: 0.0498\n"
     ]
    }
   ],
   "source": [
    "train(model=model,\n",
    "      patience_train=5,\n",
    "      patience_val=None,\n",
    "      learning_rate=.00005,\n",
    "      epochs=1000,\n",
    "      batch_size=128,\n",
    "      # cont_train=True,\n",
    "      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a_LcCIyVCjQD",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 62671,
     "status": "ok",
     "timestamp": 1688896426792,
     "user": {
      "displayName": "Yoni Krichevsky",
      "userId": "07735752940575548299"
     },
     "user_tz": -180
    },
    "id": "a_LcCIyVCjQD",
    "outputId": "117f7821-b68a-49d7-f08a-0b3cdc54c2a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patience_train=10, patience_val=None, learning_rate=1e-05, epochs=1000, batch_size=128, cont_train=False, X_train.shape=(33566, 32, 20), y_train.shape=(33566,), X_val.shape=(4619, 32, 20), y_val.shape=(4619,)\n",
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_16 (LSTM)              (None, 32, 128)           76288     \n",
      "                                                                 \n",
      " lstm_17 (LSTM)              (None, 128)               131584    \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_24 (Dense)            (None, 20)                2580      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 243,476\n",
      "Trainable params: 243,476\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Input shape (None, 32, 20), output shape (None, 20)\n",
      "Epoch 1/1000\n",
      "263/263 [==============================] - 8s 12ms/step - loss: 3.2335 - accuracy: 0.0471 - val_loss: 3.1235 - val_accuracy: 0.0478\n",
      "Epoch 2/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.1119 - accuracy: 0.0480 - val_loss: 3.0412 - val_accuracy: 0.0478\n",
      "Epoch 3/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0565 - accuracy: 0.0492 - val_loss: 3.0109 - val_accuracy: 0.0478\n",
      "Epoch 4/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0355 - accuracy: 0.0494 - val_loss: 3.0002 - val_accuracy: 0.0478\n",
      "Epoch 5/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0264 - accuracy: 0.0504 - val_loss: 2.9967 - val_accuracy: 0.0478\n",
      "Epoch 6/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0207 - accuracy: 0.0512 - val_loss: 2.9959 - val_accuracy: 0.0478\n",
      "Epoch 7/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0213 - accuracy: 0.0495 - val_loss: 2.9957 - val_accuracy: 0.0522\n",
      "Epoch 8/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0197 - accuracy: 0.0515 - val_loss: 2.9958 - val_accuracy: 0.0522\n",
      "Epoch 9/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0195 - accuracy: 0.0501 - val_loss: 2.9959 - val_accuracy: 0.0522\n",
      "Epoch 10/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0202 - accuracy: 0.0498 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 11/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0205 - accuracy: 0.0497 - val_loss: 2.9960 - val_accuracy: 0.0522\n",
      "Epoch 12/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 3.0205 - accuracy: 0.0471 - val_loss: 2.9960 - val_accuracy: 0.0522\n",
      "Epoch 13/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 3.0181 - accuracy: 0.0512 - val_loss: 2.9960 - val_accuracy: 0.0517\n",
      "Epoch 14/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0179 - accuracy: 0.0503 - val_loss: 2.9960 - val_accuracy: 0.0522\n",
      "Epoch 15/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0180 - accuracy: 0.0483 - val_loss: 2.9960 - val_accuracy: 0.0522\n",
      "Epoch 16/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0170 - accuracy: 0.0519 - val_loss: 2.9959 - val_accuracy: 0.0522\n",
      "Epoch 17/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0161 - accuracy: 0.0509 - val_loss: 2.9960 - val_accuracy: 0.0522\n",
      "Epoch 18/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 3.0162 - accuracy: 0.0510 - val_loss: 2.9960 - val_accuracy: 0.0522\n",
      "Epoch 19/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 3.0185 - accuracy: 0.0483 - val_loss: 2.9960 - val_accuracy: 0.0517\n",
      "Epoch 20/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 3.0170 - accuracy: 0.0498 - val_loss: 2.9960 - val_accuracy: 0.0517\n",
      "Epoch 21/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0173 - accuracy: 0.0481 - val_loss: 2.9959 - val_accuracy: 0.0522\n",
      "Epoch 22/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0171 - accuracy: 0.0502 - val_loss: 2.9959 - val_accuracy: 0.0522\n",
      "Epoch 23/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0160 - accuracy: 0.0493 - val_loss: 2.9960 - val_accuracy: 0.0522\n",
      "Epoch 24/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0154 - accuracy: 0.0499 - val_loss: 2.9960 - val_accuracy: 0.0515\n",
      "Epoch 25/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0159 - accuracy: 0.0503 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 26/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0150 - accuracy: 0.0516 - val_loss: 2.9958 - val_accuracy: 0.0517\n",
      "Epoch 27/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0132 - accuracy: 0.0530 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 28/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0149 - accuracy: 0.0500 - val_loss: 2.9960 - val_accuracy: 0.0522\n",
      "Epoch 29/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0161 - accuracy: 0.0475 - val_loss: 2.9959 - val_accuracy: 0.0522\n",
      "Epoch 30/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0132 - accuracy: 0.0507 - val_loss: 2.9960 - val_accuracy: 0.0522\n",
      "Epoch 31/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0148 - accuracy: 0.0491 - val_loss: 2.9959 - val_accuracy: 0.0522\n",
      "Epoch 32/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0149 - accuracy: 0.0507 - val_loss: 2.9959 - val_accuracy: 0.0522\n",
      "Epoch 33/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0142 - accuracy: 0.0506 - val_loss: 2.9960 - val_accuracy: 0.0517\n",
      "Epoch 34/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0118 - accuracy: 0.0492 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 35/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0131 - accuracy: 0.0513 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 36/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0129 - accuracy: 0.0489 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 37/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0124 - accuracy: 0.0492 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 38/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0146 - accuracy: 0.0498 - val_loss: 2.9959 - val_accuracy: 0.0520\n",
      "Epoch 39/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0118 - accuracy: 0.0497 - val_loss: 2.9959 - val_accuracy: 0.0554\n",
      "Epoch 40/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0117 - accuracy: 0.0490 - val_loss: 2.9960 - val_accuracy: 0.0489\n",
      "Epoch 41/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0111 - accuracy: 0.0490 - val_loss: 2.9959 - val_accuracy: 0.0507\n",
      "Epoch 42/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0109 - accuracy: 0.0518 - val_loss: 2.9959 - val_accuracy: 0.0522\n",
      "Epoch 43/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0095 - accuracy: 0.0520 - val_loss: 2.9960 - val_accuracy: 0.0517\n",
      "Epoch 44/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0102 - accuracy: 0.0517 - val_loss: 2.9960 - val_accuracy: 0.0515\n",
      "Epoch 45/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0122 - accuracy: 0.0487 - val_loss: 2.9960 - val_accuracy: 0.0511\n",
      "Epoch 46/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0097 - accuracy: 0.0518 - val_loss: 2.9959 - val_accuracy: 0.0515\n",
      "Epoch 47/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0097 - accuracy: 0.0495 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 48/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0097 - accuracy: 0.0485 - val_loss: 2.9960 - val_accuracy: 0.0517\n",
      "Epoch 49/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 3.0083 - accuracy: 0.0523 - val_loss: 2.9960 - val_accuracy: 0.0515\n",
      "Epoch 50/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0092 - accuracy: 0.0503 - val_loss: 2.9960 - val_accuracy: 0.0517\n",
      "Epoch 51/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0099 - accuracy: 0.0475 - val_loss: 2.9961 - val_accuracy: 0.0507\n",
      "Epoch 52/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0102 - accuracy: 0.0484 - val_loss: 2.9960 - val_accuracy: 0.0513\n",
      "Epoch 53/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0097 - accuracy: 0.0485 - val_loss: 2.9960 - val_accuracy: 0.0491\n",
      "Epoch 54/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0099 - accuracy: 0.0505 - val_loss: 2.9960 - val_accuracy: 0.0513\n",
      "Epoch 55/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 3.0086 - accuracy: 0.0504 - val_loss: 2.9960 - val_accuracy: 0.0483\n",
      "Epoch 56/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0091 - accuracy: 0.0489 - val_loss: 2.9960 - val_accuracy: 0.0509\n",
      "Epoch 57/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0086 - accuracy: 0.0507 - val_loss: 2.9960 - val_accuracy: 0.0511\n",
      "Epoch 58/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0076 - accuracy: 0.0492 - val_loss: 2.9959 - val_accuracy: 0.0530\n",
      "Epoch 59/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0066 - accuracy: 0.0512 - val_loss: 2.9960 - val_accuracy: 0.0511\n",
      "Epoch 60/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0072 - accuracy: 0.0497 - val_loss: 2.9960 - val_accuracy: 0.0500\n",
      "Epoch 61/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0080 - accuracy: 0.0503 - val_loss: 2.9961 - val_accuracy: 0.0504\n",
      "Epoch 62/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0063 - accuracy: 0.0493 - val_loss: 2.9959 - val_accuracy: 0.0541\n",
      "Epoch 63/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0075 - accuracy: 0.0497 - val_loss: 2.9960 - val_accuracy: 0.0515\n",
      "Epoch 64/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0070 - accuracy: 0.0490 - val_loss: 2.9960 - val_accuracy: 0.0535\n",
      "Epoch 65/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0070 - accuracy: 0.0516 - val_loss: 2.9960 - val_accuracy: 0.0511\n",
      "Epoch 66/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0072 - accuracy: 0.0494 - val_loss: 2.9959 - val_accuracy: 0.0535\n",
      "Epoch 67/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0080 - accuracy: 0.0507 - val_loss: 2.9960 - val_accuracy: 0.0554\n",
      "Epoch 68/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0058 - accuracy: 0.0509 - val_loss: 2.9960 - val_accuracy: 0.0526\n",
      "Epoch 69/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0068 - accuracy: 0.0498 - val_loss: 2.9961 - val_accuracy: 0.0485\n",
      "Epoch 70/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0075 - accuracy: 0.0486 - val_loss: 2.9961 - val_accuracy: 0.0517\n",
      "Epoch 71/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0072 - accuracy: 0.0495 - val_loss: 2.9960 - val_accuracy: 0.0496\n",
      "Epoch 72/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0062 - accuracy: 0.0490 - val_loss: 2.9961 - val_accuracy: 0.0552\n",
      "Epoch 73/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0064 - accuracy: 0.0505 - val_loss: 2.9960 - val_accuracy: 0.0548\n",
      "Epoch 74/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0065 - accuracy: 0.0509 - val_loss: 2.9960 - val_accuracy: 0.0526\n",
      "Epoch 75/1000\n",
      "263/263 [==============================] - 3s 10ms/step - loss: 3.0056 - accuracy: 0.0503 - val_loss: 2.9962 - val_accuracy: 0.0526\n",
      "Epoch 76/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0062 - accuracy: 0.0497 - val_loss: 2.9959 - val_accuracy: 0.0541\n",
      "Epoch 77/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0049 - accuracy: 0.0518 - val_loss: 2.9961 - val_accuracy: 0.0552\n",
      "Epoch 78/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0045 - accuracy: 0.0494 - val_loss: 2.9962 - val_accuracy: 0.0548\n",
      "Epoch 79/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0048 - accuracy: 0.0528 - val_loss: 2.9961 - val_accuracy: 0.0550\n",
      "Epoch 80/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0046 - accuracy: 0.0508 - val_loss: 2.9960 - val_accuracy: 0.0552\n",
      "Epoch 81/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0047 - accuracy: 0.0520 - val_loss: 2.9960 - val_accuracy: 0.0539\n",
      "Epoch 82/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0054 - accuracy: 0.0494 - val_loss: 2.9959 - val_accuracy: 0.0548\n",
      "Epoch 83/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0039 - accuracy: 0.0485 - val_loss: 2.9960 - val_accuracy: 0.0550\n",
      "Epoch 84/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 3.0053 - accuracy: 0.0495 - val_loss: 2.9961 - val_accuracy: 0.0563\n",
      "Epoch 85/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 3.0057 - accuracy: 0.0494 - val_loss: 2.9961 - val_accuracy: 0.0537\n",
      "Epoch 86/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 3.0042 - accuracy: 0.0515 - val_loss: 2.9963 - val_accuracy: 0.0528\n",
      "Epoch 87/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0045 - accuracy: 0.0515 - val_loss: 2.9962 - val_accuracy: 0.0541\n",
      "Epoch 88/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0042 - accuracy: 0.0496 - val_loss: 2.9962 - val_accuracy: 0.0511\n",
      "Epoch 89/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0044 - accuracy: 0.0502 - val_loss: 2.9959 - val_accuracy: 0.0541\n",
      "Epoch 90/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0031 - accuracy: 0.0512 - val_loss: 2.9960 - val_accuracy: 0.0546\n",
      "Epoch 91/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 3.0041 - accuracy: 0.0508 - val_loss: 2.9960 - val_accuracy: 0.0546\n",
      "Epoch 92/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0042 - accuracy: 0.0503 - val_loss: 2.9960 - val_accuracy: 0.0559\n",
      "Epoch 93/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0028 - accuracy: 0.0505 - val_loss: 2.9961 - val_accuracy: 0.0578\n",
      "Epoch 94/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0022 - accuracy: 0.0531 - val_loss: 2.9960 - val_accuracy: 0.0537\n",
      "Epoch 95/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0036 - accuracy: 0.0501 - val_loss: 2.9960 - val_accuracy: 0.0543\n",
      "Epoch 96/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0030 - accuracy: 0.0491 - val_loss: 2.9962 - val_accuracy: 0.0539\n",
      "Epoch 97/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0029 - accuracy: 0.0524 - val_loss: 2.9961 - val_accuracy: 0.0554\n",
      "Epoch 98/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0024 - accuracy: 0.0530 - val_loss: 2.9961 - val_accuracy: 0.0556\n",
      "Epoch 99/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0033 - accuracy: 0.0490 - val_loss: 2.9962 - val_accuracy: 0.0522\n",
      "Epoch 100/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0025 - accuracy: 0.0522 - val_loss: 2.9962 - val_accuracy: 0.0520\n",
      "Epoch 101/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0030 - accuracy: 0.0496 - val_loss: 2.9962 - val_accuracy: 0.0504\n",
      "Epoch 102/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0034 - accuracy: 0.0485 - val_loss: 2.9962 - val_accuracy: 0.0511\n",
      "Epoch 103/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0030 - accuracy: 0.0504 - val_loss: 2.9962 - val_accuracy: 0.0517\n",
      "Epoch 104/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0027 - accuracy: 0.0502 - val_loss: 2.9961 - val_accuracy: 0.0524\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([LSTM(128, input_shape=(32, 20), return_sequences=True, dropout=.1),\n",
    "                    LSTM(128, dropout=.1),\n",
    "                    Dropout(.1),\n",
    "                    Dense(128, activation='sigmoid'),\n",
    "                    Dropout(.1),\n",
    "                    Dense(128, activation='sigmoid'),\n",
    "                    Dropout(.1),\n",
    "                    Dense(20, activation='softmax')])\n",
    "train(model=model,\n",
    "      patience_train=10,\n",
    "      patience_val=None,\n",
    "      learning_rate=.00001,\n",
    "      epochs=1000,\n",
    "      batch_size=128,\n",
    "      # cont_train=True,\n",
    "      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c2wiyMGIFK_J",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 60623,
     "status": "ok",
     "timestamp": 1688896650553,
     "user": {
      "displayName": "Yoni Krichevsky",
      "userId": "07735752940575548299"
     },
     "user_tz": -180
    },
    "id": "c2wiyMGIFK_J",
    "outputId": "0b05bef3-30a6-4dcb-cfcb-ec6edb31b573"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patience_train=10, patience_val=None, learning_rate=1e-06, epochs=1000, batch_size=128, cont_train=False, X_train.shape=(33566, 32, 20), y_train.shape=(33566,), X_val.shape=(4619, 32, 20), y_val.shape=(4619,)\n",
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_16 (LSTM)              (None, 32, 128)           76288     \n",
      "                                                                 \n",
      " lstm_17 (LSTM)              (None, 128)               131584    \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_24 (Dense)            (None, 20)                2580      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 243,476\n",
      "Trainable params: 243,476\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Input shape (None, 32, 20), output shape (None, 20)\n",
      "Epoch 1/1000\n",
      "263/263 [==============================] - 8s 12ms/step - loss: 3.0029 - accuracy: 0.0515 - val_loss: 2.9961 - val_accuracy: 0.0526\n",
      "Epoch 2/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0017 - accuracy: 0.0513 - val_loss: 2.9962 - val_accuracy: 0.0513\n",
      "Epoch 3/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0028 - accuracy: 0.0511 - val_loss: 2.9962 - val_accuracy: 0.0515\n",
      "Epoch 4/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0011 - accuracy: 0.0512 - val_loss: 2.9962 - val_accuracy: 0.0513\n",
      "Epoch 5/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0028 - accuracy: 0.0510 - val_loss: 2.9962 - val_accuracy: 0.0511\n",
      "Epoch 6/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0014 - accuracy: 0.0518 - val_loss: 2.9962 - val_accuracy: 0.0513\n",
      "Epoch 7/1000\n",
      "263/263 [==============================] - 3s 10ms/step - loss: 3.0026 - accuracy: 0.0523 - val_loss: 2.9962 - val_accuracy: 0.0530\n",
      "Epoch 8/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0019 - accuracy: 0.0507 - val_loss: 2.9961 - val_accuracy: 0.0526\n",
      "Epoch 9/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0008 - accuracy: 0.0513 - val_loss: 2.9962 - val_accuracy: 0.0515\n",
      "Epoch 10/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0022 - accuracy: 0.0506 - val_loss: 2.9962 - val_accuracy: 0.0515\n",
      "Epoch 11/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0010 - accuracy: 0.0514 - val_loss: 2.9962 - val_accuracy: 0.0517\n",
      "Epoch 12/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0007 - accuracy: 0.0520 - val_loss: 2.9962 - val_accuracy: 0.0513\n",
      "Epoch 13/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0006 - accuracy: 0.0528 - val_loss: 2.9962 - val_accuracy: 0.0509\n",
      "Epoch 14/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0014 - accuracy: 0.0506 - val_loss: 2.9962 - val_accuracy: 0.0509\n",
      "Epoch 15/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0019 - accuracy: 0.0479 - val_loss: 2.9962 - val_accuracy: 0.0515\n",
      "Epoch 16/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 3.0022 - accuracy: 0.0501 - val_loss: 2.9962 - val_accuracy: 0.0517\n",
      "Epoch 17/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 3.0023 - accuracy: 0.0508 - val_loss: 2.9962 - val_accuracy: 0.0522\n",
      "Epoch 18/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0019 - accuracy: 0.0515 - val_loss: 2.9962 - val_accuracy: 0.0513\n",
      "Epoch 19/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0022 - accuracy: 0.0496 - val_loss: 2.9962 - val_accuracy: 0.0513\n",
      "Epoch 20/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0025 - accuracy: 0.0485 - val_loss: 2.9962 - val_accuracy: 0.0522\n",
      "Epoch 21/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0023 - accuracy: 0.0512 - val_loss: 2.9962 - val_accuracy: 0.0524\n",
      "Epoch 22/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0017 - accuracy: 0.0520 - val_loss: 2.9962 - val_accuracy: 0.0513\n",
      "Epoch 23/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 3.0014 - accuracy: 0.0508 - val_loss: 2.9962 - val_accuracy: 0.0513\n"
     ]
    }
   ],
   "source": [
    "train(model=model,\n",
    "      patience_train=10,\n",
    "      patience_val=None,\n",
    "      learning_rate=.000001,\n",
    "      epochs=1000,\n",
    "      batch_size=128,\n",
    "      # cont_train=True,\n",
    "      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "M3pXhXlWFfHr",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 122805,
     "status": "ok",
     "timestamp": 1688896792779,
     "user": {
      "displayName": "Yoni Krichevsky",
      "userId": "07735752940575548299"
     },
     "user_tz": -180
    },
    "id": "M3pXhXlWFfHr",
    "outputId": "0e2e4e07-3ad0-4a0a-cdb8-994e1e8e332e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patience_train=10, patience_val=None, learning_rate=0.001, epochs=1000, batch_size=128, cont_train=False, X_train.shape=(33566, 32, 20), y_train.shape=(33566,), X_val.shape=(4619, 32, 20), y_val.shape=(4619,)\n",
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_16 (LSTM)              (None, 32, 128)           76288     \n",
      "                                                                 \n",
      " lstm_17 (LSTM)              (None, 128)               131584    \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_24 (Dense)            (None, 20)                2580      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 243,476\n",
      "Trainable params: 243,476\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Input shape (None, 32, 20), output shape (None, 20)\n",
      "Epoch 1/1000\n",
      "263/263 [==============================] - 8s 12ms/step - loss: 3.0032 - accuracy: 0.0495 - val_loss: 2.9962 - val_accuracy: 0.0535\n",
      "Epoch 2/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 2.9976 - accuracy: 0.0516 - val_loss: 2.9960 - val_accuracy: 0.0520\n",
      "Epoch 3/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 2.9966 - accuracy: 0.0514 - val_loss: 2.9958 - val_accuracy: 0.0485\n",
      "Epoch 4/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 2.9963 - accuracy: 0.0506 - val_loss: 2.9959 - val_accuracy: 0.0465\n",
      "Epoch 5/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 2.9960 - accuracy: 0.0498 - val_loss: 2.9958 - val_accuracy: 0.0517\n",
      "Epoch 6/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 2.9960 - accuracy: 0.0485 - val_loss: 2.9960 - val_accuracy: 0.0517\n",
      "Epoch 7/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 2.9959 - accuracy: 0.0510 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 8/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 2.9958 - accuracy: 0.0495 - val_loss: 2.9958 - val_accuracy: 0.0522\n",
      "Epoch 9/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 2.9958 - accuracy: 0.0507 - val_loss: 2.9959 - val_accuracy: 0.0465\n",
      "Epoch 10/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 2.9958 - accuracy: 0.0499 - val_loss: 2.9960 - val_accuracy: 0.0517\n",
      "Epoch 11/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 2.9958 - accuracy: 0.0494 - val_loss: 2.9960 - val_accuracy: 0.0465\n",
      "Epoch 12/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 2.9957 - accuracy: 0.0499 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 13/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 2.9957 - accuracy: 0.0488 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 14/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 2.9958 - accuracy: 0.0509 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 15/1000\n",
      "263/263 [==============================] - 3s 10ms/step - loss: 2.9957 - accuracy: 0.0506 - val_loss: 2.9960 - val_accuracy: 0.0465\n",
      "Epoch 16/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 2.9957 - accuracy: 0.0494 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 17/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 18/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 2.9958 - accuracy: 0.0497 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 19/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 2.9957 - accuracy: 0.0506 - val_loss: 2.9958 - val_accuracy: 0.0517\n",
      "Epoch 20/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 2.9957 - accuracy: 0.0514 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 21/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 2.9957 - accuracy: 0.0517 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 22/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 2.9957 - accuracy: 0.0505 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 23/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 2.9957 - accuracy: 0.0517 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 24/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 2.9957 - accuracy: 0.0502 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 25/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 2.9957 - accuracy: 0.0500 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 26/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 2.9957 - accuracy: 0.0502 - val_loss: 2.9960 - val_accuracy: 0.0517\n",
      "Epoch 27/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 2.9957 - accuracy: 0.0498 - val_loss: 2.9958 - val_accuracy: 0.0517\n",
      "Epoch 28/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 2.9957 - accuracy: 0.0507 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 29/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 2.9957 - accuracy: 0.0515 - val_loss: 2.9959 - val_accuracy: 0.0522\n",
      "Epoch 30/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 2.9957 - accuracy: 0.0506 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 31/1000\n",
      "263/263 [==============================] - 3s 10ms/step - loss: 2.9957 - accuracy: 0.0504 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 32/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 2.9957 - accuracy: 0.0506 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 33/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 2.9957 - accuracy: 0.0511 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 34/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 2.9957 - accuracy: 0.0517 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 35/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 2.9957 - accuracy: 0.0514 - val_loss: 2.9958 - val_accuracy: 0.0522\n",
      "Epoch 36/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 2.9957 - accuracy: 0.0515 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 37/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 2.9957 - accuracy: 0.0493 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 38/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 2.9957 - accuracy: 0.0502 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 39/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 2.9957 - accuracy: 0.0509 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 40/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 2.9957 - accuracy: 0.0500 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 41/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 2.9957 - accuracy: 0.0503 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 42/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 2.9957 - accuracy: 0.0509 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 43/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 2.9957 - accuracy: 0.0516 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 44/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 2.9957 - accuracy: 0.0502 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 45/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 2.9957 - accuracy: 0.0508 - val_loss: 2.9960 - val_accuracy: 0.0517\n",
      "Epoch 46/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 2.9957 - accuracy: 0.0503 - val_loss: 2.9960 - val_accuracy: 0.0517\n",
      "Epoch 47/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 2.9957 - accuracy: 0.0514 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 48/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 2.9957 - accuracy: 0.0514 - val_loss: 2.9959 - val_accuracy: 0.0465\n",
      "Epoch 49/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 2.9957 - accuracy: 0.0502 - val_loss: 2.9959 - val_accuracy: 0.0517\n"
     ]
    }
   ],
   "source": [
    "train(model=model,\n",
    "      patience_train=10,\n",
    "      patience_val=None,\n",
    "      learning_rate=.001,\n",
    "      epochs=1000,\n",
    "      batch_size=128,\n",
    "      # cont_train=True,\n",
    "      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "gxqXfih1FttU",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 71867,
     "status": "ok",
     "timestamp": 1688896873301,
     "user": {
      "displayName": "Yoni Krichevsky",
      "userId": "07735752940575548299"
     },
     "user_tz": -180
    },
    "id": "gxqXfih1FttU",
    "outputId": "25167969-5843-422a-c219-f3d5010fd83a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patience_train=10, patience_val=None, learning_rate=0.0001, epochs=1000, batch_size=128, cont_train=False, X_train.shape=(33566, 32, 20), y_train.shape=(33566,), X_val.shape=(4619, 32, 20), y_val.shape=(4619,)\n",
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_16 (LSTM)              (None, 32, 128)           76288     \n",
      "                                                                 \n",
      " lstm_17 (LSTM)              (None, 128)               131584    \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_24 (Dense)            (None, 20)                2580      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 243,476\n",
      "Trainable params: 243,476\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Input shape (None, 32, 20), output shape (None, 20)\n",
      "Epoch 1/1000\n",
      "263/263 [==============================] - 7s 11ms/step - loss: 2.9955 - accuracy: 0.0517 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 2/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 2.9955 - accuracy: 0.0517 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 3/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 2.9955 - accuracy: 0.0517 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 4/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 2.9955 - accuracy: 0.0517 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 5/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 2.9955 - accuracy: 0.0517 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 6/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 2.9955 - accuracy: 0.0517 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 7/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 2.9955 - accuracy: 0.0517 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 8/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 2.9955 - accuracy: 0.0517 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 9/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 2.9955 - accuracy: 0.0517 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 10/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 2.9955 - accuracy: 0.0517 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 11/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 2.9955 - accuracy: 0.0517 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 12/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 2.9955 - accuracy: 0.0517 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 13/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 2.9955 - accuracy: 0.0517 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 14/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 2.9955 - accuracy: 0.0517 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 15/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 2.9955 - accuracy: 0.0517 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 16/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 2.9955 - accuracy: 0.0517 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 17/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 2.9955 - accuracy: 0.0517 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 18/1000\n",
      "263/263 [==============================] - 3s 10ms/step - loss: 2.9955 - accuracy: 0.0517 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 19/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 2.9955 - accuracy: 0.0517 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 20/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 2.9955 - accuracy: 0.0517 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 21/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 2.9955 - accuracy: 0.0517 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 22/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 2.9955 - accuracy: 0.0517 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 23/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 2.9955 - accuracy: 0.0517 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 24/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 2.9955 - accuracy: 0.0517 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 25/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 2.9955 - accuracy: 0.0517 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 26/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 2.9955 - accuracy: 0.0517 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 27/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 2.9955 - accuracy: 0.0517 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 28/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 2.9955 - accuracy: 0.0517 - val_loss: 2.9959 - val_accuracy: 0.0517\n"
     ]
    }
   ],
   "source": [
    "train(model=model,\n",
    "      patience_train=10,\n",
    "      patience_val=None,\n",
    "      learning_rate=.0001,\n",
    "      epochs=1000,\n",
    "      batch_size=128,\n",
    "      # cont_train=True,\n",
    "      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "UhsWzJ_3GXQG",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 46739,
     "status": "ok",
     "timestamp": 1688896945847,
     "user": {
      "displayName": "Yoni Krichevsky",
      "userId": "07735752940575548299"
     },
     "user_tz": -180
    },
    "id": "UhsWzJ_3GXQG",
    "outputId": "1f60a132-6b49-4faa-a84e-889316618fa3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patience_train=10, patience_val=None, learning_rate=0.0005, epochs=1000, batch_size=128, cont_train=False, X_train.shape=(33566, 32, 20), y_train.shape=(33566,), X_val.shape=(4619, 32, 20), y_val.shape=(4619,)\n",
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_16 (LSTM)              (None, 32, 128)           76288     \n",
      "                                                                 \n",
      " lstm_17 (LSTM)              (None, 128)               131584    \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_24 (Dense)            (None, 20)                2580      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 243,476\n",
      "Trainable params: 243,476\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Input shape (None, 32, 20), output shape (None, 20)\n",
      "Epoch 1/1000\n",
      "263/263 [==============================] - 8s 11ms/step - loss: 2.9956 - accuracy: 0.0500 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 2/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 2.9956 - accuracy: 0.0517 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 3/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 2.9956 - accuracy: 0.0510 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 4/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 2.9956 - accuracy: 0.0517 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 5/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 2.9956 - accuracy: 0.0507 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 6/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 2.9956 - accuracy: 0.0503 - val_loss: 2.9960 - val_accuracy: 0.0517\n",
      "Epoch 7/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 2.9956 - accuracy: 0.0517 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 8/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 2.9956 - accuracy: 0.0509 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 9/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 2.9956 - accuracy: 0.0517 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 10/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 2.9956 - accuracy: 0.0492 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 11/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 2.9956 - accuracy: 0.0517 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 12/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 2.9956 - accuracy: 0.0507 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 13/1000\n",
      "263/263 [==============================] - 3s 10ms/step - loss: 2.9956 - accuracy: 0.0517 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 14/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 2.9956 - accuracy: 0.0517 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 15/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 2.9956 - accuracy: 0.0517 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 16/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 2.9956 - accuracy: 0.0508 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 17/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 2.9956 - accuracy: 0.0517 - val_loss: 2.9959 - val_accuracy: 0.0517\n"
     ]
    }
   ],
   "source": [
    "train(model=model,\n",
    "      patience_train=10,\n",
    "      patience_val=None,\n",
    "      learning_rate=.0005,\n",
    "      epochs=1000,\n",
    "      batch_size=128,\n",
    "      # cont_train=True,\n",
    "      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a543NPiTGro3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 221528,
     "status": "ok",
     "timestamp": 1688897215717,
     "user": {
      "displayName": "Yoni Krichevsky",
      "userId": "07735752940575548299"
     },
     "user_tz": -180
    },
    "id": "a543NPiTGro3",
    "outputId": "9fd84619-50bf-4203-fab4-f882311ac54f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patience_train=10, patience_val=None, learning_rate=1e-05, epochs=1000, batch_size=128, cont_train=False, X_train.shape=(33566, 32, 20), y_train.shape=(33566,), X_val.shape=(4619, 32, 20), y_val.shape=(4619,)\n",
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_18 (LSTM)              (None, 32, 64)            21760     \n",
      "                                                                 \n",
      " lstm_19 (LSTM)              (None, 64)                33024     \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 64)                4160      \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, 64)                4160      \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_27 (Dense)            (None, 20)                1300      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 64,404\n",
      "Trainable params: 64,404\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Input shape (None, 32, 20), output shape (None, 20)\n",
      "Epoch 1/1000\n",
      "263/263 [==============================] - 8s 12ms/step - loss: 3.2771 - accuracy: 0.0495 - val_loss: 3.2095 - val_accuracy: 0.0565\n",
      "Epoch 2/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.2044 - accuracy: 0.0492 - val_loss: 3.1457 - val_accuracy: 0.0565\n",
      "Epoch 3/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.1497 - accuracy: 0.0496 - val_loss: 3.1027 - val_accuracy: 0.0565\n",
      "Epoch 4/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.1123 - accuracy: 0.0493 - val_loss: 3.0758 - val_accuracy: 0.0565\n",
      "Epoch 5/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0885 - accuracy: 0.0506 - val_loss: 3.0580 - val_accuracy: 0.0565\n",
      "Epoch 6/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0727 - accuracy: 0.0499 - val_loss: 3.0452 - val_accuracy: 0.0565\n",
      "Epoch 7/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0629 - accuracy: 0.0503 - val_loss: 3.0355 - val_accuracy: 0.0565\n",
      "Epoch 8/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0535 - accuracy: 0.0511 - val_loss: 3.0280 - val_accuracy: 0.0565\n",
      "Epoch 9/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0467 - accuracy: 0.0504 - val_loss: 3.0218 - val_accuracy: 0.0565\n",
      "Epoch 10/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0406 - accuracy: 0.0478 - val_loss: 3.0168 - val_accuracy: 0.0565\n",
      "Epoch 11/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0341 - accuracy: 0.0493 - val_loss: 3.0127 - val_accuracy: 0.0565\n",
      "Epoch 12/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0304 - accuracy: 0.0506 - val_loss: 3.0092 - val_accuracy: 0.0565\n",
      "Epoch 13/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0268 - accuracy: 0.0515 - val_loss: 3.0063 - val_accuracy: 0.0565\n",
      "Epoch 14/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0243 - accuracy: 0.0474 - val_loss: 3.0039 - val_accuracy: 0.0565\n",
      "Epoch 15/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0203 - accuracy: 0.0515 - val_loss: 3.0020 - val_accuracy: 0.0565\n",
      "Epoch 16/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0191 - accuracy: 0.0495 - val_loss: 3.0005 - val_accuracy: 0.0565\n",
      "Epoch 17/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0189 - accuracy: 0.0494 - val_loss: 2.9993 - val_accuracy: 0.0565\n",
      "Epoch 18/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0148 - accuracy: 0.0511 - val_loss: 2.9983 - val_accuracy: 0.0565\n",
      "Epoch 19/1000\n",
      "263/263 [==============================] - 3s 10ms/step - loss: 3.0151 - accuracy: 0.0505 - val_loss: 2.9976 - val_accuracy: 0.0565\n",
      "Epoch 20/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0150 - accuracy: 0.0496 - val_loss: 2.9971 - val_accuracy: 0.0565\n",
      "Epoch 21/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0143 - accuracy: 0.0487 - val_loss: 2.9968 - val_accuracy: 0.0481\n",
      "Epoch 22/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0138 - accuracy: 0.0505 - val_loss: 2.9965 - val_accuracy: 0.0487\n",
      "Epoch 23/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0130 - accuracy: 0.0487 - val_loss: 2.9963 - val_accuracy: 0.0487\n",
      "Epoch 24/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0127 - accuracy: 0.0503 - val_loss: 2.9962 - val_accuracy: 0.0487\n",
      "Epoch 25/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 3.0098 - accuracy: 0.0510 - val_loss: 2.9961 - val_accuracy: 0.0487\n",
      "Epoch 26/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 3.0112 - accuracy: 0.0494 - val_loss: 2.9960 - val_accuracy: 0.0487\n",
      "Epoch 27/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0116 - accuracy: 0.0515 - val_loss: 2.9960 - val_accuracy: 0.0520\n",
      "Epoch 28/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0111 - accuracy: 0.0499 - val_loss: 2.9960 - val_accuracy: 0.0517\n",
      "Epoch 29/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0123 - accuracy: 0.0478 - val_loss: 2.9960 - val_accuracy: 0.0517\n",
      "Epoch 30/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0085 - accuracy: 0.0535 - val_loss: 2.9960 - val_accuracy: 0.0517\n",
      "Epoch 31/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 3.0093 - accuracy: 0.0506 - val_loss: 2.9960 - val_accuracy: 0.0517\n",
      "Epoch 32/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 3.0105 - accuracy: 0.0492 - val_loss: 2.9960 - val_accuracy: 0.0517\n",
      "Epoch 33/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 3.0102 - accuracy: 0.0507 - val_loss: 2.9960 - val_accuracy: 0.0517\n",
      "Epoch 34/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0115 - accuracy: 0.0512 - val_loss: 2.9960 - val_accuracy: 0.0517\n",
      "Epoch 35/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0096 - accuracy: 0.0488 - val_loss: 2.9960 - val_accuracy: 0.0517\n",
      "Epoch 36/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0115 - accuracy: 0.0501 - val_loss: 2.9960 - val_accuracy: 0.0517\n",
      "Epoch 37/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0085 - accuracy: 0.0526 - val_loss: 2.9960 - val_accuracy: 0.0517\n",
      "Epoch 38/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0109 - accuracy: 0.0490 - val_loss: 2.9960 - val_accuracy: 0.0517\n",
      "Epoch 39/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0099 - accuracy: 0.0504 - val_loss: 2.9960 - val_accuracy: 0.0517\n",
      "Epoch 40/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0088 - accuracy: 0.0494 - val_loss: 2.9960 - val_accuracy: 0.0517\n",
      "Epoch 41/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0087 - accuracy: 0.0497 - val_loss: 2.9960 - val_accuracy: 0.0517\n",
      "Epoch 42/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0096 - accuracy: 0.0496 - val_loss: 2.9960 - val_accuracy: 0.0517\n",
      "Epoch 43/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0091 - accuracy: 0.0492 - val_loss: 2.9960 - val_accuracy: 0.0517\n",
      "Epoch 44/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0077 - accuracy: 0.0523 - val_loss: 2.9960 - val_accuracy: 0.0517\n",
      "Epoch 45/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0084 - accuracy: 0.0483 - val_loss: 2.9960 - val_accuracy: 0.0517\n",
      "Epoch 46/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0092 - accuracy: 0.0495 - val_loss: 2.9960 - val_accuracy: 0.0517\n",
      "Epoch 47/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0089 - accuracy: 0.0513 - val_loss: 2.9960 - val_accuracy: 0.0517\n",
      "Epoch 48/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0081 - accuracy: 0.0501 - val_loss: 2.9960 - val_accuracy: 0.0517\n",
      "Epoch 49/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0084 - accuracy: 0.0510 - val_loss: 2.9960 - val_accuracy: 0.0517\n",
      "Epoch 50/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0085 - accuracy: 0.0499 - val_loss: 2.9960 - val_accuracy: 0.0517\n",
      "Epoch 51/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0074 - accuracy: 0.0505 - val_loss: 2.9960 - val_accuracy: 0.0517\n",
      "Epoch 52/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0081 - accuracy: 0.0504 - val_loss: 2.9960 - val_accuracy: 0.0517\n",
      "Epoch 53/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0080 - accuracy: 0.0490 - val_loss: 2.9960 - val_accuracy: 0.0517\n",
      "Epoch 54/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0073 - accuracy: 0.0517 - val_loss: 2.9960 - val_accuracy: 0.0517\n",
      "Epoch 55/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0069 - accuracy: 0.0521 - val_loss: 2.9960 - val_accuracy: 0.0517\n",
      "Epoch 56/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0056 - accuracy: 0.0507 - val_loss: 2.9960 - val_accuracy: 0.0517\n",
      "Epoch 57/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0082 - accuracy: 0.0495 - val_loss: 2.9960 - val_accuracy: 0.0517\n",
      "Epoch 58/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0067 - accuracy: 0.0512 - val_loss: 2.9960 - val_accuracy: 0.0517\n",
      "Epoch 59/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0065 - accuracy: 0.0491 - val_loss: 2.9960 - val_accuracy: 0.0517\n",
      "Epoch 60/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0065 - accuracy: 0.0506 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 61/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0062 - accuracy: 0.0520 - val_loss: 2.9960 - val_accuracy: 0.0517\n",
      "Epoch 62/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 3.0053 - accuracy: 0.0509 - val_loss: 2.9960 - val_accuracy: 0.0517\n",
      "Epoch 63/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 3.0063 - accuracy: 0.0488 - val_loss: 2.9960 - val_accuracy: 0.0517\n",
      "Epoch 64/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0062 - accuracy: 0.0492 - val_loss: 2.9960 - val_accuracy: 0.0517\n",
      "Epoch 65/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0075 - accuracy: 0.0492 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 66/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0047 - accuracy: 0.0516 - val_loss: 2.9960 - val_accuracy: 0.0517\n",
      "Epoch 67/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0065 - accuracy: 0.0495 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 68/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 3.0058 - accuracy: 0.0488 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 69/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 3.0046 - accuracy: 0.0509 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 70/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0065 - accuracy: 0.0485 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 71/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0069 - accuracy: 0.0502 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 72/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0057 - accuracy: 0.0523 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 73/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0052 - accuracy: 0.0509 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 74/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0059 - accuracy: 0.0520 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 75/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0052 - accuracy: 0.0497 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 76/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0060 - accuracy: 0.0497 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 77/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0053 - accuracy: 0.0482 - val_loss: 2.9959 - val_accuracy: 0.0522\n",
      "Epoch 78/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0070 - accuracy: 0.0488 - val_loss: 2.9960 - val_accuracy: 0.0517\n",
      "Epoch 79/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0040 - accuracy: 0.0507 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 80/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0054 - accuracy: 0.0520 - val_loss: 2.9960 - val_accuracy: 0.0517\n",
      "Epoch 81/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0055 - accuracy: 0.0517 - val_loss: 2.9960 - val_accuracy: 0.0520\n",
      "Epoch 82/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0026 - accuracy: 0.0508 - val_loss: 2.9960 - val_accuracy: 0.0520\n",
      "Epoch 83/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0046 - accuracy: 0.0500 - val_loss: 2.9959 - val_accuracy: 0.0522\n",
      "Epoch 84/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0050 - accuracy: 0.0484 - val_loss: 2.9960 - val_accuracy: 0.0517\n",
      "Epoch 85/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0041 - accuracy: 0.0512 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 86/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0042 - accuracy: 0.0526 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 87/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0046 - accuracy: 0.0497 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 88/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0037 - accuracy: 0.0489 - val_loss: 2.9959 - val_accuracy: 0.0515\n",
      "Epoch 89/1000\n",
      "263/263 [==============================] - 3s 10ms/step - loss: 3.0035 - accuracy: 0.0517 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 90/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0028 - accuracy: 0.0506 - val_loss: 2.9959 - val_accuracy: 0.0515\n",
      "Epoch 91/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0042 - accuracy: 0.0490 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 92/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0044 - accuracy: 0.0494 - val_loss: 2.9959 - val_accuracy: 0.0517\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([LSTM(64, input_shape=(32, 20), return_sequences=True, dropout=.1),\n",
    "                    LSTM(64, dropout=.1),\n",
    "                    Dropout(.1),\n",
    "                    Dense(64, activation='sigmoid'),\n",
    "                    Dropout(.1),\n",
    "                    Dense(64, activation='sigmoid'),\n",
    "                    Dropout(.1),\n",
    "                    Dense(20, activation='softmax')])\n",
    "train(model=model,\n",
    "      patience_train=10,\n",
    "      patience_val=None,\n",
    "      learning_rate=.00001,\n",
    "      epochs=1000,\n",
    "      batch_size=128,\n",
    "      # cont_train=True,\n",
    "      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1vV_FAVrHqZl",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 75304,
     "status": "ok",
     "timestamp": 1688897315900,
     "user": {
      "displayName": "Yoni Krichevsky",
      "userId": "07735752940575548299"
     },
     "user_tz": -180
    },
    "id": "1vV_FAVrHqZl",
    "outputId": "7959b6bc-35a2-4f65-975f-5ee2c1a49cc4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patience_train=10, patience_val=None, learning_rate=1e-06, epochs=1000, batch_size=128, cont_train=False, X_train.shape=(33566, 32, 20), y_train.shape=(33566,), X_val.shape=(4619, 32, 20), y_val.shape=(4619,)\n",
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_18 (LSTM)              (None, 32, 64)            21760     \n",
      "                                                                 \n",
      " lstm_19 (LSTM)              (None, 64)                33024     \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 64)                4160      \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, 64)                4160      \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_27 (Dense)            (None, 20)                1300      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 64,404\n",
      "Trainable params: 64,404\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Input shape (None, 32, 20), output shape (None, 20)\n",
      "Epoch 1/1000\n",
      "263/263 [==============================] - 7s 11ms/step - loss: 3.0044 - accuracy: 0.0492 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 2/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0048 - accuracy: 0.0507 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 3/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0044 - accuracy: 0.0498 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 4/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0036 - accuracy: 0.0498 - val_loss: 2.9959 - val_accuracy: 0.0520\n",
      "Epoch 5/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0033 - accuracy: 0.0511 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 6/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0038 - accuracy: 0.0495 - val_loss: 2.9959 - val_accuracy: 0.0520\n",
      "Epoch 7/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0036 - accuracy: 0.0487 - val_loss: 2.9959 - val_accuracy: 0.0520\n",
      "Epoch 8/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0031 - accuracy: 0.0509 - val_loss: 2.9959 - val_accuracy: 0.0520\n",
      "Epoch 9/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0047 - accuracy: 0.0506 - val_loss: 2.9959 - val_accuracy: 0.0520\n",
      "Epoch 10/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0031 - accuracy: 0.0514 - val_loss: 2.9959 - val_accuracy: 0.0520\n",
      "Epoch 11/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0044 - accuracy: 0.0512 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 12/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0037 - accuracy: 0.0484 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 13/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0031 - accuracy: 0.0494 - val_loss: 2.9959 - val_accuracy: 0.0515\n",
      "Epoch 14/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0040 - accuracy: 0.0506 - val_loss: 2.9959 - val_accuracy: 0.0515\n",
      "Epoch 15/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0036 - accuracy: 0.0516 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 16/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0047 - accuracy: 0.0477 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 17/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0040 - accuracy: 0.0501 - val_loss: 2.9959 - val_accuracy: 0.0515\n",
      "Epoch 18/1000\n",
      "263/263 [==============================] - 3s 10ms/step - loss: 3.0049 - accuracy: 0.0488 - val_loss: 2.9959 - val_accuracy: 0.0515\n",
      "Epoch 19/1000\n",
      "263/263 [==============================] - 3s 10ms/step - loss: 3.0013 - accuracy: 0.0520 - val_loss: 2.9959 - val_accuracy: 0.0515\n",
      "Epoch 20/1000\n",
      "263/263 [==============================] - 3s 10ms/step - loss: 3.0034 - accuracy: 0.0491 - val_loss: 2.9959 - val_accuracy: 0.0515\n",
      "Epoch 21/1000\n",
      "263/263 [==============================] - 3s 10ms/step - loss: 3.0026 - accuracy: 0.0526 - val_loss: 2.9959 - val_accuracy: 0.0515\n",
      "Epoch 22/1000\n",
      "263/263 [==============================] - 3s 10ms/step - loss: 3.0019 - accuracy: 0.0526 - val_loss: 2.9959 - val_accuracy: 0.0515\n",
      "Epoch 23/1000\n",
      "263/263 [==============================] - 3s 10ms/step - loss: 3.0021 - accuracy: 0.0504 - val_loss: 2.9959 - val_accuracy: 0.0515\n",
      "Epoch 24/1000\n",
      "263/263 [==============================] - 3s 10ms/step - loss: 3.0029 - accuracy: 0.0499 - val_loss: 2.9959 - val_accuracy: 0.0513\n",
      "Epoch 25/1000\n",
      "263/263 [==============================] - 3s 10ms/step - loss: 3.0033 - accuracy: 0.0511 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 26/1000\n",
      "263/263 [==============================] - 3s 10ms/step - loss: 3.0045 - accuracy: 0.0494 - val_loss: 2.9959 - val_accuracy: 0.0515\n",
      "Epoch 27/1000\n",
      "263/263 [==============================] - 3s 10ms/step - loss: 3.0043 - accuracy: 0.0493 - val_loss: 2.9959 - val_accuracy: 0.0515\n",
      "Epoch 28/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0034 - accuracy: 0.0499 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 29/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 3.0024 - accuracy: 0.0528 - val_loss: 2.9959 - val_accuracy: 0.0517\n"
     ]
    }
   ],
   "source": [
    "train(model=model,\n",
    "      patience_train=10,\n",
    "      patience_val=None,\n",
    "      learning_rate=.000001,\n",
    "      epochs=1000,\n",
    "      batch_size=128,\n",
    "      # cont_train=True,\n",
    "      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "S21K6dbsIEGD",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 105185,
     "status": "ok",
     "timestamp": 1688897451890,
     "user": {
      "displayName": "Yoni Krichevsky",
      "userId": "07735752940575548299"
     },
     "user_tz": -180
    },
    "id": "S21K6dbsIEGD",
    "outputId": "510ab272-2cc1-418a-bfe6-6b6159db69f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patience_train=20, patience_val=None, learning_rate=1e-06, epochs=1000, batch_size=128, cont_train=False, X_train.shape=(33566, 32, 20), y_train.shape=(33566,), X_val.shape=(4619, 32, 20), y_val.shape=(4619,)\n",
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_18 (LSTM)              (None, 32, 64)            21760     \n",
      "                                                                 \n",
      " lstm_19 (LSTM)              (None, 64)                33024     \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 64)                4160      \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, 64)                4160      \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_27 (Dense)            (None, 20)                1300      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 64,404\n",
      "Trainable params: 64,404\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Input shape (None, 32, 20), output shape (None, 20)\n",
      "Epoch 1/1000\n",
      "263/263 [==============================] - 9s 13ms/step - loss: 3.0041 - accuracy: 0.0517 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 2/1000\n",
      "263/263 [==============================] - 3s 10ms/step - loss: 3.0021 - accuracy: 0.0526 - val_loss: 2.9959 - val_accuracy: 0.0515\n",
      "Epoch 3/1000\n",
      "263/263 [==============================] - 3s 10ms/step - loss: 3.0047 - accuracy: 0.0480 - val_loss: 2.9959 - val_accuracy: 0.0515\n",
      "Epoch 4/1000\n",
      "263/263 [==============================] - 3s 10ms/step - loss: 3.0040 - accuracy: 0.0509 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 5/1000\n",
      "263/263 [==============================] - 3s 10ms/step - loss: 3.0039 - accuracy: 0.0509 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 6/1000\n",
      "263/263 [==============================] - 3s 10ms/step - loss: 3.0037 - accuracy: 0.0514 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 7/1000\n",
      "263/263 [==============================] - 3s 10ms/step - loss: 3.0035 - accuracy: 0.0508 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 8/1000\n",
      "263/263 [==============================] - 3s 10ms/step - loss: 3.0028 - accuracy: 0.0522 - val_loss: 2.9959 - val_accuracy: 0.0515\n",
      "Epoch 9/1000\n",
      "263/263 [==============================] - 3s 10ms/step - loss: 3.0037 - accuracy: 0.0515 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 10/1000\n",
      "263/263 [==============================] - 3s 10ms/step - loss: 3.0044 - accuracy: 0.0496 - val_loss: 2.9959 - val_accuracy: 0.0515\n",
      "Epoch 11/1000\n",
      "263/263 [==============================] - 3s 10ms/step - loss: 3.0031 - accuracy: 0.0509 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 12/1000\n",
      "263/263 [==============================] - 3s 10ms/step - loss: 3.0036 - accuracy: 0.0501 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 13/1000\n",
      "263/263 [==============================] - 3s 10ms/step - loss: 3.0041 - accuracy: 0.0490 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 14/1000\n",
      "263/263 [==============================] - 3s 10ms/step - loss: 3.0047 - accuracy: 0.0490 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 15/1000\n",
      "263/263 [==============================] - 3s 10ms/step - loss: 3.0040 - accuracy: 0.0505 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 16/1000\n",
      "263/263 [==============================] - 3s 10ms/step - loss: 3.0023 - accuracy: 0.0516 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 17/1000\n",
      "263/263 [==============================] - 3s 10ms/step - loss: 3.0033 - accuracy: 0.0511 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 18/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0031 - accuracy: 0.0499 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 19/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 3.0036 - accuracy: 0.0481 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 20/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 3.0018 - accuracy: 0.0506 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 21/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0026 - accuracy: 0.0512 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 22/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0044 - accuracy: 0.0505 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 23/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0044 - accuracy: 0.0507 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 24/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0039 - accuracy: 0.0505 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 25/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 3.0031 - accuracy: 0.0497 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 26/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 3.0024 - accuracy: 0.0526 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 27/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0035 - accuracy: 0.0501 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 28/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0034 - accuracy: 0.0498 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 29/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0034 - accuracy: 0.0508 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 30/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0035 - accuracy: 0.0504 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 31/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0035 - accuracy: 0.0489 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 32/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0041 - accuracy: 0.0517 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 33/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0032 - accuracy: 0.0486 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 34/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0028 - accuracy: 0.0518 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 35/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0029 - accuracy: 0.0509 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 36/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0030 - accuracy: 0.0504 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 37/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0026 - accuracy: 0.0513 - val_loss: 2.9959 - val_accuracy: 0.0515\n",
      "Epoch 38/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0027 - accuracy: 0.0530 - val_loss: 2.9959 - val_accuracy: 0.0515\n",
      "Epoch 39/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0026 - accuracy: 0.0498 - val_loss: 2.9959 - val_accuracy: 0.0513\n",
      "Epoch 40/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0034 - accuracy: 0.0507 - val_loss: 2.9959 - val_accuracy: 0.0513\n"
     ]
    }
   ],
   "source": [
    "train(model=model,\n",
    "      patience_train=20,\n",
    "      patience_val=None,\n",
    "      learning_rate=.000001,\n",
    "      epochs=1000,\n",
    "      batch_size=128,\n",
    "      # cont_train=True,\n",
    "      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "hfXWqen0Ir5M",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 198788,
     "status": "ok",
     "timestamp": 1688897739374,
     "user": {
      "displayName": "Yoni Krichevsky",
      "userId": "07735752940575548299"
     },
     "user_tz": -180
    },
    "id": "hfXWqen0Ir5M",
    "outputId": "8990f421-fd3c-45eb-bd27-d1e1fadda6cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patience_train=10, patience_val=None, learning_rate=1e-05, epochs=1000, batch_size=128, cont_train=False, X_train.shape=(33566, 32, 20), y_train.shape=(33566,), X_val.shape=(4619, 32, 20), y_val.shape=(4619,)\n",
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_20 (LSTM)              (None, 128)               76288     \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_28 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " dropout_10 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_29 (Dense)            (None, 20)                2580      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 95,380\n",
      "Trainable params: 95,380\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Input shape (None, 32, 20), output shape (None, 20)\n",
      "Epoch 1/1000\n",
      "263/263 [==============================] - 5s 8ms/step - loss: 3.1450 - accuracy: 0.0501 - val_loss: 3.0786 - val_accuracy: 0.0535\n",
      "Epoch 2/1000\n",
      "263/263 [==============================] - 2s 6ms/step - loss: 3.0759 - accuracy: 0.0501 - val_loss: 3.0277 - val_accuracy: 0.0535\n",
      "Epoch 3/1000\n",
      "263/263 [==============================] - 2s 6ms/step - loss: 3.0381 - accuracy: 0.0528 - val_loss: 3.0052 - val_accuracy: 0.0446\n",
      "Epoch 4/1000\n",
      "263/263 [==============================] - 2s 6ms/step - loss: 3.0243 - accuracy: 0.0493 - val_loss: 2.9983 - val_accuracy: 0.0448\n",
      "Epoch 5/1000\n",
      "263/263 [==============================] - 2s 6ms/step - loss: 3.0194 - accuracy: 0.0515 - val_loss: 2.9967 - val_accuracy: 0.0459\n",
      "Epoch 6/1000\n",
      "263/263 [==============================] - 2s 6ms/step - loss: 3.0203 - accuracy: 0.0486 - val_loss: 2.9963 - val_accuracy: 0.0491\n",
      "Epoch 7/1000\n",
      "263/263 [==============================] - 2s 6ms/step - loss: 3.0170 - accuracy: 0.0502 - val_loss: 2.9962 - val_accuracy: 0.0522\n",
      "Epoch 8/1000\n",
      "263/263 [==============================] - 2s 6ms/step - loss: 3.0180 - accuracy: 0.0475 - val_loss: 2.9961 - val_accuracy: 0.0498\n",
      "Epoch 9/1000\n",
      "263/263 [==============================] - 2s 6ms/step - loss: 3.0162 - accuracy: 0.0520 - val_loss: 2.9962 - val_accuracy: 0.0478\n",
      "Epoch 10/1000\n",
      "263/263 [==============================] - 2s 6ms/step - loss: 3.0170 - accuracy: 0.0484 - val_loss: 2.9962 - val_accuracy: 0.0485\n",
      "Epoch 11/1000\n",
      "263/263 [==============================] - 2s 6ms/step - loss: 3.0158 - accuracy: 0.0496 - val_loss: 2.9962 - val_accuracy: 0.0502\n",
      "Epoch 12/1000\n",
      "263/263 [==============================] - 2s 6ms/step - loss: 3.0159 - accuracy: 0.0487 - val_loss: 2.9961 - val_accuracy: 0.0517\n",
      "Epoch 13/1000\n",
      "263/263 [==============================] - 2s 6ms/step - loss: 3.0155 - accuracy: 0.0496 - val_loss: 2.9961 - val_accuracy: 0.0498\n",
      "Epoch 14/1000\n",
      "263/263 [==============================] - 2s 6ms/step - loss: 3.0151 - accuracy: 0.0496 - val_loss: 2.9961 - val_accuracy: 0.0489\n",
      "Epoch 15/1000\n",
      "263/263 [==============================] - 2s 6ms/step - loss: 3.0169 - accuracy: 0.0520 - val_loss: 2.9962 - val_accuracy: 0.0513\n",
      "Epoch 16/1000\n",
      "263/263 [==============================] - 2s 6ms/step - loss: 3.0140 - accuracy: 0.0494 - val_loss: 2.9962 - val_accuracy: 0.0513\n",
      "Epoch 17/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 3.0141 - accuracy: 0.0515 - val_loss: 2.9961 - val_accuracy: 0.0528\n",
      "Epoch 18/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 3.0140 - accuracy: 0.0506 - val_loss: 2.9962 - val_accuracy: 0.0500\n",
      "Epoch 19/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 3.0138 - accuracy: 0.0504 - val_loss: 2.9962 - val_accuracy: 0.0502\n",
      "Epoch 20/1000\n",
      "263/263 [==============================] - 2s 6ms/step - loss: 3.0153 - accuracy: 0.0492 - val_loss: 2.9961 - val_accuracy: 0.0509\n",
      "Epoch 21/1000\n",
      "263/263 [==============================] - 2s 6ms/step - loss: 3.0134 - accuracy: 0.0506 - val_loss: 2.9961 - val_accuracy: 0.0494\n",
      "Epoch 22/1000\n",
      "263/263 [==============================] - 2s 6ms/step - loss: 3.0126 - accuracy: 0.0493 - val_loss: 2.9961 - val_accuracy: 0.0517\n",
      "Epoch 23/1000\n",
      "263/263 [==============================] - 2s 6ms/step - loss: 3.0112 - accuracy: 0.0489 - val_loss: 2.9961 - val_accuracy: 0.0524\n",
      "Epoch 24/1000\n",
      "263/263 [==============================] - 2s 6ms/step - loss: 3.0113 - accuracy: 0.0503 - val_loss: 2.9961 - val_accuracy: 0.0541\n",
      "Epoch 25/1000\n",
      "263/263 [==============================] - 2s 6ms/step - loss: 3.0125 - accuracy: 0.0520 - val_loss: 2.9961 - val_accuracy: 0.0502\n",
      "Epoch 26/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 3.0115 - accuracy: 0.0522 - val_loss: 2.9961 - val_accuracy: 0.0515\n",
      "Epoch 27/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 3.0122 - accuracy: 0.0501 - val_loss: 2.9961 - val_accuracy: 0.0524\n",
      "Epoch 28/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 3.0124 - accuracy: 0.0490 - val_loss: 2.9961 - val_accuracy: 0.0515\n",
      "Epoch 29/1000\n",
      "263/263 [==============================] - 2s 6ms/step - loss: 3.0098 - accuracy: 0.0511 - val_loss: 2.9961 - val_accuracy: 0.0524\n",
      "Epoch 30/1000\n",
      "263/263 [==============================] - 2s 6ms/step - loss: 3.0099 - accuracy: 0.0488 - val_loss: 2.9962 - val_accuracy: 0.0491\n",
      "Epoch 31/1000\n",
      "263/263 [==============================] - 2s 6ms/step - loss: 3.0117 - accuracy: 0.0494 - val_loss: 2.9961 - val_accuracy: 0.0522\n",
      "Epoch 32/1000\n",
      "263/263 [==============================] - 2s 6ms/step - loss: 3.0093 - accuracy: 0.0508 - val_loss: 2.9962 - val_accuracy: 0.0520\n",
      "Epoch 33/1000\n",
      "263/263 [==============================] - 2s 6ms/step - loss: 3.0107 - accuracy: 0.0508 - val_loss: 2.9960 - val_accuracy: 0.0546\n",
      "Epoch 34/1000\n",
      "263/263 [==============================] - 2s 6ms/step - loss: 3.0080 - accuracy: 0.0511 - val_loss: 2.9961 - val_accuracy: 0.0528\n",
      "Epoch 35/1000\n",
      "263/263 [==============================] - 2s 6ms/step - loss: 3.0088 - accuracy: 0.0523 - val_loss: 2.9961 - val_accuracy: 0.0533\n",
      "Epoch 36/1000\n",
      "263/263 [==============================] - 2s 6ms/step - loss: 3.0100 - accuracy: 0.0494 - val_loss: 2.9960 - val_accuracy: 0.0507\n",
      "Epoch 37/1000\n",
      "263/263 [==============================] - 2s 6ms/step - loss: 3.0077 - accuracy: 0.0529 - val_loss: 2.9959 - val_accuracy: 0.0548\n",
      "Epoch 38/1000\n",
      "263/263 [==============================] - 2s 6ms/step - loss: 3.0098 - accuracy: 0.0515 - val_loss: 2.9960 - val_accuracy: 0.0535\n",
      "Epoch 39/1000\n",
      "263/263 [==============================] - 2s 6ms/step - loss: 3.0076 - accuracy: 0.0512 - val_loss: 2.9960 - val_accuracy: 0.0528\n",
      "Epoch 40/1000\n",
      "263/263 [==============================] - 2s 6ms/step - loss: 3.0082 - accuracy: 0.0514 - val_loss: 2.9961 - val_accuracy: 0.0528\n",
      "Epoch 41/1000\n",
      "263/263 [==============================] - 2s 6ms/step - loss: 3.0093 - accuracy: 0.0477 - val_loss: 2.9961 - val_accuracy: 0.0513\n",
      "Epoch 42/1000\n",
      "263/263 [==============================] - 2s 6ms/step - loss: 3.0084 - accuracy: 0.0509 - val_loss: 2.9961 - val_accuracy: 0.0546\n",
      "Epoch 43/1000\n",
      "263/263 [==============================] - 2s 6ms/step - loss: 3.0081 - accuracy: 0.0482 - val_loss: 2.9962 - val_accuracy: 0.0528\n",
      "Epoch 44/1000\n",
      "263/263 [==============================] - 2s 6ms/step - loss: 3.0085 - accuracy: 0.0501 - val_loss: 2.9962 - val_accuracy: 0.0522\n",
      "Epoch 45/1000\n",
      "263/263 [==============================] - 2s 6ms/step - loss: 3.0071 - accuracy: 0.0523 - val_loss: 2.9962 - val_accuracy: 0.0522\n",
      "Epoch 46/1000\n",
      "263/263 [==============================] - 2s 6ms/step - loss: 3.0085 - accuracy: 0.0502 - val_loss: 2.9961 - val_accuracy: 0.0526\n",
      "Epoch 47/1000\n",
      "263/263 [==============================] - 2s 6ms/step - loss: 3.0078 - accuracy: 0.0497 - val_loss: 2.9960 - val_accuracy: 0.0517\n",
      "Epoch 48/1000\n",
      "263/263 [==============================] - 2s 6ms/step - loss: 3.0069 - accuracy: 0.0504 - val_loss: 2.9961 - val_accuracy: 0.0522\n",
      "Epoch 49/1000\n",
      "263/263 [==============================] - 2s 6ms/step - loss: 3.0064 - accuracy: 0.0494 - val_loss: 2.9962 - val_accuracy: 0.0522\n",
      "Epoch 50/1000\n",
      "263/263 [==============================] - 2s 6ms/step - loss: 3.0069 - accuracy: 0.0505 - val_loss: 2.9962 - val_accuracy: 0.0530\n",
      "Epoch 51/1000\n",
      "263/263 [==============================] - 2s 6ms/step - loss: 3.0073 - accuracy: 0.0489 - val_loss: 2.9961 - val_accuracy: 0.0524\n",
      "Epoch 52/1000\n",
      "263/263 [==============================] - 2s 6ms/step - loss: 3.0079 - accuracy: 0.0485 - val_loss: 2.9961 - val_accuracy: 0.0504\n",
      "Epoch 53/1000\n",
      "263/263 [==============================] - 2s 6ms/step - loss: 3.0061 - accuracy: 0.0528 - val_loss: 2.9960 - val_accuracy: 0.0515\n",
      "Epoch 54/1000\n",
      "263/263 [==============================] - 2s 6ms/step - loss: 3.0056 - accuracy: 0.0503 - val_loss: 2.9961 - val_accuracy: 0.0513\n",
      "Epoch 55/1000\n",
      "263/263 [==============================] - 2s 6ms/step - loss: 3.0056 - accuracy: 0.0522 - val_loss: 2.9961 - val_accuracy: 0.0513\n",
      "Epoch 56/1000\n",
      "263/263 [==============================] - 2s 6ms/step - loss: 3.0068 - accuracy: 0.0487 - val_loss: 2.9961 - val_accuracy: 0.0513\n",
      "Epoch 57/1000\n",
      "263/263 [==============================] - 2s 6ms/step - loss: 3.0069 - accuracy: 0.0478 - val_loss: 2.9961 - val_accuracy: 0.0491\n",
      "Epoch 58/1000\n",
      "263/263 [==============================] - 2s 6ms/step - loss: 3.0071 - accuracy: 0.0481 - val_loss: 2.9962 - val_accuracy: 0.0504\n",
      "Epoch 59/1000\n",
      "263/263 [==============================] - 2s 6ms/step - loss: 3.0050 - accuracy: 0.0506 - val_loss: 2.9961 - val_accuracy: 0.0509\n",
      "Epoch 60/1000\n",
      "263/263 [==============================] - 2s 6ms/step - loss: 3.0058 - accuracy: 0.0492 - val_loss: 2.9960 - val_accuracy: 0.0528\n",
      "Epoch 61/1000\n",
      "263/263 [==============================] - 2s 6ms/step - loss: 3.0054 - accuracy: 0.0510 - val_loss: 2.9960 - val_accuracy: 0.0526\n",
      "Epoch 62/1000\n",
      "263/263 [==============================] - 2s 6ms/step - loss: 3.0035 - accuracy: 0.0524 - val_loss: 2.9961 - val_accuracy: 0.0541\n",
      "Epoch 63/1000\n",
      "263/263 [==============================] - 2s 6ms/step - loss: 3.0043 - accuracy: 0.0497 - val_loss: 2.9960 - val_accuracy: 0.0526\n",
      "Epoch 64/1000\n",
      "263/263 [==============================] - 2s 6ms/step - loss: 3.0048 - accuracy: 0.0500 - val_loss: 2.9961 - val_accuracy: 0.0526\n",
      "Epoch 65/1000\n",
      "263/263 [==============================] - 2s 6ms/step - loss: 3.0042 - accuracy: 0.0496 - val_loss: 2.9961 - val_accuracy: 0.0513\n",
      "Epoch 66/1000\n",
      "263/263 [==============================] - 2s 6ms/step - loss: 3.0034 - accuracy: 0.0526 - val_loss: 2.9960 - val_accuracy: 0.0541\n",
      "Epoch 67/1000\n",
      "263/263 [==============================] - 2s 6ms/step - loss: 3.0039 - accuracy: 0.0502 - val_loss: 2.9960 - val_accuracy: 0.0533\n",
      "Epoch 68/1000\n",
      "263/263 [==============================] - 2s 6ms/step - loss: 3.0039 - accuracy: 0.0505 - val_loss: 2.9960 - val_accuracy: 0.0511\n",
      "Epoch 69/1000\n",
      "263/263 [==============================] - 2s 6ms/step - loss: 3.0030 - accuracy: 0.0484 - val_loss: 2.9961 - val_accuracy: 0.0539\n",
      "Epoch 70/1000\n",
      "263/263 [==============================] - 2s 6ms/step - loss: 3.0041 - accuracy: 0.0506 - val_loss: 2.9960 - val_accuracy: 0.0517\n",
      "Epoch 71/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 3.0026 - accuracy: 0.0529 - val_loss: 2.9960 - val_accuracy: 0.0507\n",
      "Epoch 72/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 3.0033 - accuracy: 0.0509 - val_loss: 2.9961 - val_accuracy: 0.0539\n",
      "Epoch 73/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 3.0035 - accuracy: 0.0517 - val_loss: 2.9961 - val_accuracy: 0.0541\n",
      "Epoch 74/1000\n",
      "263/263 [==============================] - 2s 6ms/step - loss: 3.0034 - accuracy: 0.0477 - val_loss: 2.9961 - val_accuracy: 0.0522\n",
      "Epoch 75/1000\n",
      "263/263 [==============================] - 2s 6ms/step - loss: 3.0034 - accuracy: 0.0496 - val_loss: 2.9961 - val_accuracy: 0.0522\n",
      "Epoch 76/1000\n",
      "263/263 [==============================] - 2s 6ms/step - loss: 3.0040 - accuracy: 0.0495 - val_loss: 2.9960 - val_accuracy: 0.0507\n",
      "Epoch 77/1000\n",
      "263/263 [==============================] - 2s 6ms/step - loss: 3.0042 - accuracy: 0.0483 - val_loss: 2.9961 - val_accuracy: 0.0515\n",
      "Epoch 78/1000\n",
      "263/263 [==============================] - 2s 6ms/step - loss: 3.0019 - accuracy: 0.0515 - val_loss: 2.9961 - val_accuracy: 0.0511\n",
      "Epoch 79/1000\n",
      "263/263 [==============================] - 1s 6ms/step - loss: 3.0033 - accuracy: 0.0480 - val_loss: 2.9961 - val_accuracy: 0.0526\n",
      "Epoch 80/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 3.0019 - accuracy: 0.0501 - val_loss: 2.9961 - val_accuracy: 0.0533\n",
      "Epoch 81/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 3.0023 - accuracy: 0.0510 - val_loss: 2.9961 - val_accuracy: 0.0541\n",
      "Epoch 82/1000\n",
      "263/263 [==============================] - 1s 5ms/step - loss: 3.0038 - accuracy: 0.0498 - val_loss: 2.9962 - val_accuracy: 0.0541\n",
      "Epoch 83/1000\n",
      "263/263 [==============================] - 2s 6ms/step - loss: 3.0023 - accuracy: 0.0498 - val_loss: 2.9961 - val_accuracy: 0.0541\n",
      "Epoch 84/1000\n",
      "263/263 [==============================] - 2s 6ms/step - loss: 3.0016 - accuracy: 0.0519 - val_loss: 2.9960 - val_accuracy: 0.0535\n",
      "Epoch 85/1000\n",
      "263/263 [==============================] - 2s 6ms/step - loss: 3.0013 - accuracy: 0.0501 - val_loss: 2.9960 - val_accuracy: 0.0509\n",
      "Epoch 86/1000\n",
      "263/263 [==============================] - 2s 6ms/step - loss: 3.0027 - accuracy: 0.0496 - val_loss: 2.9961 - val_accuracy: 0.0520\n",
      "Epoch 87/1000\n",
      "263/263 [==============================] - 2s 6ms/step - loss: 3.0025 - accuracy: 0.0510 - val_loss: 2.9960 - val_accuracy: 0.0535\n",
      "Epoch 88/1000\n",
      "263/263 [==============================] - 2s 6ms/step - loss: 3.0014 - accuracy: 0.0514 - val_loss: 2.9960 - val_accuracy: 0.0533\n",
      "Epoch 89/1000\n",
      "263/263 [==============================] - 2s 6ms/step - loss: 3.0015 - accuracy: 0.0513 - val_loss: 2.9960 - val_accuracy: 0.0528\n",
      "Epoch 90/1000\n",
      "263/263 [==============================] - 2s 6ms/step - loss: 3.0017 - accuracy: 0.0515 - val_loss: 2.9961 - val_accuracy: 0.0533\n",
      "Epoch 91/1000\n",
      "263/263 [==============================] - 2s 6ms/step - loss: 3.0025 - accuracy: 0.0497 - val_loss: 2.9961 - val_accuracy: 0.0528\n",
      "Epoch 92/1000\n",
      "263/263 [==============================] - 2s 6ms/step - loss: 3.0019 - accuracy: 0.0499 - val_loss: 2.9960 - val_accuracy: 0.0541\n",
      "Epoch 93/1000\n",
      "263/263 [==============================] - 2s 6ms/step - loss: 3.0018 - accuracy: 0.0501 - val_loss: 2.9960 - val_accuracy: 0.0522\n",
      "Epoch 94/1000\n",
      "263/263 [==============================] - 2s 6ms/step - loss: 3.0012 - accuracy: 0.0534 - val_loss: 2.9959 - val_accuracy: 0.0524\n",
      "Epoch 95/1000\n",
      "263/263 [==============================] - 2s 6ms/step - loss: 3.0010 - accuracy: 0.0507 - val_loss: 2.9960 - val_accuracy: 0.0511\n",
      "Epoch 96/1000\n",
      "263/263 [==============================] - 2s 6ms/step - loss: 3.0005 - accuracy: 0.0509 - val_loss: 2.9960 - val_accuracy: 0.0524\n",
      "Epoch 97/1000\n",
      "263/263 [==============================] - 2s 6ms/step - loss: 3.0015 - accuracy: 0.0486 - val_loss: 2.9960 - val_accuracy: 0.0524\n",
      "Epoch 98/1000\n",
      "263/263 [==============================] - 2s 6ms/step - loss: 3.0013 - accuracy: 0.0485 - val_loss: 2.9961 - val_accuracy: 0.0509\n",
      "Epoch 99/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 3.0001 - accuracy: 0.0503 - val_loss: 2.9960 - val_accuracy: 0.0543\n",
      "Epoch 100/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 3.0015 - accuracy: 0.0501 - val_loss: 2.9961 - val_accuracy: 0.0537\n",
      "Epoch 101/1000\n",
      "263/263 [==============================] - 2s 6ms/step - loss: 2.9999 - accuracy: 0.0486 - val_loss: 2.9961 - val_accuracy: 0.0537\n",
      "Epoch 102/1000\n",
      "263/263 [==============================] - 2s 6ms/step - loss: 2.9993 - accuracy: 0.0517 - val_loss: 2.9961 - val_accuracy: 0.0513\n",
      "Epoch 103/1000\n",
      "263/263 [==============================] - 2s 6ms/step - loss: 3.0000 - accuracy: 0.0502 - val_loss: 2.9961 - val_accuracy: 0.0530\n",
      "Epoch 104/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.9999 - accuracy: 0.0523 - val_loss: 2.9961 - val_accuracy: 0.0537\n",
      "Epoch 105/1000\n",
      "263/263 [==============================] - 2s 6ms/step - loss: 3.0002 - accuracy: 0.0506 - val_loss: 2.9961 - val_accuracy: 0.0530\n",
      "Epoch 106/1000\n",
      "263/263 [==============================] - 2s 6ms/step - loss: 3.0009 - accuracy: 0.0485 - val_loss: 2.9961 - val_accuracy: 0.0517\n",
      "Epoch 107/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 3.0007 - accuracy: 0.0522 - val_loss: 2.9960 - val_accuracy: 0.0515\n",
      "Epoch 108/1000\n",
      "263/263 [==============================] - 2s 6ms/step - loss: 2.9991 - accuracy: 0.0530 - val_loss: 2.9960 - val_accuracy: 0.0524\n",
      "Epoch 109/1000\n",
      "263/263 [==============================] - 2s 6ms/step - loss: 2.9995 - accuracy: 0.0501 - val_loss: 2.9960 - val_accuracy: 0.0522\n",
      "Epoch 110/1000\n",
      "263/263 [==============================] - 2s 6ms/step - loss: 2.9993 - accuracy: 0.0505 - val_loss: 2.9961 - val_accuracy: 0.0537\n",
      "Epoch 111/1000\n",
      "263/263 [==============================] - 2s 6ms/step - loss: 3.0003 - accuracy: 0.0503 - val_loss: 2.9960 - val_accuracy: 0.0533\n",
      "Epoch 112/1000\n",
      "263/263 [==============================] - 2s 6ms/step - loss: 2.9999 - accuracy: 0.0520 - val_loss: 2.9960 - val_accuracy: 0.0520\n",
      "Epoch 113/1000\n",
      "263/263 [==============================] - 2s 6ms/step - loss: 2.9987 - accuracy: 0.0524 - val_loss: 2.9960 - val_accuracy: 0.0504\n",
      "Epoch 114/1000\n",
      "263/263 [==============================] - 2s 6ms/step - loss: 2.9996 - accuracy: 0.0502 - val_loss: 2.9961 - val_accuracy: 0.0526\n",
      "Epoch 115/1000\n",
      "263/263 [==============================] - 2s 6ms/step - loss: 2.9997 - accuracy: 0.0504 - val_loss: 2.9961 - val_accuracy: 0.0535\n",
      "Epoch 116/1000\n",
      "263/263 [==============================] - 2s 6ms/step - loss: 2.9995 - accuracy: 0.0503 - val_loss: 2.9960 - val_accuracy: 0.0524\n",
      "Epoch 117/1000\n",
      "263/263 [==============================] - 2s 6ms/step - loss: 3.0000 - accuracy: 0.0512 - val_loss: 2.9960 - val_accuracy: 0.0533\n",
      "Epoch 118/1000\n",
      "263/263 [==============================] - 2s 6ms/step - loss: 3.0002 - accuracy: 0.0505 - val_loss: 2.9960 - val_accuracy: 0.0535\n",
      "Epoch 119/1000\n",
      "263/263 [==============================] - 2s 6ms/step - loss: 2.9999 - accuracy: 0.0505 - val_loss: 2.9960 - val_accuracy: 0.0524\n",
      "Epoch 120/1000\n",
      "263/263 [==============================] - 2s 6ms/step - loss: 2.9994 - accuracy: 0.0492 - val_loss: 2.9960 - val_accuracy: 0.0535\n",
      "Epoch 121/1000\n",
      "263/263 [==============================] - 2s 6ms/step - loss: 2.9991 - accuracy: 0.0505 - val_loss: 2.9960 - val_accuracy: 0.0517\n",
      "Epoch 122/1000\n",
      "263/263 [==============================] - 2s 6ms/step - loss: 2.9996 - accuracy: 0.0500 - val_loss: 2.9961 - val_accuracy: 0.0526\n",
      "Epoch 123/1000\n",
      "263/263 [==============================] - 2s 6ms/step - loss: 2.9993 - accuracy: 0.0503 - val_loss: 2.9960 - val_accuracy: 0.0524\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([LSTM(128, input_shape=(32, 20), dropout=.1),\n",
    "                    # LSTM(64, dropout=.1),\n",
    "                    Dropout(.1),\n",
    "                    Dense(128, activation='sigmoid'),\n",
    "                    Dropout(.1),\n",
    "                    # Dense(64, activation='sigmoid'),\n",
    "                    # Dropout(.1),\n",
    "                    Dense(20, activation='softmax')])\n",
    "train(model=model,\n",
    "      patience_train=10,\n",
    "      patience_val=None,\n",
    "      learning_rate=.00001,\n",
    "      epochs=1000,\n",
    "      batch_size=128,\n",
    "      # cont_train=True,\n",
    "      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "87v_bTJHJvBJ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 22418,
     "status": "ok",
     "timestamp": 1688897805808,
     "user": {
      "displayName": "Yoni Krichevsky",
      "userId": "07735752940575548299"
     },
     "user_tz": -180
    },
    "id": "87v_bTJHJvBJ",
    "outputId": "19e2e1bc-0d23-4aa5-aa8c-ade780a1b132"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patience_train=10, patience_val=None, learning_rate=1e-06, epochs=1000, batch_size=128, cont_train=False, X_train.shape=(33566, 32, 20), y_train.shape=(33566,), X_val.shape=(4619, 32, 20), y_val.shape=(4619,)\n",
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_20 (LSTM)              (None, 128)               76288     \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_28 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " dropout_10 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_29 (Dense)            (None, 20)                2580      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 95,380\n",
      "Trainable params: 95,380\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Input shape (None, 32, 20), output shape (None, 20)\n",
      "Epoch 1/1000\n",
      "263/263 [==============================] - 5s 8ms/step - loss: 2.9988 - accuracy: 0.0520 - val_loss: 2.9960 - val_accuracy: 0.0526\n",
      "Epoch 2/1000\n",
      "263/263 [==============================] - 2s 6ms/step - loss: 2.9978 - accuracy: 0.0528 - val_loss: 2.9961 - val_accuracy: 0.0522\n",
      "Epoch 3/1000\n",
      "263/263 [==============================] - 2s 6ms/step - loss: 2.9997 - accuracy: 0.0496 - val_loss: 2.9960 - val_accuracy: 0.0522\n",
      "Epoch 4/1000\n",
      "263/263 [==============================] - 2s 6ms/step - loss: 2.9984 - accuracy: 0.0512 - val_loss: 2.9960 - val_accuracy: 0.0524\n",
      "Epoch 5/1000\n",
      "263/263 [==============================] - 2s 6ms/step - loss: 2.9983 - accuracy: 0.0506 - val_loss: 2.9960 - val_accuracy: 0.0524\n",
      "Epoch 6/1000\n",
      "263/263 [==============================] - 2s 6ms/step - loss: 2.9991 - accuracy: 0.0495 - val_loss: 2.9960 - val_accuracy: 0.0520\n",
      "Epoch 7/1000\n",
      "263/263 [==============================] - 2s 6ms/step - loss: 2.9980 - accuracy: 0.0514 - val_loss: 2.9960 - val_accuracy: 0.0522\n",
      "Epoch 8/1000\n",
      "263/263 [==============================] - 2s 6ms/step - loss: 2.9990 - accuracy: 0.0508 - val_loss: 2.9960 - val_accuracy: 0.0526\n",
      "Epoch 9/1000\n",
      "263/263 [==============================] - 2s 6ms/step - loss: 2.9990 - accuracy: 0.0508 - val_loss: 2.9960 - val_accuracy: 0.0524\n",
      "Epoch 10/1000\n",
      "263/263 [==============================] - 2s 6ms/step - loss: 2.9991 - accuracy: 0.0493 - val_loss: 2.9960 - val_accuracy: 0.0524\n",
      "Epoch 11/1000\n",
      "263/263 [==============================] - 2s 6ms/step - loss: 2.9985 - accuracy: 0.0520 - val_loss: 2.9960 - val_accuracy: 0.0530\n",
      "Epoch 12/1000\n",
      "263/263 [==============================] - 2s 6ms/step - loss: 2.9996 - accuracy: 0.0516 - val_loss: 2.9960 - val_accuracy: 0.0528\n"
     ]
    }
   ],
   "source": [
    "train(model=model,\n",
    "      patience_train=10,\n",
    "      patience_val=None,\n",
    "      learning_rate=.000001,\n",
    "      epochs=1000,\n",
    "      batch_size=128,\n",
    "      # cont_train=True,\n",
    "      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "yPAatiORKtWz",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 306846,
     "status": "ok",
     "timestamp": 1688898380539,
     "user": {
      "displayName": "Yoni Krichevsky",
      "userId": "07735752940575548299"
     },
     "user_tz": -180
    },
    "id": "yPAatiORKtWz",
    "outputId": "20f9b644-e4b3-436f-d661-6175a7aa853d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patience_train=10, patience_val=None, learning_rate=1e-05, epochs=1000, batch_size=128, cont_train=False, X_train.shape=(33566, 32, 20), y_train.shape=(33566,), X_val.shape=(4619, 32, 20), y_val.shape=(4619,)\n",
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_23 (LSTM)              (None, 32, 128)           76288     \n",
      "                                                                 \n",
      " lstm_24 (LSTM)              (None, 128)               131584    \n",
      "                                                                 \n",
      " dropout_14 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_33 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " dropout_15 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_34 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " dropout_16 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_35 (Dense)            (None, 20)                2580      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 243,476\n",
      "Trainable params: 243,476\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Input shape (None, 32, 20), output shape (None, 20)\n",
      "Epoch 1/1000\n",
      "263/263 [==============================] - 7s 11ms/step - loss: 3.2675 - accuracy: 0.0489 - val_loss: 3.1203 - val_accuracy: 0.0507\n",
      "Epoch 2/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.1329 - accuracy: 0.0484 - val_loss: 3.0341 - val_accuracy: 0.0507\n",
      "Epoch 3/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0777 - accuracy: 0.0491 - val_loss: 3.0084 - val_accuracy: 0.0507\n",
      "Epoch 4/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0549 - accuracy: 0.0504 - val_loss: 2.9998 - val_accuracy: 0.0507\n",
      "Epoch 5/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0458 - accuracy: 0.0507 - val_loss: 2.9969 - val_accuracy: 0.0507\n",
      "Epoch 6/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 3.0437 - accuracy: 0.0507 - val_loss: 2.9961 - val_accuracy: 0.0507\n",
      "Epoch 7/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 3.0434 - accuracy: 0.0479 - val_loss: 2.9959 - val_accuracy: 0.0507\n",
      "Epoch 8/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0394 - accuracy: 0.0486 - val_loss: 2.9959 - val_accuracy: 0.0481\n",
      "Epoch 9/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0404 - accuracy: 0.0501 - val_loss: 2.9960 - val_accuracy: 0.0487\n",
      "Epoch 10/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0394 - accuracy: 0.0501 - val_loss: 2.9960 - val_accuracy: 0.0487\n",
      "Epoch 11/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0346 - accuracy: 0.0507 - val_loss: 2.9961 - val_accuracy: 0.0478\n",
      "Epoch 12/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0348 - accuracy: 0.0491 - val_loss: 2.9961 - val_accuracy: 0.0517\n",
      "Epoch 13/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0349 - accuracy: 0.0488 - val_loss: 2.9961 - val_accuracy: 0.0517\n",
      "Epoch 14/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0332 - accuracy: 0.0500 - val_loss: 2.9961 - val_accuracy: 0.0474\n",
      "Epoch 15/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0320 - accuracy: 0.0493 - val_loss: 2.9961 - val_accuracy: 0.0515\n",
      "Epoch 16/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0316 - accuracy: 0.0483 - val_loss: 2.9961 - val_accuracy: 0.0517\n",
      "Epoch 17/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0324 - accuracy: 0.0506 - val_loss: 2.9961 - val_accuracy: 0.0515\n",
      "Epoch 18/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0285 - accuracy: 0.0515 - val_loss: 2.9961 - val_accuracy: 0.0487\n",
      "Epoch 19/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0283 - accuracy: 0.0503 - val_loss: 2.9961 - val_accuracy: 0.0517\n",
      "Epoch 20/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0289 - accuracy: 0.0495 - val_loss: 2.9961 - val_accuracy: 0.0487\n",
      "Epoch 21/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0258 - accuracy: 0.0502 - val_loss: 2.9961 - val_accuracy: 0.0517\n",
      "Epoch 22/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0264 - accuracy: 0.0506 - val_loss: 2.9961 - val_accuracy: 0.0520\n",
      "Epoch 23/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0246 - accuracy: 0.0498 - val_loss: 2.9961 - val_accuracy: 0.0517\n",
      "Epoch 24/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0245 - accuracy: 0.0511 - val_loss: 2.9962 - val_accuracy: 0.0517\n",
      "Epoch 25/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0239 - accuracy: 0.0485 - val_loss: 2.9961 - val_accuracy: 0.0520\n",
      "Epoch 26/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0242 - accuracy: 0.0499 - val_loss: 2.9961 - val_accuracy: 0.0483\n",
      "Epoch 27/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0225 - accuracy: 0.0508 - val_loss: 2.9961 - val_accuracy: 0.0517\n",
      "Epoch 28/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0232 - accuracy: 0.0482 - val_loss: 2.9961 - val_accuracy: 0.0489\n",
      "Epoch 29/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0208 - accuracy: 0.0490 - val_loss: 2.9961 - val_accuracy: 0.0487\n",
      "Epoch 30/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0226 - accuracy: 0.0490 - val_loss: 2.9961 - val_accuracy: 0.0465\n",
      "Epoch 31/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0211 - accuracy: 0.0492 - val_loss: 2.9961 - val_accuracy: 0.0481\n",
      "Epoch 32/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0203 - accuracy: 0.0493 - val_loss: 2.9961 - val_accuracy: 0.0509\n",
      "Epoch 33/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0181 - accuracy: 0.0498 - val_loss: 2.9961 - val_accuracy: 0.0465\n",
      "Epoch 34/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0163 - accuracy: 0.0497 - val_loss: 2.9960 - val_accuracy: 0.0485\n",
      "Epoch 35/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0184 - accuracy: 0.0494 - val_loss: 2.9961 - val_accuracy: 0.0483\n",
      "Epoch 36/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0182 - accuracy: 0.0521 - val_loss: 2.9961 - val_accuracy: 0.0504\n",
      "Epoch 37/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 3.0169 - accuracy: 0.0513 - val_loss: 2.9961 - val_accuracy: 0.0517\n",
      "Epoch 38/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0162 - accuracy: 0.0489 - val_loss: 2.9962 - val_accuracy: 0.0489\n",
      "Epoch 39/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0169 - accuracy: 0.0507 - val_loss: 2.9962 - val_accuracy: 0.0487\n",
      "Epoch 40/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0142 - accuracy: 0.0495 - val_loss: 2.9961 - val_accuracy: 0.0481\n",
      "Epoch 41/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0157 - accuracy: 0.0501 - val_loss: 2.9960 - val_accuracy: 0.0465\n",
      "Epoch 42/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 3.0136 - accuracy: 0.0501 - val_loss: 2.9961 - val_accuracy: 0.0517\n",
      "Epoch 43/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 3.0149 - accuracy: 0.0487 - val_loss: 2.9961 - val_accuracy: 0.0517\n",
      "Epoch 44/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 3.0140 - accuracy: 0.0495 - val_loss: 2.9962 - val_accuracy: 0.0517\n",
      "Epoch 45/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 3.0125 - accuracy: 0.0524 - val_loss: 2.9962 - val_accuracy: 0.0487\n",
      "Epoch 46/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 3.0119 - accuracy: 0.0526 - val_loss: 2.9961 - val_accuracy: 0.0487\n",
      "Epoch 47/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 3.0133 - accuracy: 0.0506 - val_loss: 2.9961 - val_accuracy: 0.0487\n",
      "Epoch 48/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0121 - accuracy: 0.0490 - val_loss: 2.9962 - val_accuracy: 0.0481\n",
      "Epoch 49/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0118 - accuracy: 0.0522 - val_loss: 2.9961 - val_accuracy: 0.0487\n",
      "Epoch 50/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0113 - accuracy: 0.0510 - val_loss: 2.9961 - val_accuracy: 0.0487\n",
      "Epoch 51/1000\n",
      "263/263 [==============================] - 2s 9ms/step - loss: 3.0111 - accuracy: 0.0492 - val_loss: 2.9961 - val_accuracy: 0.0487\n",
      "Epoch 52/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 3.0102 - accuracy: 0.0498 - val_loss: 2.9961 - val_accuracy: 0.0517\n",
      "Epoch 53/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 3.0090 - accuracy: 0.0501 - val_loss: 2.9961 - val_accuracy: 0.0517\n",
      "Epoch 54/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 3.0087 - accuracy: 0.0515 - val_loss: 2.9961 - val_accuracy: 0.0517\n",
      "Epoch 55/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 3.0091 - accuracy: 0.0500 - val_loss: 2.9961 - val_accuracy: 0.0517\n",
      "Epoch 56/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 3.0090 - accuracy: 0.0475 - val_loss: 2.9960 - val_accuracy: 0.0483\n",
      "Epoch 57/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 3.0085 - accuracy: 0.0513 - val_loss: 2.9960 - val_accuracy: 0.0517\n",
      "Epoch 58/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 3.0087 - accuracy: 0.0516 - val_loss: 2.9961 - val_accuracy: 0.0465\n",
      "Epoch 59/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 3.0077 - accuracy: 0.0497 - val_loss: 2.9961 - val_accuracy: 0.0465\n",
      "Epoch 60/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 3.0075 - accuracy: 0.0499 - val_loss: 2.9960 - val_accuracy: 0.0465\n",
      "Epoch 61/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 3.0079 - accuracy: 0.0502 - val_loss: 2.9961 - val_accuracy: 0.0470\n",
      "Epoch 62/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 3.0061 - accuracy: 0.0503 - val_loss: 2.9960 - val_accuracy: 0.0468\n",
      "Epoch 63/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 3.0065 - accuracy: 0.0488 - val_loss: 2.9961 - val_accuracy: 0.0517\n",
      "Epoch 64/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 3.0053 - accuracy: 0.0532 - val_loss: 2.9960 - val_accuracy: 0.0468\n",
      "Epoch 65/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 3.0066 - accuracy: 0.0500 - val_loss: 2.9960 - val_accuracy: 0.0517\n",
      "Epoch 66/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 3.0052 - accuracy: 0.0490 - val_loss: 2.9960 - val_accuracy: 0.0481\n",
      "Epoch 67/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 3.0054 - accuracy: 0.0512 - val_loss: 2.9960 - val_accuracy: 0.0517\n",
      "Epoch 68/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 3.0062 - accuracy: 0.0488 - val_loss: 2.9960 - val_accuracy: 0.0517\n",
      "Epoch 69/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 3.0057 - accuracy: 0.0498 - val_loss: 2.9960 - val_accuracy: 0.0517\n",
      "Epoch 70/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 3.0044 - accuracy: 0.0520 - val_loss: 2.9960 - val_accuracy: 0.0517\n",
      "Epoch 71/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 3.0057 - accuracy: 0.0510 - val_loss: 2.9960 - val_accuracy: 0.0517\n",
      "Epoch 72/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 3.0054 - accuracy: 0.0496 - val_loss: 2.9960 - val_accuracy: 0.0522\n",
      "Epoch 73/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 3.0038 - accuracy: 0.0509 - val_loss: 2.9960 - val_accuracy: 0.0507\n",
      "Epoch 74/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 3.0041 - accuracy: 0.0511 - val_loss: 2.9960 - val_accuracy: 0.0478\n",
      "Epoch 75/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 3.0043 - accuracy: 0.0474 - val_loss: 2.9960 - val_accuracy: 0.0470\n",
      "Epoch 76/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 3.0036 - accuracy: 0.0496 - val_loss: 2.9960 - val_accuracy: 0.0470\n",
      "Epoch 77/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 3.0026 - accuracy: 0.0509 - val_loss: 2.9960 - val_accuracy: 0.0472\n",
      "Epoch 78/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 3.0039 - accuracy: 0.0501 - val_loss: 2.9960 - val_accuracy: 0.0472\n",
      "Epoch 79/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 3.0039 - accuracy: 0.0487 - val_loss: 2.9960 - val_accuracy: 0.0465\n",
      "Epoch 80/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 3.0025 - accuracy: 0.0503 - val_loss: 2.9960 - val_accuracy: 0.0470\n",
      "Epoch 81/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 3.0024 - accuracy: 0.0491 - val_loss: 2.9960 - val_accuracy: 0.0513\n",
      "Epoch 82/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 3.0023 - accuracy: 0.0513 - val_loss: 2.9960 - val_accuracy: 0.0515\n",
      "Epoch 83/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 3.0024 - accuracy: 0.0510 - val_loss: 2.9961 - val_accuracy: 0.0515\n",
      "Epoch 84/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 3.0028 - accuracy: 0.0502 - val_loss: 2.9960 - val_accuracy: 0.0513\n",
      "Epoch 85/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 3.0022 - accuracy: 0.0504 - val_loss: 2.9960 - val_accuracy: 0.0515\n",
      "Epoch 86/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 3.0020 - accuracy: 0.0475 - val_loss: 2.9960 - val_accuracy: 0.0511\n",
      "Epoch 87/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 3.0018 - accuracy: 0.0509 - val_loss: 2.9960 - val_accuracy: 0.0509\n",
      "Epoch 88/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 3.0011 - accuracy: 0.0510 - val_loss: 2.9960 - val_accuracy: 0.0507\n",
      "Epoch 89/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 3.0016 - accuracy: 0.0494 - val_loss: 2.9960 - val_accuracy: 0.0513\n",
      "Epoch 90/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 3.0018 - accuracy: 0.0498 - val_loss: 2.9959 - val_accuracy: 0.0520\n",
      "Epoch 91/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 3.0008 - accuracy: 0.0503 - val_loss: 2.9960 - val_accuracy: 0.0504\n",
      "Epoch 92/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 3.0022 - accuracy: 0.0493 - val_loss: 2.9959 - val_accuracy: 0.0520\n",
      "Epoch 93/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 3.0013 - accuracy: 0.0495 - val_loss: 2.9960 - val_accuracy: 0.0524\n",
      "Epoch 94/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 3.0011 - accuracy: 0.0497 - val_loss: 2.9960 - val_accuracy: 0.0515\n",
      "Epoch 95/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 3.0010 - accuracy: 0.0501 - val_loss: 2.9960 - val_accuracy: 0.0517\n",
      "Epoch 96/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 3.0011 - accuracy: 0.0476 - val_loss: 2.9960 - val_accuracy: 0.0481\n",
      "Epoch 97/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 3.0010 - accuracy: 0.0487 - val_loss: 2.9959 - val_accuracy: 0.0548\n",
      "Epoch 98/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 3.0012 - accuracy: 0.0511 - val_loss: 2.9959 - val_accuracy: 0.0513\n",
      "Epoch 99/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 3.0005 - accuracy: 0.0499 - val_loss: 2.9960 - val_accuracy: 0.0517\n",
      "Epoch 100/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 3.0005 - accuracy: 0.0495 - val_loss: 2.9960 - val_accuracy: 0.0517\n",
      "Epoch 101/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.9994 - accuracy: 0.0505 - val_loss: 2.9960 - val_accuracy: 0.0515\n",
      "Epoch 102/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.9996 - accuracy: 0.0492 - val_loss: 2.9960 - val_accuracy: 0.0520\n",
      "Epoch 103/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.9993 - accuracy: 0.0511 - val_loss: 2.9960 - val_accuracy: 0.0470\n",
      "Epoch 104/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 3.0001 - accuracy: 0.0496 - val_loss: 2.9960 - val_accuracy: 0.0472\n",
      "Epoch 105/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 3.0001 - accuracy: 0.0506 - val_loss: 2.9960 - val_accuracy: 0.0515\n",
      "Epoch 106/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 2.9995 - accuracy: 0.0503 - val_loss: 2.9960 - val_accuracy: 0.0470\n",
      "Epoch 107/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 3.0004 - accuracy: 0.0495 - val_loss: 2.9960 - val_accuracy: 0.0470\n",
      "Epoch 108/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 2.9985 - accuracy: 0.0518 - val_loss: 2.9960 - val_accuracy: 0.0470\n",
      "Epoch 109/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 2.9985 - accuracy: 0.0506 - val_loss: 2.9960 - val_accuracy: 0.0489\n",
      "Epoch 110/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.9993 - accuracy: 0.0510 - val_loss: 2.9960 - val_accuracy: 0.0509\n",
      "Epoch 111/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.9993 - accuracy: 0.0493 - val_loss: 2.9960 - val_accuracy: 0.0511\n",
      "Epoch 112/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.9993 - accuracy: 0.0491 - val_loss: 2.9960 - val_accuracy: 0.0515\n",
      "Epoch 113/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.9992 - accuracy: 0.0509 - val_loss: 2.9960 - val_accuracy: 0.0522\n",
      "Epoch 114/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.9984 - accuracy: 0.0515 - val_loss: 2.9960 - val_accuracy: 0.0507\n",
      "Epoch 115/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.9992 - accuracy: 0.0519 - val_loss: 2.9960 - val_accuracy: 0.0511\n",
      "Epoch 116/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 2.9988 - accuracy: 0.0506 - val_loss: 2.9960 - val_accuracy: 0.0511\n",
      "Epoch 117/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 2.9992 - accuracy: 0.0501 - val_loss: 2.9960 - val_accuracy: 0.0515\n",
      "Epoch 118/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 2.9991 - accuracy: 0.0490 - val_loss: 2.9960 - val_accuracy: 0.0513\n",
      "Epoch 119/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 2.9984 - accuracy: 0.0508 - val_loss: 2.9959 - val_accuracy: 0.0509\n",
      "Epoch 120/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.9988 - accuracy: 0.0503 - val_loss: 2.9959 - val_accuracy: 0.0511\n",
      "Epoch 121/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.9980 - accuracy: 0.0507 - val_loss: 2.9959 - val_accuracy: 0.0507\n",
      "Epoch 122/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.9980 - accuracy: 0.0505 - val_loss: 2.9959 - val_accuracy: 0.0504\n",
      "Epoch 123/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.9985 - accuracy: 0.0503 - val_loss: 2.9959 - val_accuracy: 0.0513\n",
      "Epoch 124/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.9987 - accuracy: 0.0494 - val_loss: 2.9959 - val_accuracy: 0.0509\n",
      "Epoch 125/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 2.9978 - accuracy: 0.0526 - val_loss: 2.9959 - val_accuracy: 0.0528\n",
      "Epoch 126/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 2.9985 - accuracy: 0.0490 - val_loss: 2.9959 - val_accuracy: 0.0526\n",
      "Epoch 127/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.9982 - accuracy: 0.0493 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 128/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.9980 - accuracy: 0.0493 - val_loss: 2.9959 - val_accuracy: 0.0515\n",
      "Epoch 129/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.9986 - accuracy: 0.0482 - val_loss: 2.9959 - val_accuracy: 0.0515\n",
      "Epoch 130/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.9984 - accuracy: 0.0512 - val_loss: 2.9960 - val_accuracy: 0.0511\n",
      "Epoch 131/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.9990 - accuracy: 0.0485 - val_loss: 2.9960 - val_accuracy: 0.0524\n",
      "Epoch 132/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.9982 - accuracy: 0.0507 - val_loss: 2.9959 - val_accuracy: 0.0533\n",
      "Epoch 133/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.9974 - accuracy: 0.0494 - val_loss: 2.9959 - val_accuracy: 0.0513\n",
      "Epoch 134/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.9973 - accuracy: 0.0503 - val_loss: 2.9960 - val_accuracy: 0.0513\n",
      "Epoch 135/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.9976 - accuracy: 0.0514 - val_loss: 2.9960 - val_accuracy: 0.0517\n",
      "Epoch 136/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.9975 - accuracy: 0.0509 - val_loss: 2.9960 - val_accuracy: 0.0511\n",
      "Epoch 137/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.9982 - accuracy: 0.0510 - val_loss: 2.9960 - val_accuracy: 0.0528\n",
      "Epoch 138/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 2.9976 - accuracy: 0.0499 - val_loss: 2.9960 - val_accuracy: 0.0528\n",
      "Epoch 139/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.9977 - accuracy: 0.0489 - val_loss: 2.9959 - val_accuracy: 0.0520\n",
      "Epoch 140/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.9978 - accuracy: 0.0506 - val_loss: 2.9959 - val_accuracy: 0.0537\n",
      "Epoch 141/1000\n",
      "263/263 [==============================] - 2s 7ms/step - loss: 2.9975 - accuracy: 0.0495 - val_loss: 2.9960 - val_accuracy: 0.0515\n",
      "Epoch 142/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 2.9974 - accuracy: 0.0503 - val_loss: 2.9960 - val_accuracy: 0.0513\n",
      "Epoch 143/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 2.9979 - accuracy: 0.0504 - val_loss: 2.9960 - val_accuracy: 0.0524\n",
      "Epoch 144/1000\n",
      "263/263 [==============================] - 2s 8ms/step - loss: 2.9973 - accuracy: 0.0518 - val_loss: 2.9960 - val_accuracy: 0.0515\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([LSTM(128, input_shape=(32, 20), dropout=.2, return_sequences=True),\n",
    "                    LSTM(128, dropout=.2),\n",
    "                    Dropout(.2),\n",
    "                    Dense(128, activation='sigmoid'),\n",
    "                    Dropout(.2),\n",
    "                    Dense(128, activation='sigmoid'),\n",
    "                    Dropout(.2),\n",
    "                    Dense(20, activation='softmax')])\n",
    "train(model=model,\n",
    "      patience_train=10,\n",
    "      patience_val=None,\n",
    "      learning_rate=.00001,\n",
    "      epochs=1000,\n",
    "      batch_size=128,\n",
    "      # cont_train=True,\n",
    "      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "jdsHhgr-MJEC",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 146226,
     "status": "ok",
     "timestamp": 1688898782637,
     "user": {
      "displayName": "Yoni Krichevsky",
      "userId": "07735752940575548299"
     },
     "user_tz": -180
    },
    "id": "jdsHhgr-MJEC",
    "outputId": "9871a897-aafb-4c2f-fab4-ebf807e4d6e4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patience_train=20, patience_val=None, learning_rate=1e-06, epochs=1000, batch_size=64, cont_train=False, X_train.shape=(33566, 32, 20), y_train.shape=(33566,), X_val.shape=(4619, 32, 20), y_val.shape=(4619,)\n",
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_23 (LSTM)              (None, 32, 128)           76288     \n",
      "                                                                 \n",
      " lstm_24 (LSTM)              (None, 128)               131584    \n",
      "                                                                 \n",
      " dropout_14 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_33 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " dropout_15 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_34 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " dropout_16 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_35 (Dense)            (None, 20)                2580      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 243,476\n",
      "Trainable params: 243,476\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Input shape (None, 32, 20), output shape (None, 20)\n",
      "Epoch 1/1000\n",
      "525/525 [==============================] - 10s 9ms/step - loss: 2.9981 - accuracy: 0.0473 - val_loss: 2.9960 - val_accuracy: 0.0513\n",
      "Epoch 2/1000\n",
      "525/525 [==============================] - 4s 7ms/step - loss: 2.9971 - accuracy: 0.0530 - val_loss: 2.9960 - val_accuracy: 0.0517\n",
      "Epoch 3/1000\n",
      "525/525 [==============================] - 4s 7ms/step - loss: 2.9972 - accuracy: 0.0537 - val_loss: 2.9960 - val_accuracy: 0.0515\n",
      "Epoch 4/1000\n",
      "525/525 [==============================] - 4s 8ms/step - loss: 2.9973 - accuracy: 0.0518 - val_loss: 2.9960 - val_accuracy: 0.0520\n",
      "Epoch 5/1000\n",
      "525/525 [==============================] - 4s 7ms/step - loss: 2.9977 - accuracy: 0.0495 - val_loss: 2.9960 - val_accuracy: 0.0528\n",
      "Epoch 6/1000\n",
      "525/525 [==============================] - 4s 7ms/step - loss: 2.9975 - accuracy: 0.0507 - val_loss: 2.9960 - val_accuracy: 0.0524\n",
      "Epoch 7/1000\n",
      "525/525 [==============================] - 4s 7ms/step - loss: 2.9978 - accuracy: 0.0503 - val_loss: 2.9960 - val_accuracy: 0.0524\n",
      "Epoch 8/1000\n",
      "525/525 [==============================] - 4s 7ms/step - loss: 2.9976 - accuracy: 0.0518 - val_loss: 2.9959 - val_accuracy: 0.0528\n",
      "Epoch 9/1000\n",
      "525/525 [==============================] - 4s 7ms/step - loss: 2.9969 - accuracy: 0.0501 - val_loss: 2.9960 - val_accuracy: 0.0517\n",
      "Epoch 10/1000\n",
      "525/525 [==============================] - 4s 7ms/step - loss: 2.9972 - accuracy: 0.0513 - val_loss: 2.9960 - val_accuracy: 0.0520\n",
      "Epoch 11/1000\n",
      "525/525 [==============================] - 4s 7ms/step - loss: 2.9976 - accuracy: 0.0500 - val_loss: 2.9960 - val_accuracy: 0.0520\n",
      "Epoch 12/1000\n",
      "525/525 [==============================] - 4s 8ms/step - loss: 2.9969 - accuracy: 0.0528 - val_loss: 2.9960 - val_accuracy: 0.0515\n",
      "Epoch 13/1000\n",
      "525/525 [==============================] - 4s 7ms/step - loss: 2.9976 - accuracy: 0.0506 - val_loss: 2.9960 - val_accuracy: 0.0522\n",
      "Epoch 14/1000\n",
      "525/525 [==============================] - 4s 7ms/step - loss: 2.9976 - accuracy: 0.0506 - val_loss: 2.9960 - val_accuracy: 0.0517\n",
      "Epoch 15/1000\n",
      "525/525 [==============================] - 4s 7ms/step - loss: 2.9972 - accuracy: 0.0496 - val_loss: 2.9960 - val_accuracy: 0.0509\n",
      "Epoch 16/1000\n",
      "525/525 [==============================] - 4s 7ms/step - loss: 2.9974 - accuracy: 0.0521 - val_loss: 2.9959 - val_accuracy: 0.0507\n",
      "Epoch 17/1000\n",
      "525/525 [==============================] - 4s 7ms/step - loss: 2.9973 - accuracy: 0.0494 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 18/1000\n",
      "525/525 [==============================] - 4s 7ms/step - loss: 2.9980 - accuracy: 0.0498 - val_loss: 2.9959 - val_accuracy: 0.0509\n",
      "Epoch 19/1000\n",
      "525/525 [==============================] - 4s 7ms/step - loss: 2.9971 - accuracy: 0.0498 - val_loss: 2.9959 - val_accuracy: 0.0515\n",
      "Epoch 20/1000\n",
      "525/525 [==============================] - 4s 7ms/step - loss: 2.9969 - accuracy: 0.0520 - val_loss: 2.9959 - val_accuracy: 0.0513\n",
      "Epoch 21/1000\n",
      "525/525 [==============================] - 4s 7ms/step - loss: 2.9975 - accuracy: 0.0505 - val_loss: 2.9959 - val_accuracy: 0.0513\n",
      "Epoch 22/1000\n",
      "525/525 [==============================] - 4s 8ms/step - loss: 2.9976 - accuracy: 0.0513 - val_loss: 2.9959 - val_accuracy: 0.0500\n",
      "Epoch 23/1000\n",
      "525/525 [==============================] - 4s 7ms/step - loss: 2.9975 - accuracy: 0.0509 - val_loss: 2.9959 - val_accuracy: 0.0504\n",
      "Epoch 24/1000\n",
      "525/525 [==============================] - 4s 7ms/step - loss: 2.9978 - accuracy: 0.0503 - val_loss: 2.9959 - val_accuracy: 0.0504\n",
      "Epoch 25/1000\n",
      "525/525 [==============================] - 4s 7ms/step - loss: 2.9974 - accuracy: 0.0512 - val_loss: 2.9959 - val_accuracy: 0.0513\n",
      "Epoch 26/1000\n",
      "525/525 [==============================] - 4s 7ms/step - loss: 2.9974 - accuracy: 0.0506 - val_loss: 2.9959 - val_accuracy: 0.0509\n",
      "Epoch 27/1000\n",
      "525/525 [==============================] - 4s 7ms/step - loss: 2.9972 - accuracy: 0.0506 - val_loss: 2.9959 - val_accuracy: 0.0515\n",
      "Epoch 28/1000\n",
      "525/525 [==============================] - 4s 8ms/step - loss: 2.9980 - accuracy: 0.0506 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 29/1000\n",
      "525/525 [==============================] - 4s 8ms/step - loss: 2.9977 - accuracy: 0.0498 - val_loss: 2.9959 - val_accuracy: 0.0511\n",
      "Epoch 30/1000\n",
      "525/525 [==============================] - 4s 8ms/step - loss: 2.9973 - accuracy: 0.0506 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 31/1000\n",
      "525/525 [==============================] - 4s 8ms/step - loss: 2.9978 - accuracy: 0.0492 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 32/1000\n",
      "525/525 [==============================] - 4s 7ms/step - loss: 2.9978 - accuracy: 0.0485 - val_loss: 2.9959 - val_accuracy: 0.0513\n",
      "Epoch 33/1000\n",
      "525/525 [==============================] - 4s 7ms/step - loss: 2.9974 - accuracy: 0.0510 - val_loss: 2.9959 - val_accuracy: 0.0524\n",
      "Epoch 34/1000\n",
      "525/525 [==============================] - 4s 7ms/step - loss: 2.9972 - accuracy: 0.0516 - val_loss: 2.9959 - val_accuracy: 0.0513\n",
      "Epoch 35/1000\n",
      "525/525 [==============================] - 4s 7ms/step - loss: 2.9967 - accuracy: 0.0529 - val_loss: 2.9959 - val_accuracy: 0.0513\n",
      "Epoch 36/1000\n",
      "525/525 [==============================] - 4s 7ms/step - loss: 2.9975 - accuracy: 0.0498 - val_loss: 2.9959 - val_accuracy: 0.0513\n",
      "Epoch 37/1000\n",
      "525/525 [==============================] - 4s 8ms/step - loss: 2.9973 - accuracy: 0.0489 - val_loss: 2.9959 - val_accuracy: 0.0522\n",
      "Epoch 38/1000\n",
      "525/525 [==============================] - 4s 7ms/step - loss: 2.9971 - accuracy: 0.0512 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 39/1000\n",
      "525/525 [==============================] - 4s 7ms/step - loss: 2.9972 - accuracy: 0.0517 - val_loss: 2.9959 - val_accuracy: 0.0526\n",
      "Epoch 40/1000\n",
      "525/525 [==============================] - 4s 8ms/step - loss: 2.9976 - accuracy: 0.0504 - val_loss: 2.9959 - val_accuracy: 0.0522\n",
      "Epoch 41/1000\n",
      "525/525 [==============================] - 4s 7ms/step - loss: 2.9979 - accuracy: 0.0498 - val_loss: 2.9959 - val_accuracy: 0.0520\n",
      "Epoch 42/1000\n",
      "525/525 [==============================] - 4s 7ms/step - loss: 2.9972 - accuracy: 0.0503 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 43/1000\n",
      "525/525 [==============================] - 4s 7ms/step - loss: 2.9972 - accuracy: 0.0509 - val_loss: 2.9959 - val_accuracy: 0.0524\n",
      "Epoch 44/1000\n",
      "525/525 [==============================] - 4s 7ms/step - loss: 2.9969 - accuracy: 0.0513 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 45/1000\n",
      "525/525 [==============================] - 4s 7ms/step - loss: 2.9969 - accuracy: 0.0502 - val_loss: 2.9959 - val_accuracy: 0.0524\n",
      "Epoch 46/1000\n",
      "525/525 [==============================] - 4s 7ms/step - loss: 2.9971 - accuracy: 0.0516 - val_loss: 2.9959 - val_accuracy: 0.0530\n",
      "Epoch 47/1000\n",
      "525/525 [==============================] - 4s 7ms/step - loss: 2.9973 - accuracy: 0.0508 - val_loss: 2.9959 - val_accuracy: 0.0524\n",
      "Epoch 48/1000\n",
      "525/525 [==============================] - 4s 7ms/step - loss: 2.9967 - accuracy: 0.0529 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 49/1000\n",
      "525/525 [==============================] - 4s 8ms/step - loss: 2.9972 - accuracy: 0.0491 - val_loss: 2.9959 - val_accuracy: 0.0520\n",
      "Epoch 50/1000\n",
      "525/525 [==============================] - 4s 7ms/step - loss: 2.9969 - accuracy: 0.0510 - val_loss: 2.9959 - val_accuracy: 0.0515\n",
      "Epoch 51/1000\n",
      "525/525 [==============================] - 4s 7ms/step - loss: 2.9974 - accuracy: 0.0500 - val_loss: 2.9959 - val_accuracy: 0.0511\n",
      "Epoch 52/1000\n",
      "525/525 [==============================] - 4s 7ms/step - loss: 2.9971 - accuracy: 0.0497 - val_loss: 2.9959 - val_accuracy: 0.0515\n",
      "Epoch 53/1000\n",
      "525/525 [==============================] - 4s 7ms/step - loss: 2.9970 - accuracy: 0.0524 - val_loss: 2.9959 - val_accuracy: 0.0530\n",
      "Epoch 54/1000\n",
      "525/525 [==============================] - 4s 7ms/step - loss: 2.9972 - accuracy: 0.0504 - val_loss: 2.9959 - val_accuracy: 0.0520\n",
      "Epoch 55/1000\n",
      "525/525 [==============================] - 4s 8ms/step - loss: 2.9971 - accuracy: 0.0513 - val_loss: 2.9959 - val_accuracy: 0.0509\n",
      "Epoch 56/1000\n",
      "525/525 [==============================] - 4s 7ms/step - loss: 2.9970 - accuracy: 0.0526 - val_loss: 2.9959 - val_accuracy: 0.0526\n",
      "Epoch 57/1000\n",
      "525/525 [==============================] - 4s 7ms/step - loss: 2.9975 - accuracy: 0.0495 - val_loss: 2.9959 - val_accuracy: 0.0520\n",
      "Epoch 58/1000\n",
      "525/525 [==============================] - 4s 7ms/step - loss: 2.9968 - accuracy: 0.0505 - val_loss: 2.9959 - val_accuracy: 0.0507\n",
      "Epoch 59/1000\n",
      "525/525 [==============================] - 4s 7ms/step - loss: 2.9975 - accuracy: 0.0515 - val_loss: 2.9959 - val_accuracy: 0.0511\n",
      "Epoch 60/1000\n",
      "525/525 [==============================] - 4s 7ms/step - loss: 2.9970 - accuracy: 0.0506 - val_loss: 2.9960 - val_accuracy: 0.0500\n",
      "Epoch 61/1000\n",
      "525/525 [==============================] - 4s 7ms/step - loss: 2.9974 - accuracy: 0.0506 - val_loss: 2.9960 - val_accuracy: 0.0504\n",
      "Epoch 62/1000\n",
      "525/525 [==============================] - 4s 7ms/step - loss: 2.9973 - accuracy: 0.0493 - val_loss: 2.9960 - val_accuracy: 0.0500\n",
      "Epoch 63/1000\n",
      "525/525 [==============================] - 4s 7ms/step - loss: 2.9966 - accuracy: 0.0523 - val_loss: 2.9960 - val_accuracy: 0.0507\n",
      "Epoch 64/1000\n",
      "525/525 [==============================] - 4s 7ms/step - loss: 2.9966 - accuracy: 0.0527 - val_loss: 2.9960 - val_accuracy: 0.0511\n",
      "Epoch 65/1000\n",
      "525/525 [==============================] - 4s 7ms/step - loss: 2.9968 - accuracy: 0.0510 - val_loss: 2.9960 - val_accuracy: 0.0500\n",
      "Epoch 66/1000\n",
      "525/525 [==============================] - 4s 7ms/step - loss: 2.9972 - accuracy: 0.0495 - val_loss: 2.9959 - val_accuracy: 0.0515\n",
      "Epoch 67/1000\n",
      "525/525 [==============================] - 4s 7ms/step - loss: 2.9971 - accuracy: 0.0496 - val_loss: 2.9959 - val_accuracy: 0.0511\n",
      "Epoch 68/1000\n",
      "525/525 [==============================] - 4s 8ms/step - loss: 2.9978 - accuracy: 0.0495 - val_loss: 2.9959 - val_accuracy: 0.0507\n",
      "Epoch 69/1000\n",
      "525/525 [==============================] - 4s 7ms/step - loss: 2.9970 - accuracy: 0.0517 - val_loss: 2.9960 - val_accuracy: 0.0500\n",
      "Epoch 70/1000\n",
      "525/525 [==============================] - 4s 7ms/step - loss: 2.9962 - accuracy: 0.0529 - val_loss: 2.9960 - val_accuracy: 0.0515\n",
      "Epoch 71/1000\n",
      "525/525 [==============================] - 4s 8ms/step - loss: 2.9965 - accuracy: 0.0522 - val_loss: 2.9960 - val_accuracy: 0.0513\n",
      "Epoch 72/1000\n",
      "525/525 [==============================] - 4s 8ms/step - loss: 2.9974 - accuracy: 0.0486 - val_loss: 2.9960 - val_accuracy: 0.0511\n",
      "Epoch 73/1000\n",
      "525/525 [==============================] - 4s 7ms/step - loss: 2.9970 - accuracy: 0.0530 - val_loss: 2.9960 - val_accuracy: 0.0511\n",
      "Epoch 74/1000\n",
      "525/525 [==============================] - 4s 7ms/step - loss: 2.9974 - accuracy: 0.0513 - val_loss: 2.9960 - val_accuracy: 0.0515\n",
      "Epoch 75/1000\n",
      "525/525 [==============================] - 4s 7ms/step - loss: 2.9973 - accuracy: 0.0493 - val_loss: 2.9960 - val_accuracy: 0.0504\n",
      "Epoch 76/1000\n",
      "525/525 [==============================] - 4s 8ms/step - loss: 2.9965 - accuracy: 0.0532 - val_loss: 2.9960 - val_accuracy: 0.0502\n",
      "Epoch 77/1000\n",
      "525/525 [==============================] - 4s 8ms/step - loss: 2.9967 - accuracy: 0.0509 - val_loss: 2.9960 - val_accuracy: 0.0509\n",
      "Epoch 78/1000\n",
      "525/525 [==============================] - 4s 7ms/step - loss: 2.9967 - accuracy: 0.0512 - val_loss: 2.9960 - val_accuracy: 0.0509\n",
      "Epoch 79/1000\n",
      "525/525 [==============================] - 4s 7ms/step - loss: 2.9968 - accuracy: 0.0507 - val_loss: 2.9959 - val_accuracy: 0.0507\n",
      "Epoch 80/1000\n",
      "525/525 [==============================] - 4s 8ms/step - loss: 2.9964 - accuracy: 0.0521 - val_loss: 2.9959 - val_accuracy: 0.0515\n",
      "Epoch 81/1000\n",
      "525/525 [==============================] - 4s 7ms/step - loss: 2.9969 - accuracy: 0.0523 - val_loss: 2.9959 - val_accuracy: 0.0526\n",
      "Epoch 82/1000\n",
      "525/525 [==============================] - 4s 7ms/step - loss: 2.9966 - accuracy: 0.0519 - val_loss: 2.9960 - val_accuracy: 0.0496\n",
      "Epoch 83/1000\n",
      "525/525 [==============================] - 4s 7ms/step - loss: 2.9967 - accuracy: 0.0536 - val_loss: 2.9960 - val_accuracy: 0.0504\n",
      "Epoch 84/1000\n",
      "525/525 [==============================] - 4s 8ms/step - loss: 2.9974 - accuracy: 0.0499 - val_loss: 2.9959 - val_accuracy: 0.0511\n",
      "Epoch 85/1000\n",
      "525/525 [==============================] - 4s 7ms/step - loss: 2.9972 - accuracy: 0.0509 - val_loss: 2.9960 - val_accuracy: 0.0500\n",
      "Epoch 86/1000\n",
      "525/525 [==============================] - 4s 7ms/step - loss: 2.9972 - accuracy: 0.0515 - val_loss: 2.9959 - val_accuracy: 0.0507\n",
      "Epoch 87/1000\n",
      "525/525 [==============================] - 4s 7ms/step - loss: 2.9972 - accuracy: 0.0492 - val_loss: 2.9960 - val_accuracy: 0.0507\n",
      "Epoch 88/1000\n",
      "525/525 [==============================] - 4s 7ms/step - loss: 2.9976 - accuracy: 0.0498 - val_loss: 2.9960 - val_accuracy: 0.0507\n",
      "Epoch 89/1000\n",
      "525/525 [==============================] - 4s 7ms/step - loss: 2.9969 - accuracy: 0.0498 - val_loss: 2.9960 - val_accuracy: 0.0504\n",
      "Epoch 90/1000\n",
      "525/525 [==============================] - 4s 7ms/step - loss: 2.9970 - accuracy: 0.0498 - val_loss: 2.9960 - val_accuracy: 0.0511\n"
     ]
    }
   ],
   "source": [
    "train(model=model,\n",
    "      patience_train=20,\n",
    "      patience_val=None,\n",
    "      learning_rate=.000001,\n",
    "      epochs=1000,\n",
    "      batch_size=64,\n",
    "      # cont_train=True,\n",
    "      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "aZsHP0SPN1Lq",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 152628,
     "status": "ok",
     "timestamp": 1688899010811,
     "user": {
      "displayName": "Yoni Krichevsky",
      "userId": "07735752940575548299"
     },
     "user_tz": -180
    },
    "id": "aZsHP0SPN1Lq",
    "outputId": "019ee43c-1d57-4925-c19c-289ea5d87fd1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patience_train=20, patience_val=None, learning_rate=1e-07, epochs=1000, batch_size=64, cont_train=False, X_train.shape=(33566, 32, 20), y_train.shape=(33566,), X_val.shape=(4619, 32, 20), y_val.shape=(4619,)\n",
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_23 (LSTM)              (None, 32, 128)           76288     \n",
      "                                                                 \n",
      " lstm_24 (LSTM)              (None, 128)               131584    \n",
      "                                                                 \n",
      " dropout_14 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_33 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " dropout_15 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_34 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " dropout_16 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_35 (Dense)            (None, 20)                2580      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 243,476\n",
      "Trainable params: 243,476\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Input shape (None, 32, 20), output shape (None, 20)\n",
      "Epoch 1/1000\n",
      "525/525 [==============================] - 9s 9ms/step - loss: 2.9970 - accuracy: 0.0517 - val_loss: 2.9960 - val_accuracy: 0.0511\n",
      "Epoch 2/1000\n",
      "525/525 [==============================] - 4s 7ms/step - loss: 2.9975 - accuracy: 0.0507 - val_loss: 2.9960 - val_accuracy: 0.0511\n",
      "Epoch 3/1000\n",
      "525/525 [==============================] - 4s 8ms/step - loss: 2.9965 - accuracy: 0.0508 - val_loss: 2.9960 - val_accuracy: 0.0509\n",
      "Epoch 4/1000\n",
      "525/525 [==============================] - 4s 8ms/step - loss: 2.9966 - accuracy: 0.0505 - val_loss: 2.9960 - val_accuracy: 0.0509\n",
      "Epoch 5/1000\n",
      "525/525 [==============================] - 4s 7ms/step - loss: 2.9968 - accuracy: 0.0527 - val_loss: 2.9960 - val_accuracy: 0.0509\n",
      "Epoch 6/1000\n",
      "525/525 [==============================] - 4s 7ms/step - loss: 2.9970 - accuracy: 0.0518 - val_loss: 2.9960 - val_accuracy: 0.0509\n",
      "Epoch 7/1000\n",
      "525/525 [==============================] - 4s 7ms/step - loss: 2.9976 - accuracy: 0.0513 - val_loss: 2.9960 - val_accuracy: 0.0502\n",
      "Epoch 8/1000\n",
      "525/525 [==============================] - 4s 7ms/step - loss: 2.9970 - accuracy: 0.0475 - val_loss: 2.9960 - val_accuracy: 0.0509\n",
      "Epoch 9/1000\n",
      "525/525 [==============================] - 4s 7ms/step - loss: 2.9966 - accuracy: 0.0525 - val_loss: 2.9960 - val_accuracy: 0.0509\n",
      "Epoch 10/1000\n",
      "525/525 [==============================] - 4s 7ms/step - loss: 2.9968 - accuracy: 0.0495 - val_loss: 2.9960 - val_accuracy: 0.0509\n",
      "Epoch 11/1000\n",
      "525/525 [==============================] - 4s 7ms/step - loss: 2.9973 - accuracy: 0.0494 - val_loss: 2.9960 - val_accuracy: 0.0511\n",
      "Epoch 12/1000\n",
      "525/525 [==============================] - 4s 7ms/step - loss: 2.9979 - accuracy: 0.0487 - val_loss: 2.9960 - val_accuracy: 0.0511\n",
      "Epoch 13/1000\n",
      "525/525 [==============================] - 4s 7ms/step - loss: 2.9972 - accuracy: 0.0517 - val_loss: 2.9960 - val_accuracy: 0.0509\n",
      "Epoch 14/1000\n",
      "525/525 [==============================] - 4s 7ms/step - loss: 2.9967 - accuracy: 0.0498 - val_loss: 2.9960 - val_accuracy: 0.0509\n",
      "Epoch 15/1000\n",
      "525/525 [==============================] - 4s 7ms/step - loss: 2.9971 - accuracy: 0.0507 - val_loss: 2.9960 - val_accuracy: 0.0511\n",
      "Epoch 16/1000\n",
      "525/525 [==============================] - 4s 7ms/step - loss: 2.9969 - accuracy: 0.0500 - val_loss: 2.9960 - val_accuracy: 0.0511\n",
      "Epoch 17/1000\n",
      "525/525 [==============================] - 4s 8ms/step - loss: 2.9968 - accuracy: 0.0520 - val_loss: 2.9960 - val_accuracy: 0.0511\n",
      "Epoch 18/1000\n",
      "525/525 [==============================] - 4s 7ms/step - loss: 2.9962 - accuracy: 0.0509 - val_loss: 2.9960 - val_accuracy: 0.0511\n",
      "Epoch 19/1000\n",
      "525/525 [==============================] - 4s 7ms/step - loss: 2.9970 - accuracy: 0.0494 - val_loss: 2.9960 - val_accuracy: 0.0513\n",
      "Epoch 20/1000\n",
      "525/525 [==============================] - 4s 7ms/step - loss: 2.9971 - accuracy: 0.0511 - val_loss: 2.9960 - val_accuracy: 0.0513\n",
      "Epoch 21/1000\n",
      "525/525 [==============================] - 4s 7ms/step - loss: 2.9966 - accuracy: 0.0495 - val_loss: 2.9960 - val_accuracy: 0.0513\n",
      "Epoch 22/1000\n",
      "525/525 [==============================] - 4s 8ms/step - loss: 2.9969 - accuracy: 0.0481 - val_loss: 2.9960 - val_accuracy: 0.0513\n",
      "Epoch 23/1000\n",
      "525/525 [==============================] - 4s 7ms/step - loss: 2.9965 - accuracy: 0.0517 - val_loss: 2.9960 - val_accuracy: 0.0513\n",
      "Epoch 24/1000\n",
      "525/525 [==============================] - 4s 7ms/step - loss: 2.9970 - accuracy: 0.0515 - val_loss: 2.9960 - val_accuracy: 0.0513\n",
      "Epoch 25/1000\n",
      "525/525 [==============================] - 4s 7ms/step - loss: 2.9967 - accuracy: 0.0511 - val_loss: 2.9960 - val_accuracy: 0.0513\n",
      "Epoch 26/1000\n",
      "525/525 [==============================] - 4s 8ms/step - loss: 2.9970 - accuracy: 0.0507 - val_loss: 2.9960 - val_accuracy: 0.0511\n",
      "Epoch 27/1000\n",
      "525/525 [==============================] - 4s 7ms/step - loss: 2.9971 - accuracy: 0.0499 - val_loss: 2.9960 - val_accuracy: 0.0511\n",
      "Epoch 28/1000\n",
      "525/525 [==============================] - 4s 7ms/step - loss: 2.9973 - accuracy: 0.0498 - val_loss: 2.9960 - val_accuracy: 0.0511\n",
      "Epoch 29/1000\n",
      "525/525 [==============================] - 4s 7ms/step - loss: 2.9974 - accuracy: 0.0504 - val_loss: 2.9960 - val_accuracy: 0.0513\n",
      "Epoch 30/1000\n",
      "525/525 [==============================] - 4s 7ms/step - loss: 2.9967 - accuracy: 0.0516 - val_loss: 2.9960 - val_accuracy: 0.0513\n",
      "Epoch 31/1000\n",
      "525/525 [==============================] - 4s 7ms/step - loss: 2.9975 - accuracy: 0.0492 - val_loss: 2.9960 - val_accuracy: 0.0513\n",
      "Epoch 32/1000\n",
      "525/525 [==============================] - 4s 7ms/step - loss: 2.9973 - accuracy: 0.0493 - val_loss: 2.9960 - val_accuracy: 0.0513\n",
      "Epoch 33/1000\n",
      "525/525 [==============================] - 4s 7ms/step - loss: 2.9970 - accuracy: 0.0501 - val_loss: 2.9960 - val_accuracy: 0.0513\n",
      "Epoch 34/1000\n",
      "525/525 [==============================] - 4s 7ms/step - loss: 2.9975 - accuracy: 0.0484 - val_loss: 2.9960 - val_accuracy: 0.0513\n",
      "Epoch 35/1000\n",
      "525/525 [==============================] - 4s 8ms/step - loss: 2.9968 - accuracy: 0.0511 - val_loss: 2.9960 - val_accuracy: 0.0513\n",
      "Epoch 36/1000\n",
      "525/525 [==============================] - 4s 8ms/step - loss: 2.9968 - accuracy: 0.0515 - val_loss: 2.9960 - val_accuracy: 0.0513\n",
      "Epoch 37/1000\n",
      "525/525 [==============================] - 4s 7ms/step - loss: 2.9973 - accuracy: 0.0508 - val_loss: 2.9960 - val_accuracy: 0.0513\n",
      "Epoch 38/1000\n",
      "525/525 [==============================] - 4s 7ms/step - loss: 2.9973 - accuracy: 0.0495 - val_loss: 2.9960 - val_accuracy: 0.0511\n"
     ]
    }
   ],
   "source": [
    "train(model=model,\n",
    "      patience_train=20,\n",
    "      patience_val=None,\n",
    "      learning_rate=.0000001,\n",
    "      epochs=1000,\n",
    "      batch_size=64,\n",
    "      # cont_train=True,\n",
    "      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "Zb2dAqloOt5W",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 39565,
     "status": "ok",
     "timestamp": 1688899423653,
     "user": {
      "displayName": "Yoni Krichevsky",
      "userId": "07735752940575548299"
     },
     "user_tz": -180
    },
    "id": "Zb2dAqloOt5W",
    "outputId": "c71451af-54f9-40c1-9c86-18fac779e63f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patience_train=20, patience_val=None, learning_rate=1e-06, epochs=1000, batch_size=32, cont_train=False, X_train.shape=(33566, 32, 20), y_train.shape=(33566,), X_val.shape=(4619, 32, 20), y_val.shape=(4619,)\n",
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_23 (LSTM)              (None, 32, 128)           76288     \n",
      "                                                                 \n",
      " lstm_24 (LSTM)              (None, 128)               131584    \n",
      "                                                                 \n",
      " dropout_14 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_33 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " dropout_15 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_34 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " dropout_16 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_35 (Dense)            (None, 20)                2580      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 243,476\n",
      "Trainable params: 243,476\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Input shape (None, 32, 20), output shape (None, 20)\n",
      "Epoch 1/1000\n",
      "1049/1049 [==============================] - 13s 8ms/step - loss: 2.9971 - accuracy: 0.0512 - val_loss: 2.9960 - val_accuracy: 0.0509\n",
      "Epoch 2/1000\n",
      "1049/1049 [==============================] - 8s 7ms/step - loss: 2.9971 - accuracy: 0.0514 - val_loss: 2.9960 - val_accuracy: 0.0513\n",
      "Epoch 3/1000\n",
      "1049/1049 [==============================] - 8s 7ms/step - loss: 2.9970 - accuracy: 0.0506 - val_loss: 2.9960 - val_accuracy: 0.0517\n",
      "Epoch 4/1000\n",
      "1049/1049 [==============================] - 8s 7ms/step - loss: 2.9965 - accuracy: 0.0503 - val_loss: 2.9960 - val_accuracy: 0.0520\n",
      "Epoch 5/1000\n",
      "1049/1049 [==============================] - 8s 7ms/step - loss: 2.9970 - accuracy: 0.0509 - val_loss: 2.9960 - val_accuracy: 0.0500\n",
      "Epoch 6/1000\n",
      "1049/1049 [==============================] - 8s 7ms/step - loss: 2.9970 - accuracy: 0.0515 - val_loss: 2.9960 - val_accuracy: 0.0507\n",
      "Epoch 7/1000\n",
      "1049/1049 [==============================] - 8s 7ms/step - loss: 2.9974 - accuracy: 0.0501 - val_loss: 2.9960 - val_accuracy: 0.0515\n",
      "Epoch 8/1000\n",
      "1049/1049 [==============================] - 7s 7ms/step - loss: 2.9973 - accuracy: 0.0487 - val_loss: 2.9960 - val_accuracy: 0.0511\n",
      "Epoch 9/1000\n",
      "1049/1049 [==============================] - 8s 7ms/step - loss: 2.9973 - accuracy: 0.0498 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 10/1000\n",
      "1049/1049 [==============================] - 8s 7ms/step - loss: 2.9974 - accuracy: 0.0494 - val_loss: 2.9960 - val_accuracy: 0.0511\n",
      "Epoch 11/1000\n",
      "1049/1049 [==============================] - 8s 7ms/step - loss: 2.9965 - accuracy: 0.0517 - val_loss: 2.9960 - val_accuracy: 0.0504\n",
      "Epoch 12/1000\n",
      "1049/1049 [==============================] - 8s 7ms/step - loss: 2.9970 - accuracy: 0.0494 - val_loss: 2.9960 - val_accuracy: 0.0524\n",
      "Epoch 13/1000\n",
      "1049/1049 [==============================] - 8s 7ms/step - loss: 2.9968 - accuracy: 0.0509 - val_loss: 2.9960 - val_accuracy: 0.0500\n",
      "Epoch 14/1000\n",
      "1049/1049 [==============================] - 8s 7ms/step - loss: 2.9967 - accuracy: 0.0503 - val_loss: 2.9960 - val_accuracy: 0.0515\n",
      "Epoch 15/1000\n",
      "1049/1049 [==============================] - 8s 8ms/step - loss: 2.9969 - accuracy: 0.0506 - val_loss: 2.9960 - val_accuracy: 0.0522\n",
      "Epoch 16/1000\n",
      "1049/1049 [==============================] - 8s 7ms/step - loss: 2.9972 - accuracy: 0.0511 - val_loss: 2.9960 - val_accuracy: 0.0507\n",
      "Epoch 17/1000\n",
      "1049/1049 [==============================] - 8s 7ms/step - loss: 2.9974 - accuracy: 0.0486 - val_loss: 2.9960 - val_accuracy: 0.0509\n",
      "Epoch 18/1000\n",
      "1049/1049 [==============================] - 8s 7ms/step - loss: 2.9968 - accuracy: 0.0493 - val_loss: 2.9960 - val_accuracy: 0.0509\n",
      "Epoch 19/1000\n",
      "1049/1049 [==============================] - 8s 7ms/step - loss: 2.9961 - accuracy: 0.0531 - val_loss: 2.9960 - val_accuracy: 0.0520\n",
      "Epoch 20/1000\n",
      "1049/1049 [==============================] - 8s 7ms/step - loss: 2.9971 - accuracy: 0.0488 - val_loss: 2.9960 - val_accuracy: 0.0520\n",
      "Epoch 21/1000\n",
      "1049/1049 [==============================] - 8s 7ms/step - loss: 2.9969 - accuracy: 0.0516 - val_loss: 2.9960 - val_accuracy: 0.0515\n",
      "Epoch 22/1000\n",
      "1049/1049 [==============================] - 8s 7ms/step - loss: 2.9969 - accuracy: 0.0509 - val_loss: 2.9960 - val_accuracy: 0.0515\n",
      "Epoch 23/1000\n",
      "1049/1049 [==============================] - 8s 7ms/step - loss: 2.9961 - accuracy: 0.0507 - val_loss: 2.9960 - val_accuracy: 0.0524\n",
      "Epoch 24/1000\n",
      "1049/1049 [==============================] - 8s 7ms/step - loss: 2.9971 - accuracy: 0.0499 - val_loss: 2.9960 - val_accuracy: 0.0522\n",
      "Epoch 25/1000\n",
      "1049/1049 [==============================] - 8s 7ms/step - loss: 2.9972 - accuracy: 0.0505 - val_loss: 2.9960 - val_accuracy: 0.0520\n",
      "Epoch 26/1000\n",
      "1049/1049 [==============================] - 7s 7ms/step - loss: 2.9963 - accuracy: 0.0522 - val_loss: 2.9960 - val_accuracy: 0.0502\n",
      "Epoch 27/1000\n",
      "1049/1049 [==============================] - 8s 7ms/step - loss: 2.9968 - accuracy: 0.0512 - val_loss: 2.9960 - val_accuracy: 0.0500\n",
      "Epoch 28/1000\n",
      "1049/1049 [==============================] - 8s 7ms/step - loss: 2.9967 - accuracy: 0.0519 - val_loss: 2.9960 - val_accuracy: 0.0504\n",
      "Epoch 29/1000\n",
      "1049/1049 [==============================] - 8s 7ms/step - loss: 2.9973 - accuracy: 0.0506 - val_loss: 2.9960 - val_accuracy: 0.0500\n",
      "Epoch 30/1000\n",
      "1049/1049 [==============================] - 8s 7ms/step - loss: 2.9967 - accuracy: 0.0524 - val_loss: 2.9960 - val_accuracy: 0.0496\n",
      "Epoch 31/1000\n",
      "1049/1049 [==============================] - 8s 7ms/step - loss: 2.9969 - accuracy: 0.0514 - val_loss: 2.9960 - val_accuracy: 0.0522\n",
      "Epoch 32/1000\n",
      "1049/1049 [==============================] - 8s 7ms/step - loss: 2.9970 - accuracy: 0.0516 - val_loss: 2.9960 - val_accuracy: 0.0513\n",
      "Epoch 33/1000\n",
      "1049/1049 [==============================] - 8s 7ms/step - loss: 2.9966 - accuracy: 0.0509 - val_loss: 2.9960 - val_accuracy: 0.0509\n",
      "Epoch 34/1000\n",
      "1049/1049 [==============================] - 8s 7ms/step - loss: 2.9964 - accuracy: 0.0503 - val_loss: 2.9960 - val_accuracy: 0.0504\n",
      "Epoch 35/1000\n",
      "1049/1049 [==============================] - 8s 7ms/step - loss: 2.9971 - accuracy: 0.0504 - val_loss: 2.9960 - val_accuracy: 0.0517\n",
      "Epoch 36/1000\n",
      "1049/1049 [==============================] - 8s 7ms/step - loss: 2.9971 - accuracy: 0.0492 - val_loss: 2.9960 - val_accuracy: 0.0522\n",
      "Epoch 37/1000\n",
      "1049/1049 [==============================] - 8s 8ms/step - loss: 2.9969 - accuracy: 0.0493 - val_loss: 2.9960 - val_accuracy: 0.0517\n",
      "Epoch 38/1000\n",
      "1049/1049 [==============================] - 8s 7ms/step - loss: 2.9971 - accuracy: 0.0517 - val_loss: 2.9960 - val_accuracy: 0.0522\n",
      "Epoch 39/1000\n",
      "1049/1049 [==============================] - 8s 7ms/step - loss: 2.9973 - accuracy: 0.0512 - val_loss: 2.9960 - val_accuracy: 0.0517\n",
      "Epoch 40/1000\n",
      "1049/1049 [==============================] - 8s 7ms/step - loss: 2.9964 - accuracy: 0.0526 - val_loss: 2.9960 - val_accuracy: 0.0520\n",
      "Epoch 41/1000\n",
      "1049/1049 [==============================] - 8s 7ms/step - loss: 2.9965 - accuracy: 0.0512 - val_loss: 2.9960 - val_accuracy: 0.0515\n",
      "Epoch 42/1000\n",
      "1049/1049 [==============================] - 8s 7ms/step - loss: 2.9962 - accuracy: 0.0526 - val_loss: 2.9960 - val_accuracy: 0.0515\n",
      "Epoch 43/1000\n",
      "1049/1049 [==============================] - 7s 7ms/step - loss: 2.9966 - accuracy: 0.0501 - val_loss: 2.9960 - val_accuracy: 0.0515\n"
     ]
    }
   ],
   "source": [
    "train(model=model,\n",
    "      patience_train=20,\n",
    "      patience_val=None,\n",
    "      learning_rate=.000001,\n",
    "      epochs=1000,\n",
    "      batch_size=32,\n",
    "      # cont_train=True,\n",
    "      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "OnoQFxPNRDwN",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15235,
     "status": "ok",
     "timestamp": 1688901167720,
     "user": {
      "displayName": "Yoni Krichevsky",
      "userId": "07735752940575548299"
     },
     "user_tz": -180
    },
    "id": "OnoQFxPNRDwN",
    "outputId": "4b5469fe-fc8e-46e4-c945-df5cd4f7dc33"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patience_train=20, patience_val=None, learning_rate=0.0001, epochs=1000, batch_size=16, cont_train=False, X_train.shape=(33566, 32, 20), y_train.shape=(33566,), X_val.shape=(4619, 32, 20), y_val.shape=(4619,)\n",
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_23 (LSTM)              (None, 32, 128)           76288     \n",
      "                                                                 \n",
      " lstm_24 (LSTM)              (None, 128)               131584    \n",
      "                                                                 \n",
      " dropout_14 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_33 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " dropout_15 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_34 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " dropout_16 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_35 (Dense)            (None, 20)                2580      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 243,476\n",
      "Trainable params: 243,476\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Input shape (None, 32, 20), output shape (None, 20)\n",
      "Epoch 1/1000\n",
      "2098/2098 [==============================] - 20s 8ms/step - loss: 2.9970 - accuracy: 0.0501 - val_loss: 2.9962 - val_accuracy: 0.0517\n",
      "Epoch 2/1000\n",
      "2098/2098 [==============================] - 15s 7ms/step - loss: 2.9966 - accuracy: 0.0504 - val_loss: 2.9957 - val_accuracy: 0.0517\n",
      "Epoch 3/1000\n",
      "2098/2098 [==============================] - 15s 7ms/step - loss: 2.9964 - accuracy: 0.0501 - val_loss: 2.9959 - val_accuracy: 0.0487\n",
      "Epoch 4/1000\n",
      "2098/2098 [==============================] - 15s 7ms/step - loss: 2.9964 - accuracy: 0.0489 - val_loss: 2.9960 - val_accuracy: 0.0517\n",
      "Epoch 5/1000\n",
      "2098/2098 [==============================] - 15s 7ms/step - loss: 2.9962 - accuracy: 0.0516 - val_loss: 2.9959 - val_accuracy: 0.0487\n",
      "Epoch 6/1000\n",
      "2098/2098 [==============================] - 15s 7ms/step - loss: 2.9959 - accuracy: 0.0503 - val_loss: 2.9960 - val_accuracy: 0.0509\n",
      "Epoch 7/1000\n",
      "2098/2098 [==============================] - 15s 7ms/step - loss: 2.9960 - accuracy: 0.0509 - val_loss: 2.9960 - val_accuracy: 0.0465\n",
      "Epoch 8/1000\n",
      "2098/2098 [==============================] - 15s 7ms/step - loss: 2.9959 - accuracy: 0.0519 - val_loss: 2.9960 - val_accuracy: 0.0517\n",
      "Epoch 9/1000\n",
      "2098/2098 [==============================] - 15s 7ms/step - loss: 2.9959 - accuracy: 0.0515 - val_loss: 2.9960 - val_accuracy: 0.0517\n",
      "Epoch 10/1000\n",
      "2098/2098 [==============================] - 15s 7ms/step - loss: 2.9960 - accuracy: 0.0503 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 11/1000\n",
      "2098/2098 [==============================] - 15s 7ms/step - loss: 2.9960 - accuracy: 0.0491 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 12/1000\n",
      "2098/2098 [==============================] - 16s 7ms/step - loss: 2.9958 - accuracy: 0.0490 - val_loss: 2.9958 - val_accuracy: 0.0517\n",
      "Epoch 13/1000\n",
      "2098/2098 [==============================] - 15s 7ms/step - loss: 2.9958 - accuracy: 0.0506 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 14/1000\n",
      "2098/2098 [==============================] - 15s 7ms/step - loss: 2.9958 - accuracy: 0.0515 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 15/1000\n",
      "2098/2098 [==============================] - 15s 7ms/step - loss: 2.9958 - accuracy: 0.0515 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 16/1000\n",
      "2098/2098 [==============================] - 15s 7ms/step - loss: 2.9958 - accuracy: 0.0506 - val_loss: 2.9958 - val_accuracy: 0.0517\n",
      "Epoch 17/1000\n",
      "2098/2098 [==============================] - 15s 7ms/step - loss: 2.9958 - accuracy: 0.0517 - val_loss: 2.9959 - val_accuracy: 0.0465\n",
      "Epoch 18/1000\n",
      "2098/2098 [==============================] - 15s 7ms/step - loss: 2.9957 - accuracy: 0.0498 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 19/1000\n",
      "2098/2098 [==============================] - 15s 7ms/step - loss: 2.9957 - accuracy: 0.0496 - val_loss: 2.9960 - val_accuracy: 0.0517\n",
      "Epoch 20/1000\n",
      "2098/2098 [==============================] - 15s 7ms/step - loss: 2.9957 - accuracy: 0.0480 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 21/1000\n",
      "2098/2098 [==============================] - 15s 7ms/step - loss: 2.9958 - accuracy: 0.0515 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 22/1000\n",
      "2098/2098 [==============================] - 15s 7ms/step - loss: 2.9957 - accuracy: 0.0505 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 23/1000\n",
      "2098/2098 [==============================] - 15s 7ms/step - loss: 2.9957 - accuracy: 0.0521 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 24/1000\n",
      "2098/2098 [==============================] - 16s 7ms/step - loss: 2.9957 - accuracy: 0.0494 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 25/1000\n",
      "2098/2098 [==============================] - 15s 7ms/step - loss: 2.9957 - accuracy: 0.0486 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 26/1000\n",
      "2098/2098 [==============================] - 15s 7ms/step - loss: 2.9956 - accuracy: 0.0506 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 27/1000\n",
      "2098/2098 [==============================] - 15s 7ms/step - loss: 2.9957 - accuracy: 0.0519 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 28/1000\n",
      "2098/2098 [==============================] - 15s 7ms/step - loss: 2.9957 - accuracy: 0.0512 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 29/1000\n",
      "2098/2098 [==============================] - 15s 7ms/step - loss: 2.9956 - accuracy: 0.0506 - val_loss: 2.9958 - val_accuracy: 0.0517\n",
      "Epoch 30/1000\n",
      "2098/2098 [==============================] - 15s 7ms/step - loss: 2.9957 - accuracy: 0.0514 - val_loss: 2.9958 - val_accuracy: 0.0517\n",
      "Epoch 31/1000\n",
      "2098/2098 [==============================] - 15s 7ms/step - loss: 2.9956 - accuracy: 0.0522 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 32/1000\n",
      "2098/2098 [==============================] - 15s 7ms/step - loss: 2.9956 - accuracy: 0.0512 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 33/1000\n",
      "2098/2098 [==============================] - 15s 7ms/step - loss: 2.9957 - accuracy: 0.0489 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 34/1000\n",
      "2098/2098 [==============================] - 15s 7ms/step - loss: 2.9956 - accuracy: 0.0506 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 35/1000\n",
      "2098/2098 [==============================] - 15s 7ms/step - loss: 2.9957 - accuracy: 0.0513 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 36/1000\n",
      "2098/2098 [==============================] - 15s 7ms/step - loss: 2.9956 - accuracy: 0.0505 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 37/1000\n",
      "2098/2098 [==============================] - 15s 7ms/step - loss: 2.9956 - accuracy: 0.0518 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 38/1000\n",
      "2098/2098 [==============================] - 15s 7ms/step - loss: 2.9956 - accuracy: 0.0508 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 39/1000\n",
      "2098/2098 [==============================] - 15s 7ms/step - loss: 2.9956 - accuracy: 0.0512 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 40/1000\n",
      "2098/2098 [==============================] - 15s 7ms/step - loss: 2.9956 - accuracy: 0.0511 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 41/1000\n",
      "2098/2098 [==============================] - 15s 7ms/step - loss: 2.9956 - accuracy: 0.0516 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 42/1000\n",
      "2098/2098 [==============================] - 15s 7ms/step - loss: 2.9956 - accuracy: 0.0511 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 43/1000\n",
      "2098/2098 [==============================] - 15s 7ms/step - loss: 2.9956 - accuracy: 0.0502 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 44/1000\n",
      "2098/2098 [==============================] - 15s 7ms/step - loss: 2.9956 - accuracy: 0.0515 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 45/1000\n",
      "2098/2098 [==============================] - 15s 7ms/step - loss: 2.9956 - accuracy: 0.0517 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 46/1000\n",
      "2098/2098 [==============================] - 15s 7ms/step - loss: 2.9956 - accuracy: 0.0503 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 47/1000\n",
      "2098/2098 [==============================] - 15s 7ms/step - loss: 2.9956 - accuracy: 0.0505 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 48/1000\n",
      "2098/2098 [==============================] - 15s 7ms/step - loss: 2.9956 - accuracy: 0.0514 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 49/1000\n",
      "2098/2098 [==============================] - 15s 7ms/step - loss: 2.9956 - accuracy: 0.0505 - val_loss: 2.9959 - val_accuracy: 0.0522\n",
      "Epoch 50/1000\n",
      "2098/2098 [==============================] - 15s 7ms/step - loss: 2.9956 - accuracy: 0.0514 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 51/1000\n",
      "2098/2098 [==============================] - 15s 7ms/step - loss: 2.9956 - accuracy: 0.0501 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 52/1000\n",
      "2098/2098 [==============================] - 15s 7ms/step - loss: 2.9956 - accuracy: 0.0516 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 53/1000\n",
      "2098/2098 [==============================] - 15s 7ms/step - loss: 2.9956 - accuracy: 0.0512 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 54/1000\n",
      "2098/2098 [==============================] - 15s 7ms/step - loss: 2.9956 - accuracy: 0.0498 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 55/1000\n",
      "2098/2098 [==============================] - 15s 7ms/step - loss: 2.9956 - accuracy: 0.0511 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 56/1000\n",
      "2098/2098 [==============================] - 15s 7ms/step - loss: 2.9956 - accuracy: 0.0513 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 57/1000\n",
      "2098/2098 [==============================] - 15s 7ms/step - loss: 2.9956 - accuracy: 0.0513 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 58/1000\n",
      "2098/2098 [==============================] - 15s 7ms/step - loss: 2.9956 - accuracy: 0.0521 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 59/1000\n",
      "2098/2098 [==============================] - 15s 7ms/step - loss: 2.9956 - accuracy: 0.0515 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 60/1000\n",
      "2098/2098 [==============================] - 15s 7ms/step - loss: 2.9956 - accuracy: 0.0512 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 61/1000\n",
      "2098/2098 [==============================] - 15s 7ms/step - loss: 2.9956 - accuracy: 0.0508 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 62/1000\n",
      "2098/2098 [==============================] - 15s 7ms/step - loss: 2.9956 - accuracy: 0.0523 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 63/1000\n",
      "2098/2098 [==============================] - 15s 7ms/step - loss: 2.9956 - accuracy: 0.0517 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 64/1000\n",
      "2098/2098 [==============================] - 15s 7ms/step - loss: 2.9956 - accuracy: 0.0512 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 65/1000\n",
      "2098/2098 [==============================] - 15s 7ms/step - loss: 2.9956 - accuracy: 0.0518 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 66/1000\n",
      "2098/2098 [==============================] - 15s 7ms/step - loss: 2.9956 - accuracy: 0.0503 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 67/1000\n",
      "2098/2098 [==============================] - 15s 7ms/step - loss: 2.9956 - accuracy: 0.0512 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 68/1000\n",
      "2098/2098 [==============================] - 15s 7ms/step - loss: 2.9956 - accuracy: 0.0516 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 69/1000\n",
      "2098/2098 [==============================] - 15s 7ms/step - loss: 2.9956 - accuracy: 0.0514 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 70/1000\n",
      "2098/2098 [==============================] - 15s 7ms/step - loss: 2.9956 - accuracy: 0.0498 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 71/1000\n",
      "2098/2098 [==============================] - 15s 7ms/step - loss: 2.9956 - accuracy: 0.0492 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 72/1000\n",
      "2098/2098 [==============================] - 15s 7ms/step - loss: 2.9956 - accuracy: 0.0507 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 73/1000\n",
      "2098/2098 [==============================] - 15s 7ms/step - loss: 2.9956 - accuracy: 0.0517 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 74/1000\n",
      "2098/2098 [==============================] - 15s 7ms/step - loss: 2.9956 - accuracy: 0.0512 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 75/1000\n",
      "2098/2098 [==============================] - 15s 7ms/step - loss: 2.9956 - accuracy: 0.0509 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 76/1000\n",
      "2098/2098 [==============================] - 15s 7ms/step - loss: 2.9956 - accuracy: 0.0515 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 77/1000\n",
      "2098/2098 [==============================] - 15s 7ms/step - loss: 2.9956 - accuracy: 0.0515 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 78/1000\n",
      "2098/2098 [==============================] - 15s 7ms/step - loss: 2.9956 - accuracy: 0.0519 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 79/1000\n",
      "2098/2098 [==============================] - 15s 7ms/step - loss: 2.9956 - accuracy: 0.0509 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 80/1000\n",
      "2098/2098 [==============================] - 15s 7ms/step - loss: 2.9956 - accuracy: 0.0522 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 81/1000\n",
      "2098/2098 [==============================] - 15s 7ms/step - loss: 2.9956 - accuracy: 0.0509 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 82/1000\n",
      "2098/2098 [==============================] - 15s 7ms/step - loss: 2.9956 - accuracy: 0.0512 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 83/1000\n",
      "2098/2098 [==============================] - 15s 7ms/step - loss: 2.9956 - accuracy: 0.0515 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 84/1000\n",
      "2098/2098 [==============================] - 15s 7ms/step - loss: 2.9956 - accuracy: 0.0512 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 85/1000\n",
      "2098/2098 [==============================] - 15s 7ms/step - loss: 2.9956 - accuracy: 0.0516 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 86/1000\n",
      "2098/2098 [==============================] - 15s 7ms/step - loss: 2.9956 - accuracy: 0.0506 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 87/1000\n",
      "2098/2098 [==============================] - 15s 7ms/step - loss: 2.9956 - accuracy: 0.0517 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 88/1000\n",
      "2098/2098 [==============================] - 15s 7ms/step - loss: 2.9956 - accuracy: 0.0518 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 89/1000\n",
      "2098/2098 [==============================] - 16s 7ms/step - loss: 2.9956 - accuracy: 0.0515 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 90/1000\n",
      "2098/2098 [==============================] - 16s 8ms/step - loss: 2.9956 - accuracy: 0.0517 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 91/1000\n",
      "2098/2098 [==============================] - 16s 7ms/step - loss: 2.9956 - accuracy: 0.0514 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 92/1000\n",
      "2098/2098 [==============================] - 15s 7ms/step - loss: 2.9956 - accuracy: 0.0517 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 93/1000\n",
      "2098/2098 [==============================] - 16s 8ms/step - loss: 2.9956 - accuracy: 0.0511 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 94/1000\n",
      "2098/2098 [==============================] - 16s 7ms/step - loss: 2.9956 - accuracy: 0.0512 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 95/1000\n",
      "2098/2098 [==============================] - 15s 7ms/step - loss: 2.9956 - accuracy: 0.0512 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 96/1000\n",
      "2098/2098 [==============================] - 16s 7ms/step - loss: 2.9956 - accuracy: 0.0517 - val_loss: 2.9959 - val_accuracy: 0.0517\n"
     ]
    }
   ],
   "source": [
    "train(model=model,\n",
    "      patience_train=20,\n",
    "      patience_val=None,\n",
    "      learning_rate=.0001,\n",
    "      epochs=1000,\n",
    "      batch_size=16,\n",
    "      # cont_train=True,\n",
    "      )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "WkGgntksT6CK",
   "metadata": {
    "id": "WkGgntksT6CK"
   },
   "source": [
    "## Bidirectional, more LSTM, only 1 Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "pksYqTFyT8sJ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 364632,
     "status": "ok",
     "timestamp": 1688901887763,
     "user": {
      "displayName": "Yoni Krichevsky",
      "userId": "07735752940575548299"
     },
     "user_tz": -180
    },
    "id": "pksYqTFyT8sJ",
    "outputId": "10ad9d0a-1b1e-4319-84ca-7ae29b9d9bfb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patience_train=10, patience_val=None, learning_rate=1e-05, epochs=1000, batch_size=128, cont_train=False, X_train.shape=(33566, 32, 20), y_train.shape=(33566,), X_val.shape=(4619, 32, 20), y_val.shape=(4619,)\n",
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bidirectional (Bidirectiona  (None, 32, 256)          152576    \n",
      " l)                                                              \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirectio  (None, 32, 256)          394240    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " bidirectional_2 (Bidirectio  (None, 32, 256)          394240    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " bidirectional_3 (Bidirectio  (None, 32, 256)          394240    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " bidirectional_4 (Bidirectio  (None, 256)              394240    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dropout_17 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_36 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_18 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_37 (Dense)            (None, 20)                2580      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,765,012\n",
      "Trainable params: 1,765,012\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Input shape (None, 32, 20), output shape (None, 20)\n",
      "Epoch 1/1000\n",
      "263/263 [==============================] - 26s 36ms/step - loss: 3.1367 - accuracy: 0.0515 - val_loss: 3.0057 - val_accuracy: 0.0465\n",
      "Epoch 2/1000\n",
      "263/263 [==============================] - 6s 23ms/step - loss: 3.0459 - accuracy: 0.0493 - val_loss: 2.9969 - val_accuracy: 0.0465\n",
      "Epoch 3/1000\n",
      "263/263 [==============================] - 6s 23ms/step - loss: 3.0432 - accuracy: 0.0490 - val_loss: 2.9962 - val_accuracy: 0.0465\n",
      "Epoch 4/1000\n",
      "263/263 [==============================] - 6s 24ms/step - loss: 3.0335 - accuracy: 0.0495 - val_loss: 2.9961 - val_accuracy: 0.0465\n",
      "Epoch 5/1000\n",
      "263/263 [==============================] - 6s 23ms/step - loss: 3.0300 - accuracy: 0.0485 - val_loss: 2.9960 - val_accuracy: 0.0465\n",
      "Epoch 6/1000\n",
      "263/263 [==============================] - 6s 24ms/step - loss: 3.0246 - accuracy: 0.0513 - val_loss: 2.9957 - val_accuracy: 0.0468\n",
      "Epoch 7/1000\n",
      "263/263 [==============================] - 6s 23ms/step - loss: 3.0281 - accuracy: 0.0495 - val_loss: 2.9959 - val_accuracy: 0.0509\n",
      "Epoch 8/1000\n",
      "263/263 [==============================] - 6s 23ms/step - loss: 3.0246 - accuracy: 0.0511 - val_loss: 2.9959 - val_accuracy: 0.0465\n",
      "Epoch 9/1000\n",
      "263/263 [==============================] - 6s 23ms/step - loss: 3.0218 - accuracy: 0.0499 - val_loss: 2.9957 - val_accuracy: 0.0498\n",
      "Epoch 10/1000\n",
      "263/263 [==============================] - 6s 23ms/step - loss: 3.0205 - accuracy: 0.0494 - val_loss: 2.9958 - val_accuracy: 0.0517\n",
      "Epoch 11/1000\n",
      "263/263 [==============================] - 6s 23ms/step - loss: 3.0165 - accuracy: 0.0494 - val_loss: 2.9957 - val_accuracy: 0.0515\n",
      "Epoch 12/1000\n",
      "263/263 [==============================] - 6s 24ms/step - loss: 3.0171 - accuracy: 0.0512 - val_loss: 2.9959 - val_accuracy: 0.0522\n",
      "Epoch 13/1000\n",
      "263/263 [==============================] - 6s 23ms/step - loss: 3.0153 - accuracy: 0.0489 - val_loss: 2.9960 - val_accuracy: 0.0465\n",
      "Epoch 14/1000\n",
      "263/263 [==============================] - 6s 24ms/step - loss: 3.0134 - accuracy: 0.0506 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 15/1000\n",
      "263/263 [==============================] - 6s 23ms/step - loss: 3.0129 - accuracy: 0.0478 - val_loss: 2.9959 - val_accuracy: 0.0522\n",
      "Epoch 16/1000\n",
      "263/263 [==============================] - 6s 23ms/step - loss: 3.0124 - accuracy: 0.0501 - val_loss: 2.9960 - val_accuracy: 0.0487\n",
      "Epoch 17/1000\n",
      "263/263 [==============================] - 6s 24ms/step - loss: 3.0124 - accuracy: 0.0483 - val_loss: 2.9960 - val_accuracy: 0.0463\n",
      "Epoch 18/1000\n",
      "263/263 [==============================] - 6s 24ms/step - loss: 3.0107 - accuracy: 0.0490 - val_loss: 2.9960 - val_accuracy: 0.0465\n",
      "Epoch 19/1000\n",
      "263/263 [==============================] - 6s 23ms/step - loss: 3.0096 - accuracy: 0.0487 - val_loss: 2.9960 - val_accuracy: 0.0483\n",
      "Epoch 20/1000\n",
      "263/263 [==============================] - 6s 23ms/step - loss: 3.0081 - accuracy: 0.0492 - val_loss: 2.9961 - val_accuracy: 0.0465\n",
      "Epoch 21/1000\n",
      "263/263 [==============================] - 6s 23ms/step - loss: 3.0079 - accuracy: 0.0516 - val_loss: 2.9960 - val_accuracy: 0.0524\n",
      "Epoch 22/1000\n",
      "263/263 [==============================] - 6s 24ms/step - loss: 3.0081 - accuracy: 0.0514 - val_loss: 2.9960 - val_accuracy: 0.0522\n",
      "Epoch 23/1000\n",
      "263/263 [==============================] - 6s 24ms/step - loss: 3.0066 - accuracy: 0.0529 - val_loss: 2.9961 - val_accuracy: 0.0465\n",
      "Epoch 24/1000\n",
      "263/263 [==============================] - 6s 23ms/step - loss: 3.0060 - accuracy: 0.0512 - val_loss: 2.9960 - val_accuracy: 0.0511\n",
      "Epoch 25/1000\n",
      "263/263 [==============================] - 6s 23ms/step - loss: 3.0055 - accuracy: 0.0495 - val_loss: 2.9959 - val_accuracy: 0.0522\n",
      "Epoch 26/1000\n",
      "263/263 [==============================] - 6s 23ms/step - loss: 3.0048 - accuracy: 0.0517 - val_loss: 2.9960 - val_accuracy: 0.0522\n",
      "Epoch 27/1000\n",
      "263/263 [==============================] - 6s 24ms/step - loss: 3.0033 - accuracy: 0.0503 - val_loss: 2.9961 - val_accuracy: 0.0502\n",
      "Epoch 28/1000\n",
      "263/263 [==============================] - 6s 23ms/step - loss: 3.0046 - accuracy: 0.0508 - val_loss: 2.9960 - val_accuracy: 0.0517\n",
      "Epoch 29/1000\n",
      "263/263 [==============================] - 6s 24ms/step - loss: 3.0029 - accuracy: 0.0503 - val_loss: 2.9960 - val_accuracy: 0.0522\n",
      "Epoch 30/1000\n",
      "263/263 [==============================] - 6s 23ms/step - loss: 3.0025 - accuracy: 0.0504 - val_loss: 2.9961 - val_accuracy: 0.0522\n",
      "Epoch 31/1000\n",
      "263/263 [==============================] - 6s 23ms/step - loss: 3.0030 - accuracy: 0.0509 - val_loss: 2.9960 - val_accuracy: 0.0522\n",
      "Epoch 32/1000\n",
      "263/263 [==============================] - 6s 23ms/step - loss: 3.0024 - accuracy: 0.0518 - val_loss: 2.9960 - val_accuracy: 0.0522\n",
      "Epoch 33/1000\n",
      "263/263 [==============================] - 6s 24ms/step - loss: 3.0021 - accuracy: 0.0501 - val_loss: 2.9960 - val_accuracy: 0.0522\n",
      "Epoch 34/1000\n",
      "263/263 [==============================] - 6s 23ms/step - loss: 3.0008 - accuracy: 0.0520 - val_loss: 2.9961 - val_accuracy: 0.0522\n",
      "Epoch 35/1000\n",
      "263/263 [==============================] - 6s 24ms/step - loss: 3.0023 - accuracy: 0.0488 - val_loss: 2.9960 - val_accuracy: 0.0507\n",
      "Epoch 36/1000\n",
      "263/263 [==============================] - 6s 23ms/step - loss: 3.0003 - accuracy: 0.0487 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 37/1000\n",
      "263/263 [==============================] - 6s 23ms/step - loss: 3.0011 - accuracy: 0.0496 - val_loss: 2.9959 - val_accuracy: 0.0522\n",
      "Epoch 38/1000\n",
      "263/263 [==============================] - 6s 23ms/step - loss: 2.9989 - accuracy: 0.0521 - val_loss: 2.9960 - val_accuracy: 0.0522\n",
      "Epoch 39/1000\n",
      "263/263 [==============================] - 6s 23ms/step - loss: 3.0000 - accuracy: 0.0495 - val_loss: 2.9960 - val_accuracy: 0.0517\n",
      "Epoch 40/1000\n",
      "263/263 [==============================] - 6s 24ms/step - loss: 2.9999 - accuracy: 0.0516 - val_loss: 2.9960 - val_accuracy: 0.0517\n",
      "Epoch 41/1000\n",
      "263/263 [==============================] - 6s 24ms/step - loss: 2.9997 - accuracy: 0.0499 - val_loss: 2.9960 - val_accuracy: 0.0517\n",
      "Epoch 42/1000\n",
      "263/263 [==============================] - 6s 23ms/step - loss: 2.9999 - accuracy: 0.0519 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 43/1000\n",
      "263/263 [==============================] - 6s 24ms/step - loss: 2.9991 - accuracy: 0.0490 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 44/1000\n",
      "263/263 [==============================] - 6s 23ms/step - loss: 2.9994 - accuracy: 0.0500 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 45/1000\n",
      "263/263 [==============================] - 6s 24ms/step - loss: 2.9985 - accuracy: 0.0520 - val_loss: 2.9960 - val_accuracy: 0.0517\n",
      "Epoch 46/1000\n",
      "263/263 [==============================] - 6s 24ms/step - loss: 2.9988 - accuracy: 0.0507 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 47/1000\n",
      "263/263 [==============================] - 6s 23ms/step - loss: 2.9986 - accuracy: 0.0500 - val_loss: 2.9960 - val_accuracy: 0.0522\n",
      "Epoch 48/1000\n",
      "263/263 [==============================] - 6s 23ms/step - loss: 2.9992 - accuracy: 0.0485 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 49/1000\n",
      "263/263 [==============================] - 6s 23ms/step - loss: 2.9983 - accuracy: 0.0509 - val_loss: 2.9960 - val_accuracy: 0.0517\n",
      "Epoch 50/1000\n",
      "263/263 [==============================] - 6s 23ms/step - loss: 2.9986 - accuracy: 0.0496 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 51/1000\n",
      "263/263 [==============================] - 6s 24ms/step - loss: 2.9983 - accuracy: 0.0514 - val_loss: 2.9960 - val_accuracy: 0.0522\n",
      "Epoch 52/1000\n",
      "263/263 [==============================] - 6s 24ms/step - loss: 2.9978 - accuracy: 0.0517 - val_loss: 2.9960 - val_accuracy: 0.0522\n",
      "Epoch 53/1000\n",
      "263/263 [==============================] - 6s 23ms/step - loss: 2.9982 - accuracy: 0.0490 - val_loss: 2.9959 - val_accuracy: 0.0522\n",
      "Epoch 54/1000\n",
      "263/263 [==============================] - 6s 24ms/step - loss: 2.9976 - accuracy: 0.0517 - val_loss: 2.9958 - val_accuracy: 0.0517\n",
      "Epoch 55/1000\n",
      "263/263 [==============================] - 6s 23ms/step - loss: 2.9979 - accuracy: 0.0483 - val_loss: 2.9958 - val_accuracy: 0.0517\n",
      "Epoch 56/1000\n",
      "263/263 [==============================] - 6s 23ms/step - loss: 2.9980 - accuracy: 0.0512 - val_loss: 2.9958 - val_accuracy: 0.0517\n",
      "Epoch 57/1000\n",
      "263/263 [==============================] - 6s 23ms/step - loss: 2.9977 - accuracy: 0.0515 - val_loss: 2.9958 - val_accuracy: 0.0517\n",
      "Epoch 58/1000\n",
      "263/263 [==============================] - 6s 23ms/step - loss: 2.9981 - accuracy: 0.0495 - val_loss: 2.9957 - val_accuracy: 0.0520\n",
      "Epoch 59/1000\n",
      "263/263 [==============================] - 6s 23ms/step - loss: 2.9972 - accuracy: 0.0504 - val_loss: 2.9957 - val_accuracy: 0.0520\n",
      "Epoch 60/1000\n",
      "263/263 [==============================] - 6s 23ms/step - loss: 2.9975 - accuracy: 0.0512 - val_loss: 2.9957 - val_accuracy: 0.0520\n",
      "Epoch 61/1000\n",
      "263/263 [==============================] - 6s 23ms/step - loss: 2.9972 - accuracy: 0.0503 - val_loss: 2.9957 - val_accuracy: 0.0517\n",
      "Epoch 62/1000\n",
      "263/263 [==============================] - 6s 24ms/step - loss: 2.9972 - accuracy: 0.0488 - val_loss: 2.9957 - val_accuracy: 0.0520\n",
      "Epoch 63/1000\n",
      "263/263 [==============================] - 6s 23ms/step - loss: 2.9968 - accuracy: 0.0520 - val_loss: 2.9957 - val_accuracy: 0.0520\n",
      "Epoch 64/1000\n",
      "263/263 [==============================] - 6s 23ms/step - loss: 2.9971 - accuracy: 0.0504 - val_loss: 2.9956 - val_accuracy: 0.0530\n",
      "Epoch 65/1000\n",
      "263/263 [==============================] - 6s 23ms/step - loss: 2.9970 - accuracy: 0.0497 - val_loss: 2.9956 - val_accuracy: 0.0520\n",
      "Epoch 66/1000\n",
      "263/263 [==============================] - 6s 23ms/step - loss: 2.9973 - accuracy: 0.0507 - val_loss: 2.9957 - val_accuracy: 0.0520\n",
      "Epoch 67/1000\n",
      "263/263 [==============================] - 6s 23ms/step - loss: 2.9971 - accuracy: 0.0480 - val_loss: 2.9957 - val_accuracy: 0.0533\n",
      "Epoch 68/1000\n",
      "263/263 [==============================] - 6s 23ms/step - loss: 2.9970 - accuracy: 0.0511 - val_loss: 2.9957 - val_accuracy: 0.0520\n",
      "Epoch 69/1000\n",
      "263/263 [==============================] - 6s 24ms/step - loss: 2.9967 - accuracy: 0.0525 - val_loss: 2.9957 - val_accuracy: 0.0520\n",
      "Epoch 70/1000\n",
      "263/263 [==============================] - 6s 23ms/step - loss: 2.9968 - accuracy: 0.0504 - val_loss: 2.9957 - val_accuracy: 0.0520\n",
      "Epoch 71/1000\n",
      "263/263 [==============================] - 6s 23ms/step - loss: 2.9970 - accuracy: 0.0520 - val_loss: 2.9957 - val_accuracy: 0.0517\n",
      "Epoch 72/1000\n",
      "263/263 [==============================] - 6s 25ms/step - loss: 2.9969 - accuracy: 0.0527 - val_loss: 2.9957 - val_accuracy: 0.0509\n",
      "Epoch 73/1000\n",
      "263/263 [==============================] - 6s 24ms/step - loss: 2.9963 - accuracy: 0.0518 - val_loss: 2.9957 - val_accuracy: 0.0517\n",
      "Epoch 74/1000\n",
      "263/263 [==============================] - 6s 23ms/step - loss: 2.9964 - accuracy: 0.0503 - val_loss: 2.9958 - val_accuracy: 0.0509\n",
      "Epoch 75/1000\n",
      "263/263 [==============================] - 6s 23ms/step - loss: 2.9963 - accuracy: 0.0521 - val_loss: 2.9958 - val_accuracy: 0.0522\n",
      "Epoch 76/1000\n",
      "263/263 [==============================] - 6s 23ms/step - loss: 2.9964 - accuracy: 0.0499 - val_loss: 2.9958 - val_accuracy: 0.0524\n",
      "Epoch 77/1000\n",
      "263/263 [==============================] - 6s 23ms/step - loss: 2.9967 - accuracy: 0.0513 - val_loss: 2.9957 - val_accuracy: 0.0520\n",
      "Epoch 78/1000\n",
      "263/263 [==============================] - 6s 23ms/step - loss: 2.9967 - accuracy: 0.0494 - val_loss: 2.9958 - val_accuracy: 0.0546\n",
      "Epoch 79/1000\n",
      "263/263 [==============================] - 6s 23ms/step - loss: 2.9959 - accuracy: 0.0521 - val_loss: 2.9957 - val_accuracy: 0.0513\n",
      "Epoch 80/1000\n",
      "263/263 [==============================] - 6s 24ms/step - loss: 2.9961 - accuracy: 0.0513 - val_loss: 2.9958 - val_accuracy: 0.0520\n",
      "Epoch 81/1000\n",
      "263/263 [==============================] - 6s 24ms/step - loss: 2.9963 - accuracy: 0.0500 - val_loss: 2.9957 - val_accuracy: 0.0494\n",
      "Epoch 82/1000\n",
      "263/263 [==============================] - 6s 23ms/step - loss: 2.9963 - accuracy: 0.0486 - val_loss: 2.9958 - val_accuracy: 0.0502\n",
      "Epoch 83/1000\n",
      "263/263 [==============================] - 6s 24ms/step - loss: 2.9963 - accuracy: 0.0523 - val_loss: 2.9958 - val_accuracy: 0.0515\n",
      "Epoch 84/1000\n",
      "263/263 [==============================] - 6s 23ms/step - loss: 2.9965 - accuracy: 0.0490 - val_loss: 2.9958 - val_accuracy: 0.0509\n",
      "Epoch 85/1000\n",
      "263/263 [==============================] - 6s 23ms/step - loss: 2.9958 - accuracy: 0.0528 - val_loss: 2.9958 - val_accuracy: 0.0533\n",
      "Epoch 86/1000\n",
      "263/263 [==============================] - 6s 24ms/step - loss: 2.9957 - accuracy: 0.0516 - val_loss: 2.9958 - val_accuracy: 0.0485\n",
      "Epoch 87/1000\n",
      "263/263 [==============================] - 6s 23ms/step - loss: 2.9962 - accuracy: 0.0507 - val_loss: 2.9958 - val_accuracy: 0.0517\n",
      "Epoch 88/1000\n",
      "263/263 [==============================] - 6s 23ms/step - loss: 2.9961 - accuracy: 0.0519 - val_loss: 2.9958 - val_accuracy: 0.0515\n",
      "Epoch 89/1000\n",
      "263/263 [==============================] - 6s 23ms/step - loss: 2.9962 - accuracy: 0.0511 - val_loss: 2.9958 - val_accuracy: 0.0502\n",
      "Epoch 90/1000\n",
      "263/263 [==============================] - 6s 23ms/step - loss: 2.9958 - accuracy: 0.0510 - val_loss: 2.9958 - val_accuracy: 0.0515\n",
      "Epoch 91/1000\n",
      "263/263 [==============================] - 6s 23ms/step - loss: 2.9960 - accuracy: 0.0499 - val_loss: 2.9958 - val_accuracy: 0.0517\n",
      "Epoch 92/1000\n",
      "263/263 [==============================] - 6s 24ms/step - loss: 2.9964 - accuracy: 0.0507 - val_loss: 2.9958 - val_accuracy: 0.0524\n",
      "Epoch 93/1000\n",
      "263/263 [==============================] - 6s 24ms/step - loss: 2.9963 - accuracy: 0.0508 - val_loss: 2.9958 - val_accuracy: 0.0513\n",
      "Epoch 94/1000\n",
      "263/263 [==============================] - 6s 23ms/step - loss: 2.9960 - accuracy: 0.0526 - val_loss: 2.9958 - val_accuracy: 0.0494\n",
      "Epoch 95/1000\n",
      "263/263 [==============================] - 6s 24ms/step - loss: 2.9960 - accuracy: 0.0507 - val_loss: 2.9956 - val_accuracy: 0.0511\n",
      "Epoch 96/1000\n",
      "263/263 [==============================] - 6s 23ms/step - loss: 2.9965 - accuracy: 0.0487 - val_loss: 2.9957 - val_accuracy: 0.0500\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([Bidirectional(LSTM(128, dropout=.2, return_sequences=True), input_shape=(32, 20)),\n",
    "                    Bidirectional(LSTM(128, dropout=.2, return_sequences=True)),\n",
    "                    Bidirectional(LSTM(128, dropout=.2, return_sequences=True)),\n",
    "                    Bidirectional(LSTM(128, dropout=.2, return_sequences=True)),\n",
    "                    Bidirectional(LSTM(128, dropout=.2)),\n",
    "                    Dropout(.2),\n",
    "                    Dense(128, activation='sigmoid'),\n",
    "                    Dropout(.2),\n",
    "                    # Dense(128, activation='sigmoid'),\n",
    "                    # Dropout(.2),\n",
    "                    Dense(20, activation='softmax')])\n",
    "train(model=model,\n",
    "      patience_train=10,\n",
    "      patience_val=None,\n",
    "      learning_rate=.00001,\n",
    "      epochs=1000,\n",
    "      batch_size=128,\n",
    "      # cont_train=True,\n",
    "      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "F4vk6YZLbOYA",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 145105,
     "status": "error",
     "timestamp": 1688903356951,
     "user": {
      "displayName": "Yoni Krichevsky",
      "userId": "07735752940575548299"
     },
     "user_tz": -180
    },
    "id": "F4vk6YZLbOYA",
    "outputId": "a1c681f4-b131-4171-bb5d-5cdb337aaa3a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patience_train=10, patience_val=None, learning_rate=1e-05, epochs=1000, batch_size=128, cont_train=False, X_train.shape=(33566, 32, 20), y_train.shape=(33566,), X_val.shape=(4619, 32, 20), y_val.shape=(4619,)\n",
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bidirectional_9 (Bidirectio  (None, 32, 256)          152576    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " bidirectional_10 (Bidirecti  (None, 32, 256)          394240    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " bidirectional_11 (Bidirecti  (None, 256)              394240    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_40 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_41 (Dense)            (None, 20)                2580      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 976,532\n",
      "Trainable params: 976,532\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Input shape (None, 32, 20), output shape (None, 20)\n",
      "Epoch 1/1000\n",
      "263/263 [==============================] - 16s 23ms/step - loss: 3.0462 - accuracy: 0.0498 - val_loss: 2.9991 - val_accuracy: 0.0511\n",
      "Epoch 2/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9974 - accuracy: 0.0495 - val_loss: 2.9959 - val_accuracy: 0.0528\n",
      "Epoch 3/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9962 - accuracy: 0.0508 - val_loss: 2.9962 - val_accuracy: 0.0524\n",
      "Epoch 4/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9961 - accuracy: 0.0502 - val_loss: 2.9961 - val_accuracy: 0.0541\n",
      "Epoch 5/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9961 - accuracy: 0.0494 - val_loss: 2.9960 - val_accuracy: 0.0559\n",
      "Epoch 6/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9959 - accuracy: 0.0531 - val_loss: 2.9961 - val_accuracy: 0.0526\n",
      "Epoch 7/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9959 - accuracy: 0.0505 - val_loss: 2.9958 - val_accuracy: 0.0537\n",
      "Epoch 8/1000\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 2.9959 - accuracy: 0.0508 - val_loss: 2.9959 - val_accuracy: 0.0543\n",
      "Epoch 9/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9958 - accuracy: 0.0515 - val_loss: 2.9959 - val_accuracy: 0.0559\n",
      "Epoch 10/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9958 - accuracy: 0.0526 - val_loss: 2.9960 - val_accuracy: 0.0576\n",
      "Epoch 11/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9958 - accuracy: 0.0513 - val_loss: 2.9963 - val_accuracy: 0.0504\n",
      "Epoch 12/1000\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 2.9958 - accuracy: 0.0525 - val_loss: 2.9962 - val_accuracy: 0.0546\n",
      "Epoch 13/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9956 - accuracy: 0.0502 - val_loss: 2.9962 - val_accuracy: 0.0535\n",
      "Epoch 14/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9956 - accuracy: 0.0546 - val_loss: 2.9961 - val_accuracy: 0.0561\n",
      "Epoch 15/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9955 - accuracy: 0.0532 - val_loss: 2.9962 - val_accuracy: 0.0517\n",
      "Epoch 16/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9956 - accuracy: 0.0535 - val_loss: 2.9963 - val_accuracy: 0.0533\n",
      "Epoch 17/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9954 - accuracy: 0.0542 - val_loss: 2.9964 - val_accuracy: 0.0559\n",
      "Epoch 18/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9953 - accuracy: 0.0520 - val_loss: 2.9965 - val_accuracy: 0.0496\n",
      "Epoch 19/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9953 - accuracy: 0.0534 - val_loss: 2.9965 - val_accuracy: 0.0515\n",
      "Epoch 20/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9952 - accuracy: 0.0529 - val_loss: 2.9967 - val_accuracy: 0.0483\n",
      "Epoch 21/1000\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 2.9952 - accuracy: 0.0533 - val_loss: 2.9965 - val_accuracy: 0.0528\n",
      "Epoch 22/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9952 - accuracy: 0.0541 - val_loss: 2.9967 - val_accuracy: 0.0546\n",
      "Epoch 23/1000\n",
      "263/263 [==============================] - 4s 16ms/step - loss: 2.9952 - accuracy: 0.0544 - val_loss: 2.9966 - val_accuracy: 0.0541\n",
      "Epoch 24/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9952 - accuracy: 0.0537 - val_loss: 2.9967 - val_accuracy: 0.0530\n",
      "Epoch 25/1000\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 2.9951 - accuracy: 0.0529 - val_loss: 2.9969 - val_accuracy: 0.0533\n",
      "Epoch 26/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9951 - accuracy: 0.0554 - val_loss: 2.9969 - val_accuracy: 0.0513\n",
      "Epoch 27/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9949 - accuracy: 0.0540 - val_loss: 2.9968 - val_accuracy: 0.0578\n",
      "Epoch 28/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9949 - accuracy: 0.0543 - val_loss: 2.9968 - val_accuracy: 0.0569\n",
      "Epoch 29/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9949 - accuracy: 0.0542 - val_loss: 2.9974 - val_accuracy: 0.0502\n",
      "Epoch 30/1000\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 2.9949 - accuracy: 0.0538 - val_loss: 2.9976 - val_accuracy: 0.0522\n",
      "Epoch 31/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9949 - accuracy: 0.0551 - val_loss: 2.9970 - val_accuracy: 0.0507\n",
      "Epoch 32/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9949 - accuracy: 0.0546 - val_loss: 2.9968 - val_accuracy: 0.0530\n",
      "Epoch 33/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9948 - accuracy: 0.0537 - val_loss: 2.9969 - val_accuracy: 0.0502\n",
      "Epoch 34/1000\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 2.9948 - accuracy: 0.0545 - val_loss: 2.9972 - val_accuracy: 0.0509\n",
      "Epoch 35/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9948 - accuracy: 0.0538 - val_loss: 2.9972 - val_accuracy: 0.0504\n",
      "Epoch 36/1000\n",
      "263/263 [==============================] - 4s 16ms/step - loss: 2.9946 - accuracy: 0.0556 - val_loss: 2.9970 - val_accuracy: 0.0591\n",
      "Epoch 37/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9947 - accuracy: 0.0548 - val_loss: 2.9974 - val_accuracy: 0.0500\n",
      "Epoch 38/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9946 - accuracy: 0.0547 - val_loss: 2.9972 - val_accuracy: 0.0537\n",
      "Epoch 39/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9946 - accuracy: 0.0554 - val_loss: 2.9971 - val_accuracy: 0.0485\n",
      "Epoch 40/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9945 - accuracy: 0.0534 - val_loss: 2.9973 - val_accuracy: 0.0526\n",
      "Epoch 41/1000\n",
      "263/263 [==============================] - 4s 16ms/step - loss: 2.9944 - accuracy: 0.0533 - val_loss: 2.9973 - val_accuracy: 0.0509\n",
      "Epoch 42/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9945 - accuracy: 0.0548 - val_loss: 2.9975 - val_accuracy: 0.0522\n",
      "Epoch 43/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9945 - accuracy: 0.0544 - val_loss: 2.9973 - val_accuracy: 0.0533\n",
      "Epoch 44/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9944 - accuracy: 0.0543 - val_loss: 2.9974 - val_accuracy: 0.0487\n",
      "Epoch 45/1000\n",
      "263/263 [==============================] - 4s 16ms/step - loss: 2.9945 - accuracy: 0.0550 - val_loss: 2.9978 - val_accuracy: 0.0478\n",
      "Epoch 46/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9945 - accuracy: 0.0539 - val_loss: 2.9972 - val_accuracy: 0.0498\n",
      "Epoch 47/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9944 - accuracy: 0.0538 - val_loss: 2.9973 - val_accuracy: 0.0520\n",
      "Epoch 48/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9943 - accuracy: 0.0540 - val_loss: 2.9974 - val_accuracy: 0.0537\n",
      "Epoch 49/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9942 - accuracy: 0.0561 - val_loss: 2.9973 - val_accuracy: 0.0511\n",
      "Epoch 50/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9943 - accuracy: 0.0557 - val_loss: 2.9978 - val_accuracy: 0.0515\n",
      "Epoch 51/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9942 - accuracy: 0.0557 - val_loss: 2.9976 - val_accuracy: 0.0481\n",
      "Epoch 52/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9942 - accuracy: 0.0541 - val_loss: 2.9974 - val_accuracy: 0.0507\n",
      "Epoch 53/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9941 - accuracy: 0.0567 - val_loss: 2.9971 - val_accuracy: 0.0535\n",
      "Epoch 54/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9940 - accuracy: 0.0555 - val_loss: 2.9978 - val_accuracy: 0.0500\n",
      "Epoch 55/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9941 - accuracy: 0.0549 - val_loss: 2.9977 - val_accuracy: 0.0524\n",
      "Epoch 56/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9940 - accuracy: 0.0569 - val_loss: 2.9977 - val_accuracy: 0.0481\n",
      "Epoch 57/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9939 - accuracy: 0.0541 - val_loss: 2.9976 - val_accuracy: 0.0533\n",
      "Epoch 58/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9939 - accuracy: 0.0562 - val_loss: 2.9977 - val_accuracy: 0.0494\n",
      "Epoch 59/1000\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 2.9938 - accuracy: 0.0562 - val_loss: 2.9974 - val_accuracy: 0.0520\n",
      "Epoch 60/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9939 - accuracy: 0.0550 - val_loss: 2.9976 - val_accuracy: 0.0489\n",
      "Epoch 61/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9938 - accuracy: 0.0557 - val_loss: 2.9972 - val_accuracy: 0.0524\n",
      "Epoch 62/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9937 - accuracy: 0.0564 - val_loss: 2.9975 - val_accuracy: 0.0511\n",
      "Epoch 63/1000\n",
      "263/263 [==============================] - 4s 16ms/step - loss: 2.9940 - accuracy: 0.0544 - val_loss: 2.9975 - val_accuracy: 0.0537\n",
      "Epoch 64/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9937 - accuracy: 0.0542 - val_loss: 2.9976 - val_accuracy: 0.0470\n",
      "Epoch 65/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9935 - accuracy: 0.0551 - val_loss: 2.9982 - val_accuracy: 0.0507\n",
      "Epoch 66/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9937 - accuracy: 0.0562 - val_loss: 2.9978 - val_accuracy: 0.0489\n",
      "Epoch 67/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9936 - accuracy: 0.0551 - val_loss: 2.9977 - val_accuracy: 0.0478\n",
      "Epoch 68/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9935 - accuracy: 0.0548 - val_loss: 2.9980 - val_accuracy: 0.0485\n",
      "Epoch 69/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9935 - accuracy: 0.0561 - val_loss: 2.9981 - val_accuracy: 0.0450\n",
      "Epoch 70/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9936 - accuracy: 0.0541 - val_loss: 2.9980 - val_accuracy: 0.0472\n",
      "Epoch 71/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9935 - accuracy: 0.0550 - val_loss: 2.9978 - val_accuracy: 0.0496\n",
      "Epoch 72/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9935 - accuracy: 0.0555 - val_loss: 2.9977 - val_accuracy: 0.0509\n",
      "Epoch 73/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9935 - accuracy: 0.0565 - val_loss: 2.9982 - val_accuracy: 0.0465\n",
      "Epoch 74/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9934 - accuracy: 0.0570 - val_loss: 2.9980 - val_accuracy: 0.0489\n",
      "Epoch 75/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9933 - accuracy: 0.0568 - val_loss: 2.9985 - val_accuracy: 0.0448\n",
      "Epoch 76/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9932 - accuracy: 0.0572 - val_loss: 2.9985 - val_accuracy: 0.0509\n",
      "Epoch 77/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9933 - accuracy: 0.0563 - val_loss: 2.9983 - val_accuracy: 0.0433\n",
      "Epoch 78/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9932 - accuracy: 0.0561 - val_loss: 2.9983 - val_accuracy: 0.0470\n",
      "Epoch 79/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9932 - accuracy: 0.0551 - val_loss: 2.9983 - val_accuracy: 0.0450\n",
      "Epoch 80/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9932 - accuracy: 0.0559 - val_loss: 2.9987 - val_accuracy: 0.0450\n",
      "Epoch 81/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9931 - accuracy: 0.0556 - val_loss: 2.9985 - val_accuracy: 0.0461\n",
      "Epoch 82/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9930 - accuracy: 0.0558 - val_loss: 2.9983 - val_accuracy: 0.0468\n",
      "Epoch 83/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9931 - accuracy: 0.0570 - val_loss: 2.9984 - val_accuracy: 0.0481\n",
      "Epoch 84/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9929 - accuracy: 0.0566 - val_loss: 2.9987 - val_accuracy: 0.0476\n",
      "Epoch 85/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9930 - accuracy: 0.0565 - val_loss: 2.9985 - val_accuracy: 0.0474\n",
      "Epoch 86/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9930 - accuracy: 0.0570 - val_loss: 2.9982 - val_accuracy: 0.0509\n",
      "Epoch 87/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9929 - accuracy: 0.0579 - val_loss: 2.9985 - val_accuracy: 0.0483\n",
      "Epoch 88/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9928 - accuracy: 0.0577 - val_loss: 2.9983 - val_accuracy: 0.0474\n",
      "Epoch 89/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9926 - accuracy: 0.0578 - val_loss: 2.9988 - val_accuracy: 0.0446\n",
      "Epoch 90/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9927 - accuracy: 0.0558 - val_loss: 2.9985 - val_accuracy: 0.0457\n",
      "Epoch 91/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9926 - accuracy: 0.0566 - val_loss: 2.9985 - val_accuracy: 0.0468\n",
      "Epoch 92/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9927 - accuracy: 0.0581 - val_loss: 2.9990 - val_accuracy: 0.0478\n",
      "Epoch 93/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9926 - accuracy: 0.0562 - val_loss: 2.9991 - val_accuracy: 0.0457\n",
      "Epoch 94/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9925 - accuracy: 0.0578 - val_loss: 2.9988 - val_accuracy: 0.0485\n",
      "Epoch 95/1000\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 2.9925 - accuracy: 0.0566 - val_loss: 2.9990 - val_accuracy: 0.0485\n",
      "Epoch 96/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9924 - accuracy: 0.0572 - val_loss: 2.9993 - val_accuracy: 0.0491\n",
      "Epoch 97/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9924 - accuracy: 0.0576 - val_loss: 2.9993 - val_accuracy: 0.0474\n",
      "Epoch 98/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9922 - accuracy: 0.0583 - val_loss: 2.9992 - val_accuracy: 0.0442\n",
      "Epoch 99/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9924 - accuracy: 0.0581 - val_loss: 2.9993 - val_accuracy: 0.0463\n",
      "Epoch 100/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9923 - accuracy: 0.0564 - val_loss: 2.9993 - val_accuracy: 0.0424\n",
      "Epoch 101/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9920 - accuracy: 0.0574 - val_loss: 2.9996 - val_accuracy: 0.0446\n",
      "Epoch 102/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9921 - accuracy: 0.0581 - val_loss: 2.9994 - val_accuracy: 0.0500\n",
      "Epoch 103/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9922 - accuracy: 0.0584 - val_loss: 2.9992 - val_accuracy: 0.0437\n",
      "Epoch 104/1000\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 2.9918 - accuracy: 0.0586 - val_loss: 3.0000 - val_accuracy: 0.0452\n",
      "Epoch 105/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9919 - accuracy: 0.0574 - val_loss: 2.9996 - val_accuracy: 0.0426\n",
      "Epoch 106/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9918 - accuracy: 0.0589 - val_loss: 2.9995 - val_accuracy: 0.0411\n",
      "Epoch 107/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9918 - accuracy: 0.0577 - val_loss: 2.9999 - val_accuracy: 0.0439\n",
      "Epoch 108/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9915 - accuracy: 0.0587 - val_loss: 2.9996 - val_accuracy: 0.0446\n",
      "Epoch 109/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9916 - accuracy: 0.0583 - val_loss: 2.9998 - val_accuracy: 0.0461\n",
      "Epoch 110/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9914 - accuracy: 0.0588 - val_loss: 3.0002 - val_accuracy: 0.0459\n",
      "Epoch 111/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9912 - accuracy: 0.0584 - val_loss: 2.9999 - val_accuracy: 0.0459\n",
      "Epoch 112/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9912 - accuracy: 0.0597 - val_loss: 2.9998 - val_accuracy: 0.0452\n",
      "Epoch 113/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9913 - accuracy: 0.0587 - val_loss: 3.0003 - val_accuracy: 0.0472\n",
      "Epoch 114/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9911 - accuracy: 0.0586 - val_loss: 3.0004 - val_accuracy: 0.0472\n",
      "Epoch 115/1000\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 2.9910 - accuracy: 0.0571 - val_loss: 3.0002 - val_accuracy: 0.0420\n",
      "Epoch 116/1000\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 2.9909 - accuracy: 0.0605 - val_loss: 3.0007 - val_accuracy: 0.0431\n",
      "Epoch 117/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9908 - accuracy: 0.0601 - val_loss: 3.0007 - val_accuracy: 0.0461\n",
      "Epoch 118/1000\n",
      "263/263 [==============================] - 4s 16ms/step - loss: 2.9908 - accuracy: 0.0578 - val_loss: 3.0007 - val_accuracy: 0.0476\n",
      "Epoch 119/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9905 - accuracy: 0.0604 - val_loss: 3.0010 - val_accuracy: 0.0485\n",
      "Epoch 120/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9907 - accuracy: 0.0601 - val_loss: 3.0011 - val_accuracy: 0.0452\n",
      "Epoch 121/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9904 - accuracy: 0.0597 - val_loss: 3.0009 - val_accuracy: 0.0450\n",
      "Epoch 122/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9903 - accuracy: 0.0608 - val_loss: 3.0012 - val_accuracy: 0.0448\n",
      "Epoch 123/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9901 - accuracy: 0.0594 - val_loss: 3.0012 - val_accuracy: 0.0463\n",
      "Epoch 124/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9901 - accuracy: 0.0609 - val_loss: 3.0016 - val_accuracy: 0.0418\n",
      "Epoch 125/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9901 - accuracy: 0.0612 - val_loss: 3.0016 - val_accuracy: 0.0448\n",
      "Epoch 126/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9898 - accuracy: 0.0614 - val_loss: 3.0018 - val_accuracy: 0.0461\n",
      "Epoch 127/1000\n",
      "263/263 [==============================] - 4s 16ms/step - loss: 2.9897 - accuracy: 0.0603 - val_loss: 3.0013 - val_accuracy: 0.0457\n",
      "Epoch 128/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9895 - accuracy: 0.0607 - val_loss: 3.0018 - val_accuracy: 0.0448\n",
      "Epoch 129/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9894 - accuracy: 0.0621 - val_loss: 3.0014 - val_accuracy: 0.0517\n",
      "Epoch 130/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9893 - accuracy: 0.0610 - val_loss: 3.0018 - val_accuracy: 0.0483\n",
      "Epoch 131/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9893 - accuracy: 0.0608 - val_loss: 3.0018 - val_accuracy: 0.0429\n",
      "Epoch 132/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9889 - accuracy: 0.0610 - val_loss: 3.0020 - val_accuracy: 0.0481\n",
      "Epoch 133/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9888 - accuracy: 0.0618 - val_loss: 3.0024 - val_accuracy: 0.0442\n",
      "Epoch 134/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9887 - accuracy: 0.0620 - val_loss: 3.0025 - val_accuracy: 0.0442\n",
      "Epoch 135/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9883 - accuracy: 0.0642 - val_loss: 3.0026 - val_accuracy: 0.0455\n",
      "Epoch 136/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9883 - accuracy: 0.0620 - val_loss: 3.0029 - val_accuracy: 0.0439\n",
      "Epoch 137/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9882 - accuracy: 0.0624 - val_loss: 3.0030 - val_accuracy: 0.0433\n",
      "Epoch 138/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9878 - accuracy: 0.0630 - val_loss: 3.0039 - val_accuracy: 0.0461\n",
      "Epoch 139/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9879 - accuracy: 0.0630 - val_loss: 3.0032 - val_accuracy: 0.0507\n",
      "Epoch 140/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9874 - accuracy: 0.0642 - val_loss: 3.0030 - val_accuracy: 0.0459\n",
      "Epoch 141/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9876 - accuracy: 0.0635 - val_loss: 3.0035 - val_accuracy: 0.0496\n",
      "Epoch 142/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9875 - accuracy: 0.0647 - val_loss: 3.0035 - val_accuracy: 0.0448\n",
      "Epoch 143/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9871 - accuracy: 0.0634 - val_loss: 3.0035 - val_accuracy: 0.0472\n",
      "Epoch 144/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9868 - accuracy: 0.0640 - val_loss: 3.0036 - val_accuracy: 0.0494\n",
      "Epoch 145/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9867 - accuracy: 0.0641 - val_loss: 3.0041 - val_accuracy: 0.0442\n",
      "Epoch 146/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9865 - accuracy: 0.0640 - val_loss: 3.0040 - val_accuracy: 0.0455\n",
      "Epoch 147/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9867 - accuracy: 0.0658 - val_loss: 3.0041 - val_accuracy: 0.0498\n",
      "Epoch 148/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9861 - accuracy: 0.0645 - val_loss: 3.0045 - val_accuracy: 0.0476\n",
      "Epoch 149/1000\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 2.9859 - accuracy: 0.0645 - val_loss: 3.0043 - val_accuracy: 0.0461\n",
      "Epoch 150/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9859 - accuracy: 0.0644 - val_loss: 3.0046 - val_accuracy: 0.0468\n",
      "Epoch 151/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9851 - accuracy: 0.0653 - val_loss: 3.0048 - val_accuracy: 0.0491\n",
      "Epoch 152/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9852 - accuracy: 0.0658 - val_loss: 3.0054 - val_accuracy: 0.0496\n",
      "Epoch 153/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9848 - accuracy: 0.0674 - val_loss: 3.0053 - val_accuracy: 0.0496\n",
      "Epoch 154/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9847 - accuracy: 0.0673 - val_loss: 3.0050 - val_accuracy: 0.0455\n",
      "Epoch 155/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9846 - accuracy: 0.0665 - val_loss: 3.0053 - val_accuracy: 0.0502\n",
      "Epoch 156/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9843 - accuracy: 0.0668 - val_loss: 3.0057 - val_accuracy: 0.0524\n",
      "Epoch 157/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9837 - accuracy: 0.0672 - val_loss: 3.0055 - val_accuracy: 0.0476\n",
      "Epoch 158/1000\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 2.9840 - accuracy: 0.0665 - val_loss: 3.0058 - val_accuracy: 0.0459\n",
      "Epoch 159/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9833 - accuracy: 0.0678 - val_loss: 3.0067 - val_accuracy: 0.0513\n",
      "Epoch 160/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9836 - accuracy: 0.0683 - val_loss: 3.0071 - val_accuracy: 0.0504\n",
      "Epoch 161/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9828 - accuracy: 0.0702 - val_loss: 3.0061 - val_accuracy: 0.0459\n",
      "Epoch 162/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9828 - accuracy: 0.0681 - val_loss: 3.0066 - val_accuracy: 0.0478\n",
      "Epoch 163/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9821 - accuracy: 0.0671 - val_loss: 3.0072 - val_accuracy: 0.0463\n",
      "Epoch 164/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9819 - accuracy: 0.0703 - val_loss: 3.0072 - val_accuracy: 0.0481\n",
      "Epoch 165/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9816 - accuracy: 0.0693 - val_loss: 3.0076 - val_accuracy: 0.0511\n",
      "Epoch 166/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9813 - accuracy: 0.0702 - val_loss: 3.0090 - val_accuracy: 0.0481\n",
      "Epoch 167/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9814 - accuracy: 0.0700 - val_loss: 3.0078 - val_accuracy: 0.0513\n",
      "Epoch 168/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9809 - accuracy: 0.0688 - val_loss: 3.0086 - val_accuracy: 0.0496\n",
      "Epoch 169/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9804 - accuracy: 0.0705 - val_loss: 3.0093 - val_accuracy: 0.0498\n",
      "Epoch 170/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9799 - accuracy: 0.0712 - val_loss: 3.0083 - val_accuracy: 0.0468\n",
      "Epoch 171/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9797 - accuracy: 0.0707 - val_loss: 3.0088 - val_accuracy: 0.0474\n",
      "Epoch 172/1000\n",
      "263/263 [==============================] - 4s 16ms/step - loss: 2.9790 - accuracy: 0.0723 - val_loss: 3.0096 - val_accuracy: 0.0481\n",
      "Epoch 173/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9787 - accuracy: 0.0714 - val_loss: 3.0092 - val_accuracy: 0.0496\n",
      "Epoch 174/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9781 - accuracy: 0.0731 - val_loss: 3.0102 - val_accuracy: 0.0485\n",
      "Epoch 175/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9780 - accuracy: 0.0726 - val_loss: 3.0104 - val_accuracy: 0.0452\n",
      "Epoch 176/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9775 - accuracy: 0.0731 - val_loss: 3.0108 - val_accuracy: 0.0483\n",
      "Epoch 177/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9775 - accuracy: 0.0722 - val_loss: 3.0105 - val_accuracy: 0.0481\n",
      "Epoch 178/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9768 - accuracy: 0.0738 - val_loss: 3.0110 - val_accuracy: 0.0509\n",
      "Epoch 179/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9765 - accuracy: 0.0729 - val_loss: 3.0110 - val_accuracy: 0.0450\n",
      "Epoch 180/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9756 - accuracy: 0.0723 - val_loss: 3.0110 - val_accuracy: 0.0487\n",
      "Epoch 181/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9756 - accuracy: 0.0755 - val_loss: 3.0112 - val_accuracy: 0.0472\n",
      "Epoch 182/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9750 - accuracy: 0.0729 - val_loss: 3.0122 - val_accuracy: 0.0468\n",
      "Epoch 183/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9746 - accuracy: 0.0754 - val_loss: 3.0110 - val_accuracy: 0.0478\n",
      "Epoch 184/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9745 - accuracy: 0.0739 - val_loss: 3.0122 - val_accuracy: 0.0474\n",
      "Epoch 185/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9737 - accuracy: 0.0741 - val_loss: 3.0125 - val_accuracy: 0.0452\n",
      "Epoch 186/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9729 - accuracy: 0.0761 - val_loss: 3.0139 - val_accuracy: 0.0476\n",
      "Epoch 187/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9727 - accuracy: 0.0755 - val_loss: 3.0133 - val_accuracy: 0.0452\n",
      "Epoch 188/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9719 - accuracy: 0.0767 - val_loss: 3.0138 - val_accuracy: 0.0485\n",
      "Epoch 189/1000\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 2.9722 - accuracy: 0.0760 - val_loss: 3.0145 - val_accuracy: 0.0455\n",
      "Epoch 190/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9712 - accuracy: 0.0773 - val_loss: 3.0159 - val_accuracy: 0.0496\n",
      "Epoch 191/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9708 - accuracy: 0.0765 - val_loss: 3.0149 - val_accuracy: 0.0461\n",
      "Epoch 192/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9706 - accuracy: 0.0770 - val_loss: 3.0155 - val_accuracy: 0.0457\n",
      "Epoch 193/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9698 - accuracy: 0.0794 - val_loss: 3.0153 - val_accuracy: 0.0472\n",
      "Epoch 194/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9694 - accuracy: 0.0775 - val_loss: 3.0150 - val_accuracy: 0.0470\n",
      "Epoch 195/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9683 - accuracy: 0.0798 - val_loss: 3.0154 - val_accuracy: 0.0520\n",
      "Epoch 196/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9682 - accuracy: 0.0796 - val_loss: 3.0162 - val_accuracy: 0.0487\n",
      "Epoch 197/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9674 - accuracy: 0.0788 - val_loss: 3.0165 - val_accuracy: 0.0444\n",
      "Epoch 198/1000\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 2.9668 - accuracy: 0.0800 - val_loss: 3.0165 - val_accuracy: 0.0457\n",
      "Epoch 199/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9668 - accuracy: 0.0797 - val_loss: 3.0171 - val_accuracy: 0.0483\n",
      "Epoch 200/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9660 - accuracy: 0.0797 - val_loss: 3.0168 - val_accuracy: 0.0489\n",
      "Epoch 201/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9655 - accuracy: 0.0800 - val_loss: 3.0186 - val_accuracy: 0.0491\n",
      "Epoch 202/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9646 - accuracy: 0.0809 - val_loss: 3.0186 - val_accuracy: 0.0474\n",
      "Epoch 203/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9646 - accuracy: 0.0807 - val_loss: 3.0193 - val_accuracy: 0.0465\n",
      "Epoch 204/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9641 - accuracy: 0.0803 - val_loss: 3.0197 - val_accuracy: 0.0463\n",
      "Epoch 205/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9633 - accuracy: 0.0828 - val_loss: 3.0196 - val_accuracy: 0.0476\n",
      "Epoch 206/1000\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 2.9628 - accuracy: 0.0818 - val_loss: 3.0189 - val_accuracy: 0.0448\n",
      "Epoch 207/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9625 - accuracy: 0.0822 - val_loss: 3.0196 - val_accuracy: 0.0459\n",
      "Epoch 208/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9617 - accuracy: 0.0815 - val_loss: 3.0196 - val_accuracy: 0.0457\n",
      "Epoch 209/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9610 - accuracy: 0.0833 - val_loss: 3.0186 - val_accuracy: 0.0487\n",
      "Epoch 210/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9601 - accuracy: 0.0847 - val_loss: 3.0190 - val_accuracy: 0.0481\n",
      "Epoch 211/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9592 - accuracy: 0.0852 - val_loss: 3.0210 - val_accuracy: 0.0507\n",
      "Epoch 212/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9594 - accuracy: 0.0829 - val_loss: 3.0202 - val_accuracy: 0.0494\n",
      "Epoch 213/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9588 - accuracy: 0.0836 - val_loss: 3.0206 - val_accuracy: 0.0496\n",
      "Epoch 214/1000\n",
      "263/263 [==============================] - 4s 16ms/step - loss: 2.9580 - accuracy: 0.0862 - val_loss: 3.0217 - val_accuracy: 0.0448\n",
      "Epoch 215/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9568 - accuracy: 0.0857 - val_loss: 3.0226 - val_accuracy: 0.0489\n",
      "Epoch 216/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9564 - accuracy: 0.0858 - val_loss: 3.0227 - val_accuracy: 0.0474\n",
      "Epoch 217/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9563 - accuracy: 0.0865 - val_loss: 3.0218 - val_accuracy: 0.0450\n",
      "Epoch 218/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9546 - accuracy: 0.0876 - val_loss: 3.0225 - val_accuracy: 0.0426\n",
      "Epoch 219/1000\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 2.9548 - accuracy: 0.0857 - val_loss: 3.0229 - val_accuracy: 0.0485\n",
      "Epoch 220/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9544 - accuracy: 0.0873 - val_loss: 3.0212 - val_accuracy: 0.0489\n",
      "Epoch 221/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9536 - accuracy: 0.0890 - val_loss: 3.0239 - val_accuracy: 0.0487\n",
      "Epoch 222/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9528 - accuracy: 0.0886 - val_loss: 3.0240 - val_accuracy: 0.0478\n",
      "Epoch 223/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9530 - accuracy: 0.0870 - val_loss: 3.0250 - val_accuracy: 0.0472\n",
      "Epoch 224/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9509 - accuracy: 0.0906 - val_loss: 3.0241 - val_accuracy: 0.0489\n",
      "Epoch 225/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9506 - accuracy: 0.0880 - val_loss: 3.0256 - val_accuracy: 0.0457\n",
      "Epoch 226/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9500 - accuracy: 0.0889 - val_loss: 3.0255 - val_accuracy: 0.0485\n",
      "Epoch 227/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9496 - accuracy: 0.0910 - val_loss: 3.0247 - val_accuracy: 0.0483\n",
      "Epoch 228/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9490 - accuracy: 0.0890 - val_loss: 3.0257 - val_accuracy: 0.0442\n",
      "Epoch 229/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9482 - accuracy: 0.0901 - val_loss: 3.0260 - val_accuracy: 0.0446\n",
      "Epoch 230/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9478 - accuracy: 0.0906 - val_loss: 3.0243 - val_accuracy: 0.0489\n",
      "Epoch 231/1000\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 2.9467 - accuracy: 0.0905 - val_loss: 3.0268 - val_accuracy: 0.0483\n",
      "Epoch 232/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9464 - accuracy: 0.0904 - val_loss: 3.0276 - val_accuracy: 0.0465\n",
      "Epoch 233/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9456 - accuracy: 0.0912 - val_loss: 3.0257 - val_accuracy: 0.0465\n",
      "Epoch 234/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9455 - accuracy: 0.0915 - val_loss: 3.0266 - val_accuracy: 0.0474\n",
      "Epoch 235/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9444 - accuracy: 0.0942 - val_loss: 3.0263 - val_accuracy: 0.0498\n",
      "Epoch 236/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9436 - accuracy: 0.0939 - val_loss: 3.0271 - val_accuracy: 0.0478\n",
      "Epoch 237/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9432 - accuracy: 0.0960 - val_loss: 3.0264 - val_accuracy: 0.0463\n",
      "Epoch 238/1000\n",
      " 33/263 [==>...........................] - ETA: 3s - loss: 2.9405 - accuracy: 0.0888"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-967ef02ff628>\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m                     \u001b[0;31m# Dropout(.2),\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m                     Dense(20, activation='softmax')])\n\u001b[0;32m---> 12\u001b[0;31m train(model=model,\n\u001b[0m\u001b[1;32m     13\u001b[0m       \u001b[0mpatience_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m       \u001b[0mpatience_val\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-22-3272e0f9fb9b>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, patience_train, patience_val, learning_rate, X_train, y_train, X_val, y_val, epochs, batch_size, cont_train)\u001b[0m\n\u001b[1;32m     13\u001b[0m                   \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sparse_categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                   metrics=['accuracy'])\n\u001b[0;32m---> 15\u001b[0;31m   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mearly_stopping\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1683\u001b[0m                         ):\n\u001b[1;32m   1684\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1685\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1686\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1687\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 894\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    895\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    924\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 926\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    927\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    141\u001b[0m       (concrete_function,\n\u001b[1;32m    142\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m--> 143\u001b[0;31m     return concrete_function._call_flat(\n\u001b[0m\u001b[1;32m    144\u001b[0m         filtered_flat_args, captured_inputs=concrete_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1755\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1756\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1757\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1758\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1759\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    379\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    382\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     53\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = Sequential([Bidirectional(LSTM(128, return_sequences=True), input_shape=(32, 20)),\n",
    "                    Bidirectional(LSTM(128, return_sequences=True)),\n",
    "                    # Bidirectional(LSTM(128, return_sequences=True)),\n",
    "                    # Bidirectional(LSTM(128, return_sequences=True)),\n",
    "                    Bidirectional(LSTM(128, dropout=.2)),\n",
    "                    # Dropout(.2),\n",
    "                    Dense(128, activation='sigmoid'),\n",
    "                    # Dropout(.2),\n",
    "                    # Dense(128, activation='sigmoid'),\n",
    "                    # Dropout(.2),\n",
    "                    Dense(20, activation='softmax')])\n",
    "train(model=model,\n",
    "      patience_train=10,\n",
    "      patience_val=None,\n",
    "      learning_rate=.00001,\n",
    "      epochs=1000,\n",
    "      batch_size=128,\n",
    "      # cont_train=True,\n",
    "      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "Upj5JhqdfCyk",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 120594,
     "status": "error",
     "timestamp": 1688903510024,
     "user": {
      "displayName": "Yoni Krichevsky",
      "userId": "07735752940575548299"
     },
     "user_tz": -180
    },
    "id": "Upj5JhqdfCyk",
    "outputId": "550f7ba6-3ddd-468c-95a7-0def086137e3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patience_train=10, patience_val=None, learning_rate=1e-05, epochs=1000, batch_size=128, cont_train=False, X_train.shape=(33566, 32, 20), y_train.shape=(33566,), X_val.shape=(4619, 32, 20), y_val.shape=(4619,)\n",
      "Model: \"sequential_20\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bidirectional_12 (Bidirecti  (None, 32, 256)          152576    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " bidirectional_13 (Bidirecti  (None, 32, 256)          394240    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " bidirectional_14 (Bidirecti  (None, 256)              394240    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dropout_19 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_42 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_20 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_43 (Dense)            (None, 20)                2580      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 976,532\n",
      "Trainable params: 976,532\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Input shape (None, 32, 20), output shape (None, 20)\n",
      "Epoch 1/1000\n",
      "263/263 [==============================] - 16s 23ms/step - loss: 3.1081 - accuracy: 0.0502 - val_loss: 3.0071 - val_accuracy: 0.0517\n",
      "Epoch 2/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 3.0490 - accuracy: 0.0490 - val_loss: 2.9966 - val_accuracy: 0.0530\n",
      "Epoch 3/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 3.0402 - accuracy: 0.0485 - val_loss: 2.9967 - val_accuracy: 0.0468\n",
      "Epoch 4/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 3.0350 - accuracy: 0.0498 - val_loss: 2.9964 - val_accuracy: 0.0524\n",
      "Epoch 5/1000\n",
      "263/263 [==============================] - 4s 16ms/step - loss: 3.0323 - accuracy: 0.0512 - val_loss: 2.9962 - val_accuracy: 0.0494\n",
      "Epoch 6/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 3.0306 - accuracy: 0.0492 - val_loss: 2.9964 - val_accuracy: 0.0494\n",
      "Epoch 7/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 3.0282 - accuracy: 0.0484 - val_loss: 2.9967 - val_accuracy: 0.0522\n",
      "Epoch 8/1000\n",
      "263/263 [==============================] - 4s 16ms/step - loss: 3.0254 - accuracy: 0.0509 - val_loss: 2.9966 - val_accuracy: 0.0513\n",
      "Epoch 9/1000\n",
      "263/263 [==============================] - 4s 16ms/step - loss: 3.0227 - accuracy: 0.0510 - val_loss: 2.9963 - val_accuracy: 0.0546\n",
      "Epoch 10/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 3.0235 - accuracy: 0.0492 - val_loss: 2.9965 - val_accuracy: 0.0496\n",
      "Epoch 11/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 3.0225 - accuracy: 0.0492 - val_loss: 2.9965 - val_accuracy: 0.0526\n",
      "Epoch 12/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 3.0174 - accuracy: 0.0503 - val_loss: 2.9961 - val_accuracy: 0.0526\n",
      "Epoch 13/1000\n",
      "263/263 [==============================] - 4s 16ms/step - loss: 3.0184 - accuracy: 0.0515 - val_loss: 2.9961 - val_accuracy: 0.0528\n",
      "Epoch 14/1000\n",
      "263/263 [==============================] - 4s 16ms/step - loss: 3.0151 - accuracy: 0.0498 - val_loss: 2.9962 - val_accuracy: 0.0533\n",
      "Epoch 15/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 3.0165 - accuracy: 0.0500 - val_loss: 2.9962 - val_accuracy: 0.0535\n",
      "Epoch 16/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 3.0145 - accuracy: 0.0494 - val_loss: 2.9963 - val_accuracy: 0.0504\n",
      "Epoch 17/1000\n",
      "263/263 [==============================] - 4s 16ms/step - loss: 3.0120 - accuracy: 0.0508 - val_loss: 2.9960 - val_accuracy: 0.0528\n",
      "Epoch 18/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 3.0113 - accuracy: 0.0504 - val_loss: 2.9960 - val_accuracy: 0.0511\n",
      "Epoch 19/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 3.0114 - accuracy: 0.0484 - val_loss: 2.9960 - val_accuracy: 0.0517\n",
      "Epoch 20/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 3.0104 - accuracy: 0.0509 - val_loss: 2.9960 - val_accuracy: 0.0517\n",
      "Epoch 21/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 3.0088 - accuracy: 0.0501 - val_loss: 2.9959 - val_accuracy: 0.0520\n",
      "Epoch 22/1000\n",
      "263/263 [==============================] - 4s 16ms/step - loss: 3.0092 - accuracy: 0.0484 - val_loss: 2.9961 - val_accuracy: 0.0530\n",
      "Epoch 23/1000\n",
      "263/263 [==============================] - 4s 16ms/step - loss: 3.0067 - accuracy: 0.0520 - val_loss: 2.9960 - val_accuracy: 0.0520\n",
      "Epoch 24/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 3.0071 - accuracy: 0.0517 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 25/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 3.0059 - accuracy: 0.0521 - val_loss: 2.9960 - val_accuracy: 0.0515\n",
      "Epoch 26/1000\n",
      "263/263 [==============================] - 4s 16ms/step - loss: 3.0057 - accuracy: 0.0504 - val_loss: 2.9959 - val_accuracy: 0.0578\n",
      "Epoch 27/1000\n",
      " 77/263 [=======>......................] - ETA: 2s - loss: 3.0014 - accuracy: 0.0523"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-66a83766cec0>\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m                     \u001b[0;31m# Dropout(.2),\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m                     Dense(20, activation='softmax')])\n\u001b[0;32m---> 12\u001b[0;31m train(model=model,\n\u001b[0m\u001b[1;32m     13\u001b[0m       \u001b[0mpatience_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m       \u001b[0mpatience_val\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-22-3272e0f9fb9b>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, patience_train, patience_val, learning_rate, X_train, y_train, X_val, y_val, epochs, batch_size, cont_train)\u001b[0m\n\u001b[1;32m     13\u001b[0m                   \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sparse_categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                   metrics=['accuracy'])\n\u001b[0;32m---> 15\u001b[0;31m   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mearly_stopping\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1683\u001b[0m                         ):\n\u001b[1;32m   1684\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1685\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1686\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1687\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 894\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    895\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    924\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 926\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    927\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    141\u001b[0m       (concrete_function,\n\u001b[1;32m    142\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m--> 143\u001b[0;31m     return concrete_function._call_flat(\n\u001b[0m\u001b[1;32m    144\u001b[0m         filtered_flat_args, captured_inputs=concrete_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1755\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1756\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1757\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1758\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1759\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    379\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    382\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     53\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = Sequential([Bidirectional(LSTM(128, dropout=.2, return_sequences=True), input_shape=(32, 20)),\n",
    "                    Bidirectional(LSTM(128, dropout=.2, return_sequences=True)),\n",
    "                    # Bidirectional(LSTM(128, return_sequences=True)),\n",
    "                    # Bidirectional(LSTM(128, return_sequences=True)),\n",
    "                    Bidirectional(LSTM(128, dropout=.2)),\n",
    "                    Dropout(.2),\n",
    "                    Dense(128, activation='sigmoid'),\n",
    "                    Dropout(.2),\n",
    "                    # Dense(128, activation='sigmoid'),\n",
    "                    # Dropout(.2),\n",
    "                    Dense(20, activation='softmax')])\n",
    "train(model=model,\n",
    "      patience_train=10,\n",
    "      patience_val=None,\n",
    "      learning_rate=.00001,\n",
    "      epochs=1000,\n",
    "      batch_size=128,\n",
    "      # cont_train=True,\n",
    "      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "E_aXugOFfoUN",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 108909,
     "status": "ok",
     "timestamp": 1688903739861,
     "user": {
      "displayName": "Yoni Krichevsky",
      "userId": "07735752940575548299"
     },
     "user_tz": -180
    },
    "id": "E_aXugOFfoUN",
    "outputId": "194d71e6-2930-4c47-ddb7-289f7dfd0b67"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patience_train=10, patience_val=None, learning_rate=0.001, epochs=1000, batch_size=128, cont_train=False, X_train.shape=(33566, 32, 20), y_train.shape=(33566,), X_val.shape=(4619, 32, 20), y_val.shape=(4619,)\n",
      "Model: \"sequential_20\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bidirectional_12 (Bidirecti  (None, 32, 256)          152576    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " bidirectional_13 (Bidirecti  (None, 32, 256)          394240    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " bidirectional_14 (Bidirecti  (None, 256)              394240    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dropout_19 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_42 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_20 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_43 (Dense)            (None, 20)                2580      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 976,532\n",
      "Trainable params: 976,532\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Input shape (None, 32, 20), output shape (None, 20)\n",
      "Epoch 1/1000\n",
      "263/263 [==============================] - 15s 23ms/step - loss: 3.0005 - accuracy: 0.0506 - val_loss: 2.9956 - val_accuracy: 0.0565\n",
      "Epoch 2/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9962 - accuracy: 0.0495 - val_loss: 2.9966 - val_accuracy: 0.0465\n",
      "Epoch 3/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9961 - accuracy: 0.0501 - val_loss: 2.9958 - val_accuracy: 0.0522\n",
      "Epoch 4/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9959 - accuracy: 0.0495 - val_loss: 2.9957 - val_accuracy: 0.0522\n",
      "Epoch 5/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9957 - accuracy: 0.0503 - val_loss: 2.9959 - val_accuracy: 0.0522\n",
      "Epoch 6/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9958 - accuracy: 0.0500 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 7/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9958 - accuracy: 0.0503 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 8/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9957 - accuracy: 0.0499 - val_loss: 2.9959 - val_accuracy: 0.0465\n",
      "Epoch 9/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9958 - accuracy: 0.0500 - val_loss: 2.9959 - val_accuracy: 0.0522\n",
      "Epoch 10/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9957 - accuracy: 0.0509 - val_loss: 2.9959 - val_accuracy: 0.0465\n",
      "Epoch 11/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9957 - accuracy: 0.0481 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 12/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9957 - accuracy: 0.0500 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 13/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9957 - accuracy: 0.0506 - val_loss: 2.9959 - val_accuracy: 0.0522\n",
      "Epoch 14/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9957 - accuracy: 0.0498 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 15/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9957 - accuracy: 0.0512 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 16/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9957 - accuracy: 0.0498 - val_loss: 2.9959 - val_accuracy: 0.0465\n",
      "Epoch 17/1000\n",
      "263/263 [==============================] - 4s 16ms/step - loss: 2.9957 - accuracy: 0.0500 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 18/1000\n",
      "263/263 [==============================] - 4s 16ms/step - loss: 2.9957 - accuracy: 0.0511 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 19/1000\n",
      "263/263 [==============================] - 4s 16ms/step - loss: 2.9957 - accuracy: 0.0499 - val_loss: 2.9959 - val_accuracy: 0.0522\n",
      "Epoch 20/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9957 - accuracy: 0.0504 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 21/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9957 - accuracy: 0.0499 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 22/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9957 - accuracy: 0.0491 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 23/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9957 - accuracy: 0.0502 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 24/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9957 - accuracy: 0.0497 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 25/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9957 - accuracy: 0.0500 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 26/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9957 - accuracy: 0.0502 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 27/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9957 - accuracy: 0.0492 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 28/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9957 - accuracy: 0.0509 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 29/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9957 - accuracy: 0.0503 - val_loss: 2.9959 - val_accuracy: 0.0522\n",
      "Epoch 30/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9957 - accuracy: 0.0506 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 31/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9957 - accuracy: 0.0511 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 32/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9957 - accuracy: 0.0504 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 33/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9957 - accuracy: 0.0489 - val_loss: 2.9959 - val_accuracy: 0.0522\n",
      "Epoch 34/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9957 - accuracy: 0.0517 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 35/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9957 - accuracy: 0.0517 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 36/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9957 - accuracy: 0.0512 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 37/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9957 - accuracy: 0.0501 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 38/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9957 - accuracy: 0.0502 - val_loss: 2.9960 - val_accuracy: 0.0517\n",
      "Epoch 39/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9957 - accuracy: 0.0496 - val_loss: 2.9960 - val_accuracy: 0.0517\n",
      "Epoch 40/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9957 - accuracy: 0.0507 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 41/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9957 - accuracy: 0.0498 - val_loss: 2.9959 - val_accuracy: 0.0522\n",
      "Epoch 42/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9957 - accuracy: 0.0515 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 43/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9957 - accuracy: 0.0496 - val_loss: 2.9960 - val_accuracy: 0.0517\n",
      "Epoch 44/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9957 - accuracy: 0.0510 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 45/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9957 - accuracy: 0.0499 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 46/1000\n",
      "263/263 [==============================] - 4s 16ms/step - loss: 2.9957 - accuracy: 0.0506 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 47/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9957 - accuracy: 0.0513 - val_loss: 2.9960 - val_accuracy: 0.0517\n",
      "Epoch 48/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9957 - accuracy: 0.0504 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 49/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9957 - accuracy: 0.0509 - val_loss: 2.9960 - val_accuracy: 0.0517\n",
      "Epoch 50/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9957 - accuracy: 0.0497 - val_loss: 2.9960 - val_accuracy: 0.0517\n",
      "Epoch 51/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9957 - accuracy: 0.0492 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 52/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9957 - accuracy: 0.0510 - val_loss: 2.9959 - val_accuracy: 0.0517\n"
     ]
    }
   ],
   "source": [
    "train(model=model,\n",
    "      patience_train=10,\n",
    "      patience_val=None,\n",
    "      learning_rate=.001,\n",
    "      epochs=1000,\n",
    "      batch_size=128,\n",
    "      # cont_train=True,\n",
    "      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "Du2o1AnagpiV",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 119328,
     "status": "ok",
     "timestamp": 1688903908843,
     "user": {
      "displayName": "Yoni Krichevsky",
      "userId": "07735752940575548299"
     },
     "user_tz": -180
    },
    "id": "Du2o1AnagpiV",
    "outputId": "d7a21bd6-ecae-4835-efdc-e800a6038f6f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patience_train=10, patience_val=None, learning_rate=0.0001, epochs=1000, batch_size=128, cont_train=False, X_train.shape=(33566, 32, 20), y_train.shape=(33566,), X_val.shape=(4619, 32, 20), y_val.shape=(4619,)\n",
      "Model: \"sequential_20\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bidirectional_12 (Bidirecti  (None, 32, 256)          152576    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " bidirectional_13 (Bidirecti  (None, 32, 256)          394240    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " bidirectional_14 (Bidirecti  (None, 256)              394240    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dropout_19 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_42 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_20 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_43 (Dense)            (None, 20)                2580      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 976,532\n",
      "Trainable params: 976,532\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Input shape (None, 32, 20), output shape (None, 20)\n",
      "Epoch 1/1000\n",
      "263/263 [==============================] - 16s 22ms/step - loss: 2.9956 - accuracy: 0.0517 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 2/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9955 - accuracy: 0.0517 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 3/1000\n",
      "263/263 [==============================] - 4s 16ms/step - loss: 2.9955 - accuracy: 0.0517 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 4/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9955 - accuracy: 0.0517 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 5/1000\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 2.9955 - accuracy: 0.0517 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 6/1000\n",
      "263/263 [==============================] - 4s 16ms/step - loss: 2.9955 - accuracy: 0.0517 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 7/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9955 - accuracy: 0.0517 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 8/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9955 - accuracy: 0.0517 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 9/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9955 - accuracy: 0.0517 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 10/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9955 - accuracy: 0.0517 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 11/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9955 - accuracy: 0.0517 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 12/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9955 - accuracy: 0.0517 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 13/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9955 - accuracy: 0.0517 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 14/1000\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 2.9955 - accuracy: 0.0517 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 15/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9955 - accuracy: 0.0517 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 16/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9955 - accuracy: 0.0517 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 17/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9955 - accuracy: 0.0517 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 18/1000\n",
      "263/263 [==============================] - 4s 16ms/step - loss: 2.9955 - accuracy: 0.0517 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 19/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9955 - accuracy: 0.0517 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 20/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9955 - accuracy: 0.0517 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 21/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9955 - accuracy: 0.0517 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 22/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9955 - accuracy: 0.0517 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 23/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9955 - accuracy: 0.0517 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 24/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9955 - accuracy: 0.0517 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 25/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9955 - accuracy: 0.0517 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 26/1000\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 2.9955 - accuracy: 0.0517 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 27/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9955 - accuracy: 0.0517 - val_loss: 2.9959 - val_accuracy: 0.0517\n"
     ]
    }
   ],
   "source": [
    "train(model=model,\n",
    "      patience_train=10,\n",
    "      patience_val=None,\n",
    "      learning_rate=.0001,\n",
    "      epochs=1000,\n",
    "      batch_size=128,\n",
    "      # cont_train=True,\n",
    "      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "NyxpSp8Wg8v8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 478986,
     "status": "ok",
     "timestamp": 1688904399546,
     "user": {
      "displayName": "Yoni Krichevsky",
      "userId": "07735752940575548299"
     },
     "user_tz": -180
    },
    "id": "NyxpSp8Wg8v8",
    "outputId": "b329fa90-5b0a-413c-aad3-2ad36521cfb0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patience_train=10, patience_val=None, learning_rate=1e-05, epochs=1000, batch_size=128, cont_train=False, X_train.shape=(33566, 32, 20), y_train.shape=(33566,), X_val.shape=(4619, 32, 20), y_val.shape=(4619,)\n",
      "Model: \"sequential_21\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bidirectional_15 (Bidirecti  (None, 32, 256)          152576    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " bidirectional_16 (Bidirecti  (None, 32, 256)          394240    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " bidirectional_17 (Bidirecti  (None, 256)              394240    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dropout_21 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_44 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_22 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_45 (Dense)            (None, 20)                2580      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 976,532\n",
      "Trainable params: 976,532\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Input shape (None, 32, 20), output shape (None, 20)\n",
      "Epoch 1/1000\n",
      "263/263 [==============================] - 16s 22ms/step - loss: 3.1359 - accuracy: 0.0489 - val_loss: 3.0184 - val_accuracy: 0.0509\n",
      "Epoch 2/1000\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 3.0251 - accuracy: 0.0490 - val_loss: 2.9966 - val_accuracy: 0.0489\n",
      "Epoch 3/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 3.0150 - accuracy: 0.0503 - val_loss: 2.9960 - val_accuracy: 0.0513\n",
      "Epoch 4/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 3.0161 - accuracy: 0.0483 - val_loss: 2.9958 - val_accuracy: 0.0522\n",
      "Epoch 5/1000\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 3.0144 - accuracy: 0.0504 - val_loss: 2.9960 - val_accuracy: 0.0461\n",
      "Epoch 6/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 3.0128 - accuracy: 0.0496 - val_loss: 2.9958 - val_accuracy: 0.0517\n",
      "Epoch 7/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 3.0111 - accuracy: 0.0505 - val_loss: 2.9958 - val_accuracy: 0.0511\n",
      "Epoch 8/1000\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 3.0118 - accuracy: 0.0504 - val_loss: 2.9958 - val_accuracy: 0.0509\n",
      "Epoch 9/1000\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 3.0093 - accuracy: 0.0519 - val_loss: 2.9958 - val_accuracy: 0.0517\n",
      "Epoch 10/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 3.0111 - accuracy: 0.0480 - val_loss: 2.9958 - val_accuracy: 0.0524\n",
      "Epoch 11/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 3.0099 - accuracy: 0.0486 - val_loss: 2.9958 - val_accuracy: 0.0517\n",
      "Epoch 12/1000\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 3.0091 - accuracy: 0.0493 - val_loss: 2.9958 - val_accuracy: 0.0524\n",
      "Epoch 13/1000\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 3.0099 - accuracy: 0.0502 - val_loss: 2.9958 - val_accuracy: 0.0520\n",
      "Epoch 14/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 3.0107 - accuracy: 0.0497 - val_loss: 2.9957 - val_accuracy: 0.0509\n",
      "Epoch 15/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 3.0060 - accuracy: 0.0504 - val_loss: 2.9957 - val_accuracy: 0.0530\n",
      "Epoch 16/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 3.0062 - accuracy: 0.0510 - val_loss: 2.9961 - val_accuracy: 0.0476\n",
      "Epoch 17/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 3.0063 - accuracy: 0.0505 - val_loss: 2.9959 - val_accuracy: 0.0500\n",
      "Epoch 18/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 3.0064 - accuracy: 0.0498 - val_loss: 2.9958 - val_accuracy: 0.0498\n",
      "Epoch 19/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 3.0050 - accuracy: 0.0529 - val_loss: 2.9958 - val_accuracy: 0.0537\n",
      "Epoch 20/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 3.0054 - accuracy: 0.0491 - val_loss: 2.9960 - val_accuracy: 0.0502\n",
      "Epoch 21/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 3.0057 - accuracy: 0.0507 - val_loss: 2.9961 - val_accuracy: 0.0504\n",
      "Epoch 22/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 3.0052 - accuracy: 0.0524 - val_loss: 2.9960 - val_accuracy: 0.0543\n",
      "Epoch 23/1000\n",
      "263/263 [==============================] - 4s 16ms/step - loss: 3.0035 - accuracy: 0.0518 - val_loss: 2.9959 - val_accuracy: 0.0526\n",
      "Epoch 24/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 3.0045 - accuracy: 0.0510 - val_loss: 2.9961 - val_accuracy: 0.0515\n",
      "Epoch 25/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 3.0042 - accuracy: 0.0494 - val_loss: 2.9958 - val_accuracy: 0.0528\n",
      "Epoch 26/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 3.0038 - accuracy: 0.0503 - val_loss: 2.9960 - val_accuracy: 0.0502\n",
      "Epoch 27/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 3.0033 - accuracy: 0.0502 - val_loss: 2.9961 - val_accuracy: 0.0496\n",
      "Epoch 28/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 3.0038 - accuracy: 0.0469 - val_loss: 2.9960 - val_accuracy: 0.0517\n",
      "Epoch 29/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 3.0030 - accuracy: 0.0486 - val_loss: 2.9960 - val_accuracy: 0.0491\n",
      "Epoch 30/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 3.0021 - accuracy: 0.0516 - val_loss: 2.9957 - val_accuracy: 0.0513\n",
      "Epoch 31/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 3.0025 - accuracy: 0.0486 - val_loss: 2.9960 - val_accuracy: 0.0528\n",
      "Epoch 32/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 3.0015 - accuracy: 0.0509 - val_loss: 2.9962 - val_accuracy: 0.0498\n",
      "Epoch 33/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 3.0018 - accuracy: 0.0492 - val_loss: 2.9961 - val_accuracy: 0.0502\n",
      "Epoch 34/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 3.0027 - accuracy: 0.0491 - val_loss: 2.9961 - val_accuracy: 0.0517\n",
      "Epoch 35/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 3.0020 - accuracy: 0.0497 - val_loss: 2.9961 - val_accuracy: 0.0496\n",
      "Epoch 36/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 3.0017 - accuracy: 0.0489 - val_loss: 2.9961 - val_accuracy: 0.0522\n",
      "Epoch 37/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 3.0010 - accuracy: 0.0513 - val_loss: 2.9962 - val_accuracy: 0.0511\n",
      "Epoch 38/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 3.0012 - accuracy: 0.0506 - val_loss: 2.9963 - val_accuracy: 0.0504\n",
      "Epoch 39/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 3.0004 - accuracy: 0.0523 - val_loss: 2.9961 - val_accuracy: 0.0539\n",
      "Epoch 40/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 3.0007 - accuracy: 0.0515 - val_loss: 2.9961 - val_accuracy: 0.0511\n",
      "Epoch 41/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 3.0005 - accuracy: 0.0511 - val_loss: 2.9960 - val_accuracy: 0.0537\n",
      "Epoch 42/1000\n",
      "263/263 [==============================] - 4s 16ms/step - loss: 3.0003 - accuracy: 0.0499 - val_loss: 2.9961 - val_accuracy: 0.0556\n",
      "Epoch 43/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9997 - accuracy: 0.0497 - val_loss: 2.9962 - val_accuracy: 0.0552\n",
      "Epoch 44/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 3.0001 - accuracy: 0.0534 - val_loss: 2.9965 - val_accuracy: 0.0504\n",
      "Epoch 45/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9996 - accuracy: 0.0509 - val_loss: 2.9962 - val_accuracy: 0.0533\n",
      "Epoch 46/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 3.0000 - accuracy: 0.0515 - val_loss: 2.9962 - val_accuracy: 0.0539\n",
      "Epoch 47/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 3.0000 - accuracy: 0.0495 - val_loss: 2.9962 - val_accuracy: 0.0524\n",
      "Epoch 48/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 3.0005 - accuracy: 0.0503 - val_loss: 2.9963 - val_accuracy: 0.0524\n",
      "Epoch 49/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9993 - accuracy: 0.0488 - val_loss: 2.9964 - val_accuracy: 0.0543\n",
      "Epoch 50/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9996 - accuracy: 0.0489 - val_loss: 2.9962 - val_accuracy: 0.0539\n",
      "Epoch 51/1000\n",
      "263/263 [==============================] - 4s 16ms/step - loss: 2.9982 - accuracy: 0.0525 - val_loss: 2.9965 - val_accuracy: 0.0494\n",
      "Epoch 52/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9991 - accuracy: 0.0512 - val_loss: 2.9967 - val_accuracy: 0.0491\n",
      "Epoch 53/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9985 - accuracy: 0.0506 - val_loss: 2.9963 - val_accuracy: 0.0515\n",
      "Epoch 54/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9992 - accuracy: 0.0512 - val_loss: 2.9966 - val_accuracy: 0.0489\n",
      "Epoch 55/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9985 - accuracy: 0.0514 - val_loss: 2.9963 - val_accuracy: 0.0517\n",
      "Epoch 56/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9987 - accuracy: 0.0504 - val_loss: 2.9965 - val_accuracy: 0.0539\n",
      "Epoch 57/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9989 - accuracy: 0.0518 - val_loss: 2.9965 - val_accuracy: 0.0569\n",
      "Epoch 58/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9978 - accuracy: 0.0495 - val_loss: 2.9965 - val_accuracy: 0.0552\n",
      "Epoch 59/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9985 - accuracy: 0.0514 - val_loss: 2.9966 - val_accuracy: 0.0515\n",
      "Epoch 60/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9976 - accuracy: 0.0533 - val_loss: 2.9969 - val_accuracy: 0.0541\n",
      "Epoch 61/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9979 - accuracy: 0.0501 - val_loss: 2.9966 - val_accuracy: 0.0556\n",
      "Epoch 62/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9977 - accuracy: 0.0534 - val_loss: 2.9966 - val_accuracy: 0.0489\n",
      "Epoch 63/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9977 - accuracy: 0.0521 - val_loss: 2.9969 - val_accuracy: 0.0543\n",
      "Epoch 64/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9980 - accuracy: 0.0525 - val_loss: 2.9970 - val_accuracy: 0.0528\n",
      "Epoch 65/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9982 - accuracy: 0.0503 - val_loss: 2.9969 - val_accuracy: 0.0535\n",
      "Epoch 66/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9971 - accuracy: 0.0517 - val_loss: 2.9966 - val_accuracy: 0.0513\n",
      "Epoch 67/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9972 - accuracy: 0.0520 - val_loss: 2.9965 - val_accuracy: 0.0552\n",
      "Epoch 68/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9977 - accuracy: 0.0535 - val_loss: 2.9967 - val_accuracy: 0.0509\n",
      "Epoch 69/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9973 - accuracy: 0.0505 - val_loss: 2.9972 - val_accuracy: 0.0511\n",
      "Epoch 70/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9973 - accuracy: 0.0507 - val_loss: 2.9969 - val_accuracy: 0.0537\n",
      "Epoch 71/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9978 - accuracy: 0.0519 - val_loss: 2.9968 - val_accuracy: 0.0509\n",
      "Epoch 72/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9969 - accuracy: 0.0546 - val_loss: 2.9965 - val_accuracy: 0.0520\n",
      "Epoch 73/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9977 - accuracy: 0.0518 - val_loss: 2.9966 - val_accuracy: 0.0548\n",
      "Epoch 74/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9971 - accuracy: 0.0528 - val_loss: 2.9966 - val_accuracy: 0.0541\n",
      "Epoch 75/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9971 - accuracy: 0.0510 - val_loss: 2.9967 - val_accuracy: 0.0548\n",
      "Epoch 76/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9968 - accuracy: 0.0543 - val_loss: 2.9967 - val_accuracy: 0.0556\n",
      "Epoch 77/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9970 - accuracy: 0.0513 - val_loss: 2.9969 - val_accuracy: 0.0526\n",
      "Epoch 78/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9967 - accuracy: 0.0524 - val_loss: 2.9970 - val_accuracy: 0.0485\n",
      "Epoch 79/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9966 - accuracy: 0.0526 - val_loss: 2.9966 - val_accuracy: 0.0543\n",
      "Epoch 80/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9973 - accuracy: 0.0509 - val_loss: 2.9970 - val_accuracy: 0.0515\n",
      "Epoch 81/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9968 - accuracy: 0.0501 - val_loss: 2.9969 - val_accuracy: 0.0541\n",
      "Epoch 82/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9968 - accuracy: 0.0518 - val_loss: 2.9971 - val_accuracy: 0.0552\n",
      "Epoch 83/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9965 - accuracy: 0.0523 - val_loss: 2.9967 - val_accuracy: 0.0543\n",
      "Epoch 84/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9964 - accuracy: 0.0517 - val_loss: 2.9966 - val_accuracy: 0.0574\n",
      "Epoch 85/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9962 - accuracy: 0.0536 - val_loss: 2.9965 - val_accuracy: 0.0563\n",
      "Epoch 86/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9968 - accuracy: 0.0521 - val_loss: 2.9966 - val_accuracy: 0.0541\n",
      "Epoch 87/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9967 - accuracy: 0.0520 - val_loss: 2.9964 - val_accuracy: 0.0585\n",
      "Epoch 88/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9963 - accuracy: 0.0519 - val_loss: 2.9969 - val_accuracy: 0.0526\n",
      "Epoch 89/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9962 - accuracy: 0.0512 - val_loss: 2.9969 - val_accuracy: 0.0546\n",
      "Epoch 90/1000\n",
      "263/263 [==============================] - 4s 16ms/step - loss: 2.9962 - accuracy: 0.0518 - val_loss: 2.9970 - val_accuracy: 0.0524\n",
      "Epoch 91/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9959 - accuracy: 0.0529 - val_loss: 2.9969 - val_accuracy: 0.0528\n",
      "Epoch 92/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9959 - accuracy: 0.0535 - val_loss: 2.9969 - val_accuracy: 0.0563\n",
      "Epoch 93/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9963 - accuracy: 0.0512 - val_loss: 2.9971 - val_accuracy: 0.0535\n",
      "Epoch 94/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9960 - accuracy: 0.0523 - val_loss: 2.9967 - val_accuracy: 0.0526\n",
      "Epoch 95/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9960 - accuracy: 0.0530 - val_loss: 2.9968 - val_accuracy: 0.0535\n",
      "Epoch 96/1000\n",
      "263/263 [==============================] - 4s 16ms/step - loss: 2.9957 - accuracy: 0.0506 - val_loss: 2.9969 - val_accuracy: 0.0554\n",
      "Epoch 97/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9960 - accuracy: 0.0521 - val_loss: 2.9972 - val_accuracy: 0.0520\n",
      "Epoch 98/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9957 - accuracy: 0.0528 - val_loss: 2.9969 - val_accuracy: 0.0524\n",
      "Epoch 99/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9955 - accuracy: 0.0529 - val_loss: 2.9967 - val_accuracy: 0.0541\n",
      "Epoch 100/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9961 - accuracy: 0.0532 - val_loss: 2.9969 - val_accuracy: 0.0533\n",
      "Epoch 101/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9965 - accuracy: 0.0521 - val_loss: 2.9971 - val_accuracy: 0.0541\n",
      "Epoch 102/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9963 - accuracy: 0.0525 - val_loss: 2.9969 - val_accuracy: 0.0552\n",
      "Epoch 103/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9954 - accuracy: 0.0541 - val_loss: 2.9967 - val_accuracy: 0.0520\n",
      "Epoch 104/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9956 - accuracy: 0.0526 - val_loss: 2.9967 - val_accuracy: 0.0552\n",
      "Epoch 105/1000\n",
      "263/263 [==============================] - 4s 16ms/step - loss: 2.9955 - accuracy: 0.0526 - val_loss: 2.9969 - val_accuracy: 0.0569\n",
      "Epoch 106/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9955 - accuracy: 0.0504 - val_loss: 2.9967 - val_accuracy: 0.0565\n",
      "Epoch 107/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9957 - accuracy: 0.0520 - val_loss: 2.9968 - val_accuracy: 0.0526\n",
      "Epoch 108/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9948 - accuracy: 0.0523 - val_loss: 2.9969 - val_accuracy: 0.0546\n",
      "Epoch 109/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9955 - accuracy: 0.0525 - val_loss: 2.9969 - val_accuracy: 0.0563\n",
      "Epoch 110/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9958 - accuracy: 0.0520 - val_loss: 2.9968 - val_accuracy: 0.0552\n",
      "Epoch 111/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9952 - accuracy: 0.0512 - val_loss: 2.9969 - val_accuracy: 0.0556\n",
      "Epoch 112/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9954 - accuracy: 0.0519 - val_loss: 2.9970 - val_accuracy: 0.0541\n",
      "Epoch 113/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9954 - accuracy: 0.0513 - val_loss: 2.9968 - val_accuracy: 0.0561\n",
      "Epoch 114/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9962 - accuracy: 0.0502 - val_loss: 2.9969 - val_accuracy: 0.0552\n",
      "Epoch 115/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9951 - accuracy: 0.0536 - val_loss: 2.9970 - val_accuracy: 0.0513\n",
      "Epoch 116/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9955 - accuracy: 0.0522 - val_loss: 2.9970 - val_accuracy: 0.0502\n",
      "Epoch 117/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9957 - accuracy: 0.0506 - val_loss: 2.9970 - val_accuracy: 0.0554\n",
      "Epoch 118/1000\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.9951 - accuracy: 0.0510 - val_loss: 2.9970 - val_accuracy: 0.0572\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([Bidirectional(LSTM(128, dropout=.1, return_sequences=True), input_shape=(32, 20)),\n",
    "                    Bidirectional(LSTM(128, dropout=.1, return_sequences=True)),\n",
    "                    # Bidirectional(LSTM(128, return_sequences=True)),\n",
    "                    # Bidirectional(LSTM(128, return_sequences=True)),\n",
    "                    Bidirectional(LSTM(128, dropout=.1)),\n",
    "                    Dropout(.1),\n",
    "                    Dense(128, activation='sigmoid'),\n",
    "                    Dropout(.1),\n",
    "                    # Dense(128, activation='sigmoid'),\n",
    "                    # Dropout(.2),\n",
    "                    Dense(20, activation='softmax')])\n",
    "train(model=model,\n",
    "      patience_train=10,\n",
    "      patience_val=None,\n",
    "      learning_rate=.00001,\n",
    "      epochs=1000,\n",
    "      batch_size=128,\n",
    "      # cont_train=True,\n",
    "      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0lreE2Cijz8-",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 22612,
     "status": "ok",
     "timestamp": 1688904780198,
     "user": {
      "displayName": "Yoni Krichevsky",
      "userId": "07735752940575548299"
     },
     "user_tz": -180
    },
    "id": "0lreE2Cijz8-",
    "outputId": "d8e7a21c-1947-4bc2-a6ef-1adf250e90f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patience_train=10, patience_val=None, learning_rate=1e-06, epochs=1000, batch_size=64, cont_train=False, X_train.shape=(33566, 32, 20), y_train.shape=(33566,), X_val.shape=(4619, 32, 20), y_val.shape=(4619,)\n",
      "Model: \"sequential_21\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bidirectional_15 (Bidirecti  (None, 32, 256)          152576    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " bidirectional_16 (Bidirecti  (None, 32, 256)          394240    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " bidirectional_17 (Bidirecti  (None, 256)              394240    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dropout_21 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_44 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_22 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_45 (Dense)            (None, 20)                2580      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 976,532\n",
      "Trainable params: 976,532\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Input shape (None, 32, 20), output shape (None, 20)\n",
      "Epoch 1/1000\n",
      "525/525 [==============================] - 20s 20ms/step - loss: 2.9951 - accuracy: 0.0517 - val_loss: 2.9970 - val_accuracy: 0.0572\n",
      "Epoch 2/1000\n",
      "525/525 [==============================] - 8s 15ms/step - loss: 2.9950 - accuracy: 0.0545 - val_loss: 2.9971 - val_accuracy: 0.0580\n",
      "Epoch 3/1000\n",
      "525/525 [==============================] - 8s 14ms/step - loss: 2.9950 - accuracy: 0.0542 - val_loss: 2.9971 - val_accuracy: 0.0585\n",
      "Epoch 4/1000\n",
      "525/525 [==============================] - 8s 15ms/step - loss: 2.9951 - accuracy: 0.0509 - val_loss: 2.9970 - val_accuracy: 0.0580\n",
      "Epoch 5/1000\n",
      "525/525 [==============================] - 8s 15ms/step - loss: 2.9947 - accuracy: 0.0531 - val_loss: 2.9971 - val_accuracy: 0.0576\n",
      "Epoch 6/1000\n",
      "525/525 [==============================] - 8s 15ms/step - loss: 2.9950 - accuracy: 0.0528 - val_loss: 2.9971 - val_accuracy: 0.0561\n",
      "Epoch 7/1000\n",
      "525/525 [==============================] - 8s 15ms/step - loss: 2.9948 - accuracy: 0.0545 - val_loss: 2.9971 - val_accuracy: 0.0554\n",
      "Epoch 8/1000\n",
      "525/525 [==============================] - 8s 15ms/step - loss: 2.9946 - accuracy: 0.0542 - val_loss: 2.9971 - val_accuracy: 0.0569\n",
      "Epoch 9/1000\n",
      "525/525 [==============================] - 8s 15ms/step - loss: 2.9947 - accuracy: 0.0530 - val_loss: 2.9971 - val_accuracy: 0.0554\n",
      "Epoch 10/1000\n",
      "525/525 [==============================] - 8s 15ms/step - loss: 2.9948 - accuracy: 0.0547 - val_loss: 2.9971 - val_accuracy: 0.0561\n",
      "Epoch 11/1000\n",
      "525/525 [==============================] - 8s 15ms/step - loss: 2.9949 - accuracy: 0.0529 - val_loss: 2.9971 - val_accuracy: 0.0554\n",
      "Epoch 12/1000\n",
      "525/525 [==============================] - 8s 15ms/step - loss: 2.9947 - accuracy: 0.0544 - val_loss: 2.9971 - val_accuracy: 0.0563\n",
      "Epoch 13/1000\n",
      "525/525 [==============================] - 8s 15ms/step - loss: 2.9950 - accuracy: 0.0551 - val_loss: 2.9970 - val_accuracy: 0.0559\n",
      "Epoch 14/1000\n",
      "525/525 [==============================] - 8s 15ms/step - loss: 2.9948 - accuracy: 0.0554 - val_loss: 2.9970 - val_accuracy: 0.0556\n",
      "Epoch 15/1000\n",
      "525/525 [==============================] - 8s 15ms/step - loss: 2.9947 - accuracy: 0.0550 - val_loss: 2.9971 - val_accuracy: 0.0550\n",
      "Epoch 16/1000\n",
      "525/525 [==============================] - 8s 15ms/step - loss: 2.9948 - accuracy: 0.0543 - val_loss: 2.9971 - val_accuracy: 0.0556\n",
      "Epoch 17/1000\n",
      "525/525 [==============================] - 8s 15ms/step - loss: 2.9949 - accuracy: 0.0537 - val_loss: 2.9971 - val_accuracy: 0.0552\n",
      "Epoch 18/1000\n",
      "525/525 [==============================] - 8s 15ms/step - loss: 2.9948 - accuracy: 0.0527 - val_loss: 2.9971 - val_accuracy: 0.0567\n"
     ]
    }
   ],
   "source": [
    "train(model=model,\n",
    "      patience_train=10,\n",
    "      patience_val=None,\n",
    "      learning_rate=.000001,\n",
    "      epochs=1000,\n",
    "      batch_size=64,\n",
    "      # cont_train=True,\n",
    "      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "R5lAXweRr6DJ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12839,
     "status": "ok",
     "timestamp": 1688909466583,
     "user": {
      "displayName": "Yoni Krichevsky",
      "userId": "07735752940575548299"
     },
     "user_tz": -180
    },
    "id": "R5lAXweRr6DJ",
    "outputId": "23cbcb20-22b3-49f4-efa2-fc15501e27b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patience_train=10, patience_val=None, learning_rate=1e-05, epochs=1000, batch_size=32, cont_train=False, X_train.shape=(33566, 32, 20), y_train.shape=(33566,), X_val.shape=(4619, 32, 20), y_val.shape=(4619,)\n",
      "Model: \"sequential_21\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bidirectional_15 (Bidirecti  (None, 32, 256)          152576    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " bidirectional_16 (Bidirecti  (None, 32, 256)          394240    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " bidirectional_17 (Bidirecti  (None, 256)              394240    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dropout_21 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_44 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_22 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_45 (Dense)            (None, 20)                2580      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 976,532\n",
      "Trainable params: 976,532\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Input shape (None, 32, 20), output shape (None, 20)\n",
      "Epoch 1/1000\n",
      "1049/1049 [==============================] - 27s 17ms/step - loss: 2.9949 - accuracy: 0.0532 - val_loss: 2.9970 - val_accuracy: 0.0504\n",
      "Epoch 2/1000\n",
      "1049/1049 [==============================] - 16s 15ms/step - loss: 2.9954 - accuracy: 0.0517 - val_loss: 2.9972 - val_accuracy: 0.0546\n",
      "Epoch 3/1000\n",
      "1049/1049 [==============================] - 16s 15ms/step - loss: 2.9948 - accuracy: 0.0535 - val_loss: 2.9971 - val_accuracy: 0.0537\n",
      "Epoch 4/1000\n",
      "1049/1049 [==============================] - 16s 15ms/step - loss: 2.9949 - accuracy: 0.0541 - val_loss: 2.9972 - val_accuracy: 0.0546\n",
      "Epoch 5/1000\n",
      "1049/1049 [==============================] - 15s 15ms/step - loss: 2.9953 - accuracy: 0.0522 - val_loss: 2.9971 - val_accuracy: 0.0548\n",
      "Epoch 6/1000\n",
      "1049/1049 [==============================] - 15s 14ms/step - loss: 2.9949 - accuracy: 0.0522 - val_loss: 2.9968 - val_accuracy: 0.0537\n",
      "Epoch 7/1000\n",
      "1049/1049 [==============================] - 15s 14ms/step - loss: 2.9956 - accuracy: 0.0515 - val_loss: 2.9971 - val_accuracy: 0.0494\n",
      "Epoch 8/1000\n",
      "1049/1049 [==============================] - 15s 14ms/step - loss: 2.9951 - accuracy: 0.0527 - val_loss: 2.9969 - val_accuracy: 0.0565\n",
      "Epoch 9/1000\n",
      "1049/1049 [==============================] - 15s 14ms/step - loss: 2.9953 - accuracy: 0.0529 - val_loss: 2.9970 - val_accuracy: 0.0522\n",
      "Epoch 10/1000\n",
      "1049/1049 [==============================] - 15s 14ms/step - loss: 2.9948 - accuracy: 0.0540 - val_loss: 2.9970 - val_accuracy: 0.0539\n",
      "Epoch 11/1000\n",
      "1049/1049 [==============================] - 15s 15ms/step - loss: 2.9948 - accuracy: 0.0525 - val_loss: 2.9971 - val_accuracy: 0.0546\n",
      "Epoch 12/1000\n",
      "1049/1049 [==============================] - 15s 14ms/step - loss: 2.9952 - accuracy: 0.0510 - val_loss: 2.9970 - val_accuracy: 0.0513\n",
      "Epoch 13/1000\n",
      "1049/1049 [==============================] - 15s 14ms/step - loss: 2.9949 - accuracy: 0.0545 - val_loss: 2.9972 - val_accuracy: 0.0507\n",
      "Epoch 14/1000\n",
      "1049/1049 [==============================] - 15s 14ms/step - loss: 2.9948 - accuracy: 0.0515 - val_loss: 2.9973 - val_accuracy: 0.0520\n",
      "Epoch 15/1000\n",
      "1049/1049 [==============================] - 15s 14ms/step - loss: 2.9948 - accuracy: 0.0528 - val_loss: 2.9970 - val_accuracy: 0.0500\n",
      "Epoch 16/1000\n",
      "1049/1049 [==============================] - 15s 14ms/step - loss: 2.9948 - accuracy: 0.0538 - val_loss: 2.9973 - val_accuracy: 0.0500\n",
      "Epoch 17/1000\n",
      "1049/1049 [==============================] - 15s 14ms/step - loss: 2.9949 - accuracy: 0.0551 - val_loss: 2.9972 - val_accuracy: 0.0474\n",
      "Epoch 18/1000\n",
      "1049/1049 [==============================] - 15s 15ms/step - loss: 2.9947 - accuracy: 0.0518 - val_loss: 2.9978 - val_accuracy: 0.0541\n",
      "Epoch 19/1000\n",
      "1049/1049 [==============================] - 15s 14ms/step - loss: 2.9950 - accuracy: 0.0517 - val_loss: 2.9972 - val_accuracy: 0.0533\n",
      "Epoch 20/1000\n",
      "1049/1049 [==============================] - 15s 14ms/step - loss: 2.9944 - accuracy: 0.0541 - val_loss: 2.9971 - val_accuracy: 0.0509\n",
      "Epoch 21/1000\n",
      "1049/1049 [==============================] - 15s 14ms/step - loss: 2.9946 - accuracy: 0.0542 - val_loss: 2.9983 - val_accuracy: 0.0528\n",
      "Epoch 22/1000\n",
      "1049/1049 [==============================] - 15s 14ms/step - loss: 2.9945 - accuracy: 0.0539 - val_loss: 2.9969 - val_accuracy: 0.0556\n",
      "Epoch 23/1000\n",
      "1049/1049 [==============================] - 15s 15ms/step - loss: 2.9944 - accuracy: 0.0553 - val_loss: 2.9972 - val_accuracy: 0.0496\n",
      "Epoch 24/1000\n",
      "1049/1049 [==============================] - 15s 14ms/step - loss: 2.9943 - accuracy: 0.0535 - val_loss: 2.9973 - val_accuracy: 0.0491\n",
      "Epoch 25/1000\n",
      "1049/1049 [==============================] - 15s 14ms/step - loss: 2.9941 - accuracy: 0.0542 - val_loss: 2.9973 - val_accuracy: 0.0533\n",
      "Epoch 26/1000\n",
      "1049/1049 [==============================] - 15s 14ms/step - loss: 2.9941 - accuracy: 0.0558 - val_loss: 2.9972 - val_accuracy: 0.0517\n",
      "Epoch 27/1000\n",
      "1049/1049 [==============================] - 15s 14ms/step - loss: 2.9942 - accuracy: 0.0552 - val_loss: 2.9972 - val_accuracy: 0.0489\n",
      "Epoch 28/1000\n",
      "1049/1049 [==============================] - 15s 14ms/step - loss: 2.9942 - accuracy: 0.0540 - val_loss: 2.9973 - val_accuracy: 0.0478\n",
      "Epoch 29/1000\n",
      "1049/1049 [==============================] - 15s 14ms/step - loss: 2.9944 - accuracy: 0.0544 - val_loss: 2.9974 - val_accuracy: 0.0513\n",
      "Epoch 30/1000\n",
      "1049/1049 [==============================] - 15s 14ms/step - loss: 2.9943 - accuracy: 0.0552 - val_loss: 2.9973 - val_accuracy: 0.0478\n",
      "Epoch 31/1000\n",
      "1049/1049 [==============================] - 15s 14ms/step - loss: 2.9940 - accuracy: 0.0533 - val_loss: 2.9975 - val_accuracy: 0.0485\n",
      "Epoch 32/1000\n",
      "1049/1049 [==============================] - 15s 14ms/step - loss: 2.9938 - accuracy: 0.0561 - val_loss: 2.9976 - val_accuracy: 0.0539\n",
      "Epoch 33/1000\n",
      "1049/1049 [==============================] - 15s 14ms/step - loss: 2.9943 - accuracy: 0.0538 - val_loss: 2.9973 - val_accuracy: 0.0541\n",
      "Epoch 34/1000\n",
      "1049/1049 [==============================] - 15s 15ms/step - loss: 2.9939 - accuracy: 0.0550 - val_loss: 2.9973 - val_accuracy: 0.0513\n",
      "Epoch 35/1000\n",
      "1049/1049 [==============================] - 15s 14ms/step - loss: 2.9935 - accuracy: 0.0560 - val_loss: 2.9974 - val_accuracy: 0.0481\n",
      "Epoch 36/1000\n",
      "1049/1049 [==============================] - 16s 15ms/step - loss: 2.9939 - accuracy: 0.0539 - val_loss: 2.9980 - val_accuracy: 0.0515\n",
      "Epoch 37/1000\n",
      "1049/1049 [==============================] - 15s 15ms/step - loss: 2.9937 - accuracy: 0.0552 - val_loss: 2.9971 - val_accuracy: 0.0530\n",
      "Epoch 38/1000\n",
      "1049/1049 [==============================] - 15s 14ms/step - loss: 2.9937 - accuracy: 0.0546 - val_loss: 2.9984 - val_accuracy: 0.0513\n",
      "Epoch 39/1000\n",
      "1049/1049 [==============================] - 15s 14ms/step - loss: 2.9936 - accuracy: 0.0559 - val_loss: 2.9976 - val_accuracy: 0.0515\n",
      "Epoch 40/1000\n",
      "1049/1049 [==============================] - 15s 14ms/step - loss: 2.9938 - accuracy: 0.0543 - val_loss: 2.9974 - val_accuracy: 0.0535\n",
      "Epoch 41/1000\n",
      "1049/1049 [==============================] - 15s 14ms/step - loss: 2.9936 - accuracy: 0.0558 - val_loss: 2.9980 - val_accuracy: 0.0517\n",
      "Epoch 42/1000\n",
      "1049/1049 [==============================] - 15s 14ms/step - loss: 2.9936 - accuracy: 0.0545 - val_loss: 2.9975 - val_accuracy: 0.0537\n",
      "Epoch 43/1000\n",
      "1049/1049 [==============================] - 15s 14ms/step - loss: 2.9934 - accuracy: 0.0564 - val_loss: 2.9974 - val_accuracy: 0.0517\n",
      "Epoch 44/1000\n",
      "1049/1049 [==============================] - 15s 14ms/step - loss: 2.9934 - accuracy: 0.0561 - val_loss: 2.9976 - val_accuracy: 0.0535\n",
      "Epoch 45/1000\n",
      "1049/1049 [==============================] - 15s 14ms/step - loss: 2.9933 - accuracy: 0.0560 - val_loss: 2.9977 - val_accuracy: 0.0524\n",
      "Epoch 46/1000\n",
      "1049/1049 [==============================] - 15s 14ms/step - loss: 2.9934 - accuracy: 0.0559 - val_loss: 2.9980 - val_accuracy: 0.0552\n",
      "Epoch 47/1000\n",
      "1049/1049 [==============================] - 15s 14ms/step - loss: 2.9934 - accuracy: 0.0546 - val_loss: 2.9973 - val_accuracy: 0.0509\n",
      "Epoch 48/1000\n",
      "1049/1049 [==============================] - 15s 14ms/step - loss: 2.9934 - accuracy: 0.0543 - val_loss: 2.9979 - val_accuracy: 0.0550\n",
      "Epoch 49/1000\n",
      "1049/1049 [==============================] - 15s 14ms/step - loss: 2.9930 - accuracy: 0.0564 - val_loss: 2.9974 - val_accuracy: 0.0517\n",
      "Epoch 50/1000\n",
      "1049/1049 [==============================] - 15s 14ms/step - loss: 2.9930 - accuracy: 0.0549 - val_loss: 2.9987 - val_accuracy: 0.0502\n",
      "Epoch 51/1000\n",
      "1049/1049 [==============================] - 15s 14ms/step - loss: 2.9934 - accuracy: 0.0562 - val_loss: 2.9972 - val_accuracy: 0.0522\n",
      "Epoch 52/1000\n",
      "1049/1049 [==============================] - 15s 14ms/step - loss: 2.9933 - accuracy: 0.0561 - val_loss: 2.9979 - val_accuracy: 0.0515\n",
      "Epoch 53/1000\n",
      "1049/1049 [==============================] - 15s 14ms/step - loss: 2.9930 - accuracy: 0.0551 - val_loss: 2.9978 - val_accuracy: 0.0530\n",
      "Epoch 54/1000\n",
      "1049/1049 [==============================] - 15s 15ms/step - loss: 2.9928 - accuracy: 0.0555 - val_loss: 2.9976 - val_accuracy: 0.0494\n",
      "Epoch 55/1000\n",
      "1049/1049 [==============================] - 15s 14ms/step - loss: 2.9927 - accuracy: 0.0547 - val_loss: 2.9977 - val_accuracy: 0.0511\n",
      "Epoch 56/1000\n",
      "1049/1049 [==============================] - 15s 14ms/step - loss: 2.9929 - accuracy: 0.0563 - val_loss: 2.9979 - val_accuracy: 0.0526\n",
      "Epoch 57/1000\n",
      "1049/1049 [==============================] - 15s 14ms/step - loss: 2.9927 - accuracy: 0.0572 - val_loss: 2.9974 - val_accuracy: 0.0509\n",
      "Epoch 58/1000\n",
      "1049/1049 [==============================] - 15s 14ms/step - loss: 2.9928 - accuracy: 0.0570 - val_loss: 2.9982 - val_accuracy: 0.0526\n",
      "Epoch 59/1000\n",
      "1049/1049 [==============================] - 16s 15ms/step - loss: 2.9926 - accuracy: 0.0532 - val_loss: 2.9982 - val_accuracy: 0.0543\n",
      "Epoch 60/1000\n",
      "1049/1049 [==============================] - 16s 15ms/step - loss: 2.9924 - accuracy: 0.0572 - val_loss: 2.9977 - val_accuracy: 0.0537\n",
      "Epoch 61/1000\n",
      "1049/1049 [==============================] - 16s 15ms/step - loss: 2.9920 - accuracy: 0.0569 - val_loss: 2.9979 - val_accuracy: 0.0517\n",
      "Epoch 62/1000\n",
      "1049/1049 [==============================] - 16s 15ms/step - loss: 2.9927 - accuracy: 0.0561 - val_loss: 2.9986 - val_accuracy: 0.0515\n",
      "Epoch 63/1000\n",
      "1049/1049 [==============================] - 16s 15ms/step - loss: 2.9923 - accuracy: 0.0555 - val_loss: 2.9980 - val_accuracy: 0.0502\n",
      "Epoch 64/1000\n",
      "1049/1049 [==============================] - 16s 15ms/step - loss: 2.9922 - accuracy: 0.0596 - val_loss: 2.9985 - val_accuracy: 0.0509\n",
      "Epoch 65/1000\n",
      "1049/1049 [==============================] - 16s 15ms/step - loss: 2.9923 - accuracy: 0.0550 - val_loss: 2.9979 - val_accuracy: 0.0496\n",
      "Epoch 66/1000\n",
      "1049/1049 [==============================] - 16s 15ms/step - loss: 2.9921 - accuracy: 0.0559 - val_loss: 2.9988 - val_accuracy: 0.0491\n",
      "Epoch 67/1000\n",
      "1049/1049 [==============================] - 16s 15ms/step - loss: 2.9923 - accuracy: 0.0580 - val_loss: 2.9980 - val_accuracy: 0.0504\n",
      "Epoch 68/1000\n",
      "1049/1049 [==============================] - 16s 15ms/step - loss: 2.9919 - accuracy: 0.0581 - val_loss: 2.9983 - val_accuracy: 0.0569\n",
      "Epoch 69/1000\n",
      "1049/1049 [==============================] - 16s 15ms/step - loss: 2.9920 - accuracy: 0.0576 - val_loss: 2.9988 - val_accuracy: 0.0535\n",
      "Epoch 70/1000\n",
      "1049/1049 [==============================] - 15s 15ms/step - loss: 2.9919 - accuracy: 0.0576 - val_loss: 2.9978 - val_accuracy: 0.0487\n",
      "Epoch 71/1000\n",
      "1049/1049 [==============================] - 15s 14ms/step - loss: 2.9919 - accuracy: 0.0568 - val_loss: 2.9977 - val_accuracy: 0.0504\n",
      "Epoch 72/1000\n",
      "1049/1049 [==============================] - 15s 15ms/step - loss: 2.9917 - accuracy: 0.0590 - val_loss: 2.9981 - val_accuracy: 0.0515\n",
      "Epoch 73/1000\n",
      "1049/1049 [==============================] - 15s 15ms/step - loss: 2.9922 - accuracy: 0.0559 - val_loss: 2.9981 - val_accuracy: 0.0476\n",
      "Epoch 74/1000\n",
      "1049/1049 [==============================] - 15s 15ms/step - loss: 2.9915 - accuracy: 0.0576 - val_loss: 2.9978 - val_accuracy: 0.0504\n",
      "Epoch 75/1000\n",
      "1049/1049 [==============================] - 16s 15ms/step - loss: 2.9917 - accuracy: 0.0567 - val_loss: 2.9983 - val_accuracy: 0.0509\n",
      "Epoch 76/1000\n",
      "1049/1049 [==============================] - 15s 14ms/step - loss: 2.9914 - accuracy: 0.0582 - val_loss: 2.9985 - val_accuracy: 0.0498\n",
      "Epoch 77/1000\n",
      "1049/1049 [==============================] - 15s 15ms/step - loss: 2.9917 - accuracy: 0.0566 - val_loss: 2.9989 - val_accuracy: 0.0513\n",
      "Epoch 78/1000\n",
      "1049/1049 [==============================] - 16s 15ms/step - loss: 2.9912 - accuracy: 0.0565 - val_loss: 2.9981 - val_accuracy: 0.0511\n",
      "Epoch 79/1000\n",
      "1049/1049 [==============================] - 15s 15ms/step - loss: 2.9915 - accuracy: 0.0570 - val_loss: 2.9989 - val_accuracy: 0.0530\n",
      "Epoch 80/1000\n",
      "1049/1049 [==============================] - 15s 14ms/step - loss: 2.9911 - accuracy: 0.0574 - val_loss: 2.9992 - val_accuracy: 0.0537\n",
      "Epoch 81/1000\n",
      "1049/1049 [==============================] - 15s 15ms/step - loss: 2.9912 - accuracy: 0.0593 - val_loss: 2.9990 - val_accuracy: 0.0517\n",
      "Epoch 82/1000\n",
      "1049/1049 [==============================] - 15s 14ms/step - loss: 2.9911 - accuracy: 0.0584 - val_loss: 2.9985 - val_accuracy: 0.0483\n",
      "Epoch 83/1000\n",
      "1049/1049 [==============================] - 15s 15ms/step - loss: 2.9907 - accuracy: 0.0574 - val_loss: 2.9982 - val_accuracy: 0.0535\n",
      "Epoch 84/1000\n",
      "1049/1049 [==============================] - 16s 15ms/step - loss: 2.9910 - accuracy: 0.0570 - val_loss: 2.9983 - val_accuracy: 0.0502\n",
      "Epoch 85/1000\n",
      "1049/1049 [==============================] - 15s 15ms/step - loss: 2.9907 - accuracy: 0.0578 - val_loss: 2.9993 - val_accuracy: 0.0500\n",
      "Epoch 86/1000\n",
      "1049/1049 [==============================] - 15s 14ms/step - loss: 2.9904 - accuracy: 0.0572 - val_loss: 2.9984 - val_accuracy: 0.0509\n",
      "Epoch 87/1000\n",
      "1049/1049 [==============================] - 16s 15ms/step - loss: 2.9905 - accuracy: 0.0575 - val_loss: 2.9994 - val_accuracy: 0.0474\n",
      "Epoch 88/1000\n",
      "1049/1049 [==============================] - 15s 15ms/step - loss: 2.9905 - accuracy: 0.0585 - val_loss: 2.9992 - val_accuracy: 0.0511\n",
      "Epoch 89/1000\n",
      "1049/1049 [==============================] - 16s 15ms/step - loss: 2.9910 - accuracy: 0.0562 - val_loss: 2.9989 - val_accuracy: 0.0507\n",
      "Epoch 90/1000\n",
      "1049/1049 [==============================] - 16s 15ms/step - loss: 2.9906 - accuracy: 0.0593 - val_loss: 2.9994 - val_accuracy: 0.0511\n",
      "Epoch 91/1000\n",
      "1049/1049 [==============================] - 16s 15ms/step - loss: 2.9902 - accuracy: 0.0583 - val_loss: 2.9986 - val_accuracy: 0.0507\n",
      "Epoch 92/1000\n",
      "1049/1049 [==============================] - 16s 15ms/step - loss: 2.9901 - accuracy: 0.0572 - val_loss: 2.9989 - val_accuracy: 0.0489\n",
      "Epoch 93/1000\n",
      "1049/1049 [==============================] - 16s 15ms/step - loss: 2.9904 - accuracy: 0.0613 - val_loss: 3.0000 - val_accuracy: 0.0528\n",
      "Epoch 94/1000\n",
      "1049/1049 [==============================] - 15s 15ms/step - loss: 2.9905 - accuracy: 0.0599 - val_loss: 3.0001 - val_accuracy: 0.0478\n",
      "Epoch 95/1000\n",
      "1049/1049 [==============================] - 16s 15ms/step - loss: 2.9900 - accuracy: 0.0597 - val_loss: 2.9994 - val_accuracy: 0.0485\n",
      "Epoch 96/1000\n",
      "1049/1049 [==============================] - 16s 15ms/step - loss: 2.9904 - accuracy: 0.0606 - val_loss: 2.9985 - val_accuracy: 0.0500\n",
      "Epoch 97/1000\n",
      "1049/1049 [==============================] - 15s 15ms/step - loss: 2.9900 - accuracy: 0.0611 - val_loss: 2.9986 - val_accuracy: 0.0530\n",
      "Epoch 98/1000\n",
      "1049/1049 [==============================] - 15s 15ms/step - loss: 2.9896 - accuracy: 0.0587 - val_loss: 2.9993 - val_accuracy: 0.0504\n",
      "Epoch 99/1000\n",
      "1049/1049 [==============================] - 16s 15ms/step - loss: 2.9902 - accuracy: 0.0590 - val_loss: 2.9995 - val_accuracy: 0.0541\n",
      "Epoch 100/1000\n",
      "1049/1049 [==============================] - 16s 15ms/step - loss: 2.9901 - accuracy: 0.0589 - val_loss: 2.9990 - val_accuracy: 0.0559\n",
      "Epoch 101/1000\n",
      "1049/1049 [==============================] - 16s 15ms/step - loss: 2.9898 - accuracy: 0.0596 - val_loss: 3.0003 - val_accuracy: 0.0476\n",
      "Epoch 102/1000\n",
      "1049/1049 [==============================] - 16s 15ms/step - loss: 2.9893 - accuracy: 0.0608 - val_loss: 3.0000 - val_accuracy: 0.0509\n",
      "Epoch 103/1000\n",
      "1049/1049 [==============================] - 16s 15ms/step - loss: 2.9897 - accuracy: 0.0583 - val_loss: 2.9998 - val_accuracy: 0.0491\n",
      "Epoch 104/1000\n",
      "1049/1049 [==============================] - 16s 15ms/step - loss: 2.9895 - accuracy: 0.0610 - val_loss: 2.9991 - val_accuracy: 0.0550\n",
      "Epoch 105/1000\n",
      "1049/1049 [==============================] - 15s 14ms/step - loss: 2.9892 - accuracy: 0.0607 - val_loss: 2.9988 - val_accuracy: 0.0511\n",
      "Epoch 106/1000\n",
      "1049/1049 [==============================] - 15s 15ms/step - loss: 2.9897 - accuracy: 0.0575 - val_loss: 2.9994 - val_accuracy: 0.0524\n",
      "Epoch 107/1000\n",
      "1049/1049 [==============================] - 16s 15ms/step - loss: 2.9890 - accuracy: 0.0592 - val_loss: 3.0001 - val_accuracy: 0.0483\n",
      "Epoch 108/1000\n",
      "1049/1049 [==============================] - 15s 15ms/step - loss: 2.9888 - accuracy: 0.0604 - val_loss: 3.0002 - val_accuracy: 0.0524\n",
      "Epoch 109/1000\n",
      "1049/1049 [==============================] - 15s 15ms/step - loss: 2.9886 - accuracy: 0.0604 - val_loss: 3.0000 - val_accuracy: 0.0515\n",
      "Epoch 110/1000\n",
      "1049/1049 [==============================] - 16s 15ms/step - loss: 2.9888 - accuracy: 0.0601 - val_loss: 2.9998 - val_accuracy: 0.0533\n",
      "Epoch 111/1000\n",
      "1049/1049 [==============================] - 15s 15ms/step - loss: 2.9888 - accuracy: 0.0599 - val_loss: 2.9992 - val_accuracy: 0.0485\n",
      "Epoch 112/1000\n",
      "1049/1049 [==============================] - 15s 15ms/step - loss: 2.9888 - accuracy: 0.0588 - val_loss: 2.9994 - val_accuracy: 0.0522\n",
      "Epoch 113/1000\n",
      "1049/1049 [==============================] - 15s 15ms/step - loss: 2.9886 - accuracy: 0.0613 - val_loss: 2.9997 - val_accuracy: 0.0507\n",
      "Epoch 114/1000\n",
      "1049/1049 [==============================] - 16s 15ms/step - loss: 2.9888 - accuracy: 0.0607 - val_loss: 2.9996 - val_accuracy: 0.0526\n",
      "Epoch 115/1000\n",
      "1049/1049 [==============================] - 15s 15ms/step - loss: 2.9880 - accuracy: 0.0606 - val_loss: 3.0010 - val_accuracy: 0.0515\n",
      "Epoch 116/1000\n",
      "1049/1049 [==============================] - 15s 15ms/step - loss: 2.9877 - accuracy: 0.0616 - val_loss: 3.0002 - val_accuracy: 0.0511\n",
      "Epoch 117/1000\n",
      "1049/1049 [==============================] - 15s 14ms/step - loss: 2.9879 - accuracy: 0.0598 - val_loss: 3.0004 - val_accuracy: 0.0537\n",
      "Epoch 118/1000\n",
      "1049/1049 [==============================] - 15s 15ms/step - loss: 2.9882 - accuracy: 0.0602 - val_loss: 3.0009 - val_accuracy: 0.0524\n",
      "Epoch 119/1000\n",
      "1049/1049 [==============================] - 15s 15ms/step - loss: 2.9880 - accuracy: 0.0605 - val_loss: 2.9994 - val_accuracy: 0.0509\n",
      "Epoch 120/1000\n",
      "1049/1049 [==============================] - 15s 14ms/step - loss: 2.9879 - accuracy: 0.0628 - val_loss: 3.0008 - val_accuracy: 0.0513\n",
      "Epoch 121/1000\n",
      "1049/1049 [==============================] - 16s 15ms/step - loss: 2.9875 - accuracy: 0.0643 - val_loss: 3.0005 - val_accuracy: 0.0496\n",
      "Epoch 122/1000\n",
      "1049/1049 [==============================] - 15s 14ms/step - loss: 2.9878 - accuracy: 0.0624 - val_loss: 3.0009 - val_accuracy: 0.0520\n",
      "Epoch 123/1000\n",
      "1049/1049 [==============================] - 15s 14ms/step - loss: 2.9874 - accuracy: 0.0593 - val_loss: 2.9999 - val_accuracy: 0.0515\n",
      "Epoch 124/1000\n",
      "1049/1049 [==============================] - 15s 15ms/step - loss: 2.9878 - accuracy: 0.0592 - val_loss: 2.9994 - val_accuracy: 0.0537\n",
      "Epoch 125/1000\n",
      "1049/1049 [==============================] - 15s 15ms/step - loss: 2.9871 - accuracy: 0.0608 - val_loss: 3.0016 - val_accuracy: 0.0526\n",
      "Epoch 126/1000\n",
      "1049/1049 [==============================] - 15s 15ms/step - loss: 2.9874 - accuracy: 0.0603 - val_loss: 3.0007 - val_accuracy: 0.0511\n",
      "Epoch 127/1000\n",
      "1049/1049 [==============================] - 16s 15ms/step - loss: 2.9867 - accuracy: 0.0628 - val_loss: 3.0011 - val_accuracy: 0.0522\n",
      "Epoch 128/1000\n",
      "1049/1049 [==============================] - 16s 15ms/step - loss: 2.9871 - accuracy: 0.0615 - val_loss: 3.0013 - val_accuracy: 0.0563\n",
      "Epoch 129/1000\n",
      "1049/1049 [==============================] - 16s 15ms/step - loss: 2.9869 - accuracy: 0.0610 - val_loss: 3.0007 - val_accuracy: 0.0522\n",
      "Epoch 130/1000\n",
      "1049/1049 [==============================] - 15s 14ms/step - loss: 2.9865 - accuracy: 0.0627 - val_loss: 3.0018 - val_accuracy: 0.0509\n",
      "Epoch 131/1000\n",
      "1049/1049 [==============================] - 15s 15ms/step - loss: 2.9864 - accuracy: 0.0612 - val_loss: 3.0011 - val_accuracy: 0.0500\n",
      "Epoch 132/1000\n",
      "1049/1049 [==============================] - 15s 15ms/step - loss: 2.9872 - accuracy: 0.0602 - val_loss: 3.0016 - val_accuracy: 0.0509\n",
      "Epoch 133/1000\n",
      "1049/1049 [==============================] - 16s 15ms/step - loss: 2.9857 - accuracy: 0.0627 - val_loss: 3.0020 - val_accuracy: 0.0487\n",
      "Epoch 134/1000\n",
      "1049/1049 [==============================] - 16s 15ms/step - loss: 2.9865 - accuracy: 0.0628 - val_loss: 3.0011 - val_accuracy: 0.0528\n",
      "Epoch 135/1000\n",
      "1049/1049 [==============================] - 16s 15ms/step - loss: 2.9864 - accuracy: 0.0614 - val_loss: 3.0024 - val_accuracy: 0.0494\n",
      "Epoch 136/1000\n",
      "1049/1049 [==============================] - 15s 15ms/step - loss: 2.9858 - accuracy: 0.0627 - val_loss: 3.0016 - val_accuracy: 0.0567\n",
      "Epoch 137/1000\n",
      "1049/1049 [==============================] - 15s 15ms/step - loss: 2.9862 - accuracy: 0.0611 - val_loss: 3.0021 - val_accuracy: 0.0491\n",
      "Epoch 138/1000\n",
      "1049/1049 [==============================] - 16s 15ms/step - loss: 2.9859 - accuracy: 0.0618 - val_loss: 3.0011 - val_accuracy: 0.0537\n",
      "Epoch 139/1000\n",
      "1049/1049 [==============================] - 16s 15ms/step - loss: 2.9860 - accuracy: 0.0634 - val_loss: 3.0011 - val_accuracy: 0.0513\n",
      "Epoch 140/1000\n",
      "1049/1049 [==============================] - 15s 15ms/step - loss: 2.9848 - accuracy: 0.0616 - val_loss: 3.0019 - val_accuracy: 0.0515\n",
      "Epoch 141/1000\n",
      "1049/1049 [==============================] - 15s 15ms/step - loss: 2.9854 - accuracy: 0.0625 - val_loss: 3.0022 - val_accuracy: 0.0507\n",
      "Epoch 142/1000\n",
      "1049/1049 [==============================] - 16s 15ms/step - loss: 2.9853 - accuracy: 0.0622 - val_loss: 3.0030 - val_accuracy: 0.0515\n",
      "Epoch 143/1000\n",
      "1049/1049 [==============================] - 15s 14ms/step - loss: 2.9852 - accuracy: 0.0628 - val_loss: 3.0022 - val_accuracy: 0.0533\n",
      "Epoch 144/1000\n",
      "1049/1049 [==============================] - 15s 14ms/step - loss: 2.9842 - accuracy: 0.0650 - val_loss: 3.0026 - val_accuracy: 0.0517\n",
      "Epoch 145/1000\n",
      "1049/1049 [==============================] - 15s 14ms/step - loss: 2.9851 - accuracy: 0.0613 - val_loss: 3.0026 - val_accuracy: 0.0465\n",
      "Epoch 146/1000\n",
      "1049/1049 [==============================] - 15s 15ms/step - loss: 2.9854 - accuracy: 0.0630 - val_loss: 3.0036 - val_accuracy: 0.0513\n",
      "Epoch 147/1000\n",
      "1049/1049 [==============================] - 15s 14ms/step - loss: 2.9848 - accuracy: 0.0629 - val_loss: 3.0024 - val_accuracy: 0.0533\n",
      "Epoch 148/1000\n",
      "1049/1049 [==============================] - 15s 15ms/step - loss: 2.9843 - accuracy: 0.0635 - val_loss: 3.0035 - val_accuracy: 0.0498\n",
      "Epoch 149/1000\n",
      "1049/1049 [==============================] - 15s 14ms/step - loss: 2.9838 - accuracy: 0.0658 - val_loss: 3.0023 - val_accuracy: 0.0504\n",
      "Epoch 150/1000\n",
      "1049/1049 [==============================] - 15s 14ms/step - loss: 2.9848 - accuracy: 0.0623 - val_loss: 3.0022 - val_accuracy: 0.0539\n",
      "Epoch 151/1000\n",
      "1049/1049 [==============================] - 15s 14ms/step - loss: 2.9844 - accuracy: 0.0617 - val_loss: 3.0026 - val_accuracy: 0.0513\n",
      "Epoch 152/1000\n",
      "1049/1049 [==============================] - 15s 15ms/step - loss: 2.9838 - accuracy: 0.0634 - val_loss: 3.0047 - val_accuracy: 0.0535\n",
      "Epoch 153/1000\n",
      "1049/1049 [==============================] - 15s 14ms/step - loss: 2.9839 - accuracy: 0.0658 - val_loss: 3.0037 - val_accuracy: 0.0485\n",
      "Epoch 154/1000\n",
      "1049/1049 [==============================] - 15s 14ms/step - loss: 2.9832 - accuracy: 0.0653 - val_loss: 3.0029 - val_accuracy: 0.0511\n",
      "Epoch 155/1000\n",
      "1049/1049 [==============================] - 15s 14ms/step - loss: 2.9837 - accuracy: 0.0633 - val_loss: 3.0021 - val_accuracy: 0.0535\n",
      "Epoch 156/1000\n",
      "1049/1049 [==============================] - 15s 15ms/step - loss: 2.9836 - accuracy: 0.0628 - val_loss: 3.0029 - val_accuracy: 0.0504\n",
      "Epoch 157/1000\n",
      "1049/1049 [==============================] - 15s 14ms/step - loss: 2.9839 - accuracy: 0.0626 - val_loss: 3.0045 - val_accuracy: 0.0528\n",
      "Epoch 158/1000\n",
      "1049/1049 [==============================] - 15s 15ms/step - loss: 2.9845 - accuracy: 0.0621 - val_loss: 3.0025 - val_accuracy: 0.0483\n",
      "Epoch 159/1000\n",
      "1049/1049 [==============================] - 16s 15ms/step - loss: 2.9834 - accuracy: 0.0643 - val_loss: 3.0035 - val_accuracy: 0.0498\n",
      "Epoch 160/1000\n",
      "1049/1049 [==============================] - 16s 15ms/step - loss: 2.9827 - accuracy: 0.0659 - val_loss: 3.0034 - val_accuracy: 0.0511\n",
      "Epoch 161/1000\n",
      "1049/1049 [==============================] - 16s 15ms/step - loss: 2.9827 - accuracy: 0.0666 - val_loss: 3.0042 - val_accuracy: 0.0487\n",
      "Epoch 162/1000\n",
      "1049/1049 [==============================] - 16s 15ms/step - loss: 2.9828 - accuracy: 0.0646 - val_loss: 3.0035 - val_accuracy: 0.0530\n",
      "Epoch 163/1000\n",
      "1049/1049 [==============================] - 15s 14ms/step - loss: 2.9833 - accuracy: 0.0657 - val_loss: 3.0049 - val_accuracy: 0.0494\n",
      "Epoch 164/1000\n",
      "1049/1049 [==============================] - 15s 14ms/step - loss: 2.9816 - accuracy: 0.0649 - val_loss: 3.0046 - val_accuracy: 0.0485\n",
      "Epoch 165/1000\n",
      "1049/1049 [==============================] - 15s 14ms/step - loss: 2.9828 - accuracy: 0.0648 - val_loss: 3.0037 - val_accuracy: 0.0513\n",
      "Epoch 166/1000\n",
      "1049/1049 [==============================] - 15s 14ms/step - loss: 2.9821 - accuracy: 0.0663 - val_loss: 3.0042 - val_accuracy: 0.0498\n",
      "Epoch 167/1000\n",
      "1049/1049 [==============================] - 15s 14ms/step - loss: 2.9806 - accuracy: 0.0665 - val_loss: 3.0053 - val_accuracy: 0.0543\n",
      "Epoch 168/1000\n",
      "1049/1049 [==============================] - 15s 14ms/step - loss: 2.9823 - accuracy: 0.0653 - val_loss: 3.0050 - val_accuracy: 0.0535\n",
      "Epoch 169/1000\n",
      "1049/1049 [==============================] - 15s 15ms/step - loss: 2.9812 - accuracy: 0.0647 - val_loss: 3.0037 - val_accuracy: 0.0537\n",
      "Epoch 170/1000\n",
      "1049/1049 [==============================] - 15s 14ms/step - loss: 2.9815 - accuracy: 0.0655 - val_loss: 3.0041 - val_accuracy: 0.0498\n",
      "Epoch 171/1000\n",
      "1049/1049 [==============================] - 15s 14ms/step - loss: 2.9816 - accuracy: 0.0676 - val_loss: 3.0043 - val_accuracy: 0.0496\n",
      "Epoch 172/1000\n",
      "1049/1049 [==============================] - 15s 14ms/step - loss: 2.9809 - accuracy: 0.0659 - val_loss: 3.0044 - val_accuracy: 0.0548\n",
      "Epoch 173/1000\n",
      "1049/1049 [==============================] - 15s 14ms/step - loss: 2.9815 - accuracy: 0.0669 - val_loss: 3.0045 - val_accuracy: 0.0515\n",
      "Epoch 174/1000\n",
      "1049/1049 [==============================] - 15s 14ms/step - loss: 2.9815 - accuracy: 0.0645 - val_loss: 3.0051 - val_accuracy: 0.0530\n",
      "Epoch 175/1000\n",
      "1049/1049 [==============================] - 15s 15ms/step - loss: 2.9808 - accuracy: 0.0672 - val_loss: 3.0043 - val_accuracy: 0.0548\n",
      "Epoch 176/1000\n",
      "1049/1049 [==============================] - 15s 15ms/step - loss: 2.9813 - accuracy: 0.0655 - val_loss: 3.0050 - val_accuracy: 0.0530\n",
      "Epoch 177/1000\n",
      "1049/1049 [==============================] - 15s 15ms/step - loss: 2.9814 - accuracy: 0.0656 - val_loss: 3.0055 - val_accuracy: 0.0496\n"
     ]
    }
   ],
   "source": [
    "train(model=model,\n",
    "      patience_train=10,\n",
    "      patience_val=None,\n",
    "      learning_rate=.00001,\n",
    "      epochs=1000,\n",
    "      batch_size=32,\n",
    "      # cont_train=True,\n",
    "      )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0688e654",
   "metadata": {
    "id": "0688e654"
   },
   "source": [
    "## RNN - 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0acf99f5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-04T15:26:16.627154Z",
     "start_time": "2023-07-04T15:24:51.238295Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 733,
     "status": "ok",
     "timestamp": 1688640986809,
     "user": {
      "displayName": "Yoni Krichevsky",
      "userId": "07735752940575548299"
     },
     "user_tz": -180
    },
    "id": "0acf99f5",
    "outputId": "ead223ea-5fcb-40a5-c55b-ee5ead83373c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_1 (LSTM)               (None, 20)                3280      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 20)                420       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,700\n",
      "Trainable params: 3,700\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "lstm = Sequential([LSTM(20, input_shape=(32, 20)),\n",
    "                  Dense(20, activation='softmax')]\n",
    "                  )\n",
    "lstm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fywomH2MyDHV",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1688640987798,
     "user": {
      "displayName": "Yoni Krichevsky",
      "userId": "07735752940575548299"
     },
     "user_tz": -180
    },
    "id": "fywomH2MyDHV",
    "outputId": "7318ee42-9e96-4cc8-e5cb-b797c936dcf4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((None, 32, 20), (None, 20))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm.input_shape, lstm.output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7scJaL11yFZl",
   "metadata": {
    "id": "7scJaL11yFZl"
   },
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "m8qVhFI0yGNq",
   "metadata": {
    "id": "m8qVhFI0yGNq"
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "\n",
    "lstm.compile(optimizer=Adam(learning_rate=learning_rate),\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qFT4LKjm1f4e",
   "metadata": {
    "id": "qFT4LKjm1f4e"
   },
   "outputs": [],
   "source": [
    "tf.config.run_functions_eagerly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "p_J8vUn3yIRt",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 129162,
     "status": "ok",
     "timestamp": 1688641143335,
     "user": {
      "displayName": "Yoni Krichevsky",
      "userId": "07735752940575548299"
     },
     "user_tz": -180
    },
    "id": "p_J8vUn3yIRt",
    "outputId": "3eb19f9a-1260-41a8-bf51-558b4bdb64c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "263/263 [==============================] - 12s 45ms/step - loss: 3.0303 - accuracy: 0.0490 - val_loss: 2.9992 - val_accuracy: 0.0459\n",
      "Epoch 2/20\n",
      "263/263 [==============================] - 12s 44ms/step - loss: 2.9970 - accuracy: 0.0489 - val_loss: 2.9969 - val_accuracy: 0.0483\n",
      "Epoch 3/20\n",
      "263/263 [==============================] - 13s 50ms/step - loss: 2.9965 - accuracy: 0.0488 - val_loss: 2.9972 - val_accuracy: 0.0515\n",
      "Epoch 4/20\n",
      "263/263 [==============================] - 11s 43ms/step - loss: 2.9961 - accuracy: 0.0502 - val_loss: 2.9970 - val_accuracy: 0.0513\n",
      "Epoch 5/20\n",
      "263/263 [==============================] - 11s 41ms/step - loss: 2.9959 - accuracy: 0.0511 - val_loss: 2.9972 - val_accuracy: 0.0448\n",
      "Epoch 6/20\n",
      "263/263 [==============================] - 12s 45ms/step - loss: 2.9956 - accuracy: 0.0485 - val_loss: 2.9968 - val_accuracy: 0.0489\n",
      "Epoch 7/20\n",
      "263/263 [==============================] - 11s 44ms/step - loss: 2.9954 - accuracy: 0.0505 - val_loss: 2.9975 - val_accuracy: 0.0509\n",
      "Epoch 8/20\n",
      "263/263 [==============================] - 12s 44ms/step - loss: 2.9955 - accuracy: 0.0519 - val_loss: 2.9978 - val_accuracy: 0.0448\n",
      "Epoch 9/20\n",
      "263/263 [==============================] - 12s 47ms/step - loss: 2.9954 - accuracy: 0.0491 - val_loss: 2.9973 - val_accuracy: 0.0446\n",
      "Epoch 10/20\n",
      "263/263 [==============================] - 11s 43ms/step - loss: 2.9952 - accuracy: 0.0496 - val_loss: 2.9980 - val_accuracy: 0.0487\n",
      "Epoch 11/20\n",
      "263/263 [==============================] - 11s 43ms/step - loss: 2.9950 - accuracy: 0.0515 - val_loss: 2.9974 - val_accuracy: 0.0507\n"
     ]
    }
   ],
   "source": [
    "# learning_rate = 0.001\n",
    "lstm.fit(X_train, y_train, batch_size=32, epochs=20, validation_data=(X_val, y_val), callbacks=[early_stopping]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "BXKeX35myKuR",
   "metadata": {
    "id": "BXKeX35myKuR"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "SUSSOLfn3AED",
   "metadata": {
    "id": "SUSSOLfn3AED"
   },
   "source": [
    "## RNN - 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vMpVlEXi3AEI",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-04T15:26:16.627154Z",
     "start_time": "2023-07-04T15:24:51.238295Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 57855,
     "status": "ok",
     "timestamp": 1688641276597,
     "user": {
      "displayName": "Yoni Krichevsky",
      "userId": "07735752940575548299"
     },
     "user_tz": -180
    },
    "id": "vMpVlEXi3AEI",
    "outputId": "0ce71c72-8f80-4b19-a6e4-cecb478c5465"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_2 (LSTM)               (None, 50)                14200     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 20)                1020      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 15,220\n",
      "Trainable params: 15,220\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "lstm = Sequential([LSTM(50, input_shape=(32, 20)),\n",
    "                  Dense(20, activation='softmax')]\n",
    "                  )\n",
    "lstm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ir2i_cdG3AEJ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1688641276598,
     "user": {
      "displayName": "Yoni Krichevsky",
      "userId": "07735752940575548299"
     },
     "user_tz": -180
    },
    "id": "ir2i_cdG3AEJ",
    "outputId": "c0fb217f-8fb1-4d28-c0b8-3529f85dd503"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((None, 32, 20), (None, 20))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm.input_shape, lstm.output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ozZiRn9j3AEJ",
   "metadata": {
    "id": "ozZiRn9j3AEJ"
   },
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "KKBQbuLu3AEJ",
   "metadata": {
    "id": "KKBQbuLu3AEJ"
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "\n",
    "lstm.compile(optimizer=Adam(learning_rate=learning_rate),\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aBA0eveL3AEJ",
   "metadata": {
    "id": "aBA0eveL3AEJ"
   },
   "outputs": [],
   "source": [
    "tf.config.run_functions_eagerly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "HPedmYez3AEJ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 311455,
     "status": "ok",
     "timestamp": 1688641588050,
     "user": {
      "displayName": "Yoni Krichevsky",
      "userId": "07735752940575548299"
     },
     "user_tz": -180
    },
    "id": "HPedmYez3AEJ",
    "outputId": "3e938c89-7f57-4180-ae17-0119a3dbcc61"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1049/1049 [==============================] - 45s 43ms/step - loss: 3.0044 - accuracy: 0.0507 - val_loss: 2.9986 - val_accuracy: 0.0487\n",
      "Epoch 2/20\n",
      "1049/1049 [==============================] - 44s 42ms/step - loss: 2.9984 - accuracy: 0.0488 - val_loss: 2.9970 - val_accuracy: 0.0524\n",
      "Epoch 3/20\n",
      "1049/1049 [==============================] - 44s 42ms/step - loss: 2.9981 - accuracy: 0.0518 - val_loss: 2.9995 - val_accuracy: 0.0470\n",
      "Epoch 4/20\n",
      "1049/1049 [==============================] - 45s 43ms/step - loss: 2.9988 - accuracy: 0.0503 - val_loss: 2.9990 - val_accuracy: 0.0489\n",
      "Epoch 5/20\n",
      "1049/1049 [==============================] - 44s 42ms/step - loss: 2.9981 - accuracy: 0.0494 - val_loss: 3.0023 - val_accuracy: 0.0459\n",
      "Epoch 6/20\n",
      "1049/1049 [==============================] - 45s 43ms/step - loss: 2.9977 - accuracy: 0.0510 - val_loss: 2.9984 - val_accuracy: 0.0507\n",
      "Epoch 7/20\n",
      "1049/1049 [==============================] - 45s 43ms/step - loss: 2.9973 - accuracy: 0.0508 - val_loss: 2.9998 - val_accuracy: 0.0522\n"
     ]
    }
   ],
   "source": [
    "# learning_rate = 0.001\n",
    "lstm.fit(X_train, y_train, batch_size=32, epochs=20, validation_data=(X_val, y_val), callbacks=[early_stopping]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dlNHfsIyKwW",
   "metadata": {
    "id": "0dlNHfsIyKwW"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "iwBCtxSH7rfV",
   "metadata": {
    "id": "iwBCtxSH7rfV"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bMjI-fAK7r4T",
   "metadata": {
    "id": "bMjI-fAK7r4T"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "kEn-XwRy7r4U",
   "metadata": {
    "id": "kEn-XwRy7r4U"
   },
   "source": [
    "## RNN - 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "uIPMOQB47r4U",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-04T15:26:16.627154Z",
     "start_time": "2023-07-04T15:24:51.238295Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 46091,
     "status": "ok",
     "timestamp": 1688642499141,
     "user": {
      "displayName": "Yoni Krichevsky",
      "userId": "07735752940575548299"
     },
     "user_tz": -180
    },
    "id": "uIPMOQB47r4U",
    "outputId": "f44acac4-ec79-4175-afdd-7f906819aecc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_3 (LSTM)               (None, 100)               48400     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 20)                2020      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 50,420\n",
      "Trainable params: 50,420\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "lstm = Sequential([LSTM(100, input_shape=(32, 20)),\n",
    "                  Dense(20, activation='softmax')]\n",
    "                  )\n",
    "lstm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "HA-XeO9H7r4U",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1688642499141,
     "user": {
      "displayName": "Yoni Krichevsky",
      "userId": "07735752940575548299"
     },
     "user_tz": -180
    },
    "id": "HA-XeO9H7r4U",
    "outputId": "94cfad1f-8360-4179-f47a-e38860ecf0cb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((None, 32, 20), (None, 20))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm.input_shape, lstm.output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8W_Q3RnZ7r4U",
   "metadata": {
    "id": "8W_Q3RnZ7r4U"
   },
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "GKZr0CQ07r4V",
   "metadata": {
    "id": "GKZr0CQ07r4V"
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.0001\n",
    "\n",
    "lstm.compile(optimizer=Adam(learning_rate=learning_rate),\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3sJuJ-VO7r4V",
   "metadata": {
    "id": "3sJuJ-VO7r4V"
   },
   "outputs": [],
   "source": [
    "tf.config.run_functions_eagerly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6tbtumjR7r4W",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 370825,
     "status": "ok",
     "timestamp": 1688642869963,
     "user": {
      "displayName": "Yoni Krichevsky",
      "userId": "07735752940575548299"
     },
     "user_tz": -180
    },
    "id": "6tbtumjR7r4W",
    "outputId": "1686e2fe-31ea-4836-ab90-a1b37ca3bbd1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "   1/1049 [..............................] - ETA: 1:19 - loss: 3.1293 - accuracy: 0.0312"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/structured_function.py:254: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1049/1049 [==============================] - 44s 42ms/step - loss: 3.0057 - accuracy: 0.0495 - val_loss: 2.9993 - val_accuracy: 0.0489\n",
      "Epoch 2/20\n",
      "1049/1049 [==============================] - 45s 43ms/step - loss: 3.0005 - accuracy: 0.0503 - val_loss: 2.9993 - val_accuracy: 0.0533\n",
      "Epoch 3/20\n",
      "1049/1049 [==============================] - 45s 42ms/step - loss: 3.0015 - accuracy: 0.0512 - val_loss: 2.9990 - val_accuracy: 0.0498\n",
      "Epoch 4/20\n",
      "1049/1049 [==============================] - 44s 42ms/step - loss: 2.9991 - accuracy: 0.0515 - val_loss: 3.0017 - val_accuracy: 0.0489\n",
      "Epoch 5/20\n",
      "1049/1049 [==============================] - 44s 42ms/step - loss: 2.9986 - accuracy: 0.0512 - val_loss: 3.0038 - val_accuracy: 0.0513\n",
      "Epoch 6/20\n",
      "1049/1049 [==============================] - 47s 45ms/step - loss: 2.9994 - accuracy: 0.0526 - val_loss: 3.0029 - val_accuracy: 0.0504\n",
      "Epoch 7/20\n",
      "1049/1049 [==============================] - 54s 52ms/step - loss: 2.9979 - accuracy: 0.0539 - val_loss: 3.0013 - val_accuracy: 0.0515\n",
      "Epoch 8/20\n",
      "1049/1049 [==============================] - 48s 46ms/step - loss: 2.9994 - accuracy: 0.0504 - val_loss: 3.0108 - val_accuracy: 0.0522\n"
     ]
    }
   ],
   "source": [
    "# learning_rate = 0.001\n",
    "lstm.fit(X_train, y_train, batch_size=32, epochs=20, validation_data=(X_val, y_val), callbacks=[early_stopping]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ZeEUOWp39fUT",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 343687,
     "status": "ok",
     "timestamp": 1688643258941,
     "user": {
      "displayName": "Yoni Krichevsky",
      "userId": "07735752940575548299"
     },
     "user_tz": -180
    },
    "id": "ZeEUOWp39fUT",
    "outputId": "4ee2204b-3a2c-48a5-b81a-b47cd497080e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/structured_function.py:254: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1049/1049 [==============================] - 46s 44ms/step - loss: 2.9937 - accuracy: 0.0533 - val_loss: 3.0010 - val_accuracy: 0.0489\n",
      "Epoch 2/20\n",
      "1049/1049 [==============================] - 45s 43ms/step - loss: 2.9904 - accuracy: 0.0558 - val_loss: 2.9991 - val_accuracy: 0.0520\n",
      "Epoch 3/20\n",
      "1049/1049 [==============================] - 44s 42ms/step - loss: 2.9892 - accuracy: 0.0556 - val_loss: 2.9996 - val_accuracy: 0.0524\n",
      "Epoch 4/20\n",
      "1049/1049 [==============================] - 48s 45ms/step - loss: 2.9884 - accuracy: 0.0560 - val_loss: 3.0001 - val_accuracy: 0.0489\n",
      "Epoch 5/20\n",
      "1049/1049 [==============================] - 44s 42ms/step - loss: 2.9878 - accuracy: 0.0558 - val_loss: 3.0007 - val_accuracy: 0.0580\n",
      "Epoch 6/20\n",
      "1049/1049 [==============================] - 45s 43ms/step - loss: 2.9871 - accuracy: 0.0560 - val_loss: 3.0007 - val_accuracy: 0.0457\n",
      "Epoch 7/20\n",
      "1049/1049 [==============================] - 45s 43ms/step - loss: 2.9868 - accuracy: 0.0566 - val_loss: 3.0002 - val_accuracy: 0.0496\n"
     ]
    }
   ],
   "source": [
    "# learning_rate = 0.0001\n",
    "lstm.fit(X_train, y_train, batch_size=32, epochs=20, validation_data=(X_val, y_val), callbacks=[early_stopping]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "TgsLxLOq8-Ax",
   "metadata": {
    "id": "TgsLxLOq8-Ax"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "_iauhkVw_Uqt",
   "metadata": {
    "id": "_iauhkVw_Uqt"
   },
   "source": [
    "## RNN - 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "x1LNquqw_Uq2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-04T15:26:16.627154Z",
     "start_time": "2023-07-04T15:24:51.238295Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 40842,
     "status": "ok",
     "timestamp": 1688643443631,
     "user": {
      "displayName": "Yoni Krichevsky",
      "userId": "07735752940575548299"
     },
     "user_tz": -180
    },
    "id": "x1LNquqw_Uq2",
    "outputId": "6f672904-ca4d-446b-ef71-447a81bd71aa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_4 (LSTM)               (None, 200)               176800    \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 20)                4020      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 180,820\n",
      "Trainable params: 180,820\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "lstm = Sequential([LSTM(200, input_shape=(32, 20)),\n",
    "                  Dense(20, activation='softmax')]\n",
    "                  )\n",
    "lstm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Ke_RbSmL_Uq3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1688643443631,
     "user": {
      "displayName": "Yoni Krichevsky",
      "userId": "07735752940575548299"
     },
     "user_tz": -180
    },
    "id": "Ke_RbSmL_Uq3",
    "outputId": "72adb1d8-457a-49f9-8024-a27260b95fed"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((None, 32, 20), (None, 20))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm.input_shape, lstm.output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "h5sCE9CP_Uq3",
   "metadata": {
    "id": "h5sCE9CP_Uq3"
   },
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Kt0oqxB8_Uq3",
   "metadata": {
    "id": "Kt0oqxB8_Uq3"
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.0001\n",
    "\n",
    "lstm.compile(optimizer=Adam(learning_rate=learning_rate),\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6oezAYDL_Uq3",
   "metadata": {
    "id": "6oezAYDL_Uq3"
   },
   "outputs": [],
   "source": [
    "tf.config.run_functions_eagerly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mXi4VxsE_Uq3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 482496,
     "status": "ok",
     "timestamp": 1688643926125,
     "user": {
      "displayName": "Yoni Krichevsky",
      "userId": "07735752940575548299"
     },
     "user_tz": -180
    },
    "id": "mXi4VxsE_Uq3",
    "outputId": "675f48aa-327c-4a89-fba7-26310f5493d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1049/1049 [==============================] - 48s 46ms/step - loss: 3.0241 - accuracy: 0.0502 - val_loss: 3.0057 - val_accuracy: 0.0535\n",
      "Epoch 2/20\n",
      "1049/1049 [==============================] - 48s 45ms/step - loss: 3.0001 - accuracy: 0.0531 - val_loss: 3.0037 - val_accuracy: 0.0517\n",
      "Epoch 3/20\n",
      "1049/1049 [==============================] - 47s 45ms/step - loss: 2.9968 - accuracy: 0.0529 - val_loss: 3.0044 - val_accuracy: 0.0500\n",
      "Epoch 4/20\n",
      "1049/1049 [==============================] - 51s 49ms/step - loss: 2.9950 - accuracy: 0.0557 - val_loss: 3.0024 - val_accuracy: 0.0504\n",
      "Epoch 5/20\n",
      "1049/1049 [==============================] - 51s 49ms/step - loss: 2.9931 - accuracy: 0.0540 - val_loss: 3.0008 - val_accuracy: 0.0543\n",
      "Epoch 6/20\n",
      "1049/1049 [==============================] - 47s 45ms/step - loss: 2.9915 - accuracy: 0.0556 - val_loss: 3.0030 - val_accuracy: 0.0470\n",
      "Epoch 7/20\n",
      "1049/1049 [==============================] - 50s 48ms/step - loss: 2.9898 - accuracy: 0.0562 - val_loss: 3.0014 - val_accuracy: 0.0507\n",
      "Epoch 8/20\n",
      "1049/1049 [==============================] - 46s 44ms/step - loss: 2.9881 - accuracy: 0.0596 - val_loss: 3.0016 - val_accuracy: 0.0489\n",
      "Epoch 9/20\n",
      "1049/1049 [==============================] - 47s 45ms/step - loss: 2.9864 - accuracy: 0.0596 - val_loss: 3.0040 - val_accuracy: 0.0455\n",
      "Epoch 10/20\n",
      "1049/1049 [==============================] - 47s 44ms/step - loss: 2.9847 - accuracy: 0.0608 - val_loss: 3.0041 - val_accuracy: 0.0461\n"
     ]
    }
   ],
   "source": [
    "# learning_rate = 0.0001\n",
    "lstm.fit(X_train, y_train, batch_size=32, epochs=20, validation_data=(X_val, y_val), callbacks=[early_stopping]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wVg4cpZKANpC",
   "metadata": {
    "id": "wVg4cpZKANpC"
   },
   "source": [
    "## RNN - 100 + Fully connected 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5W2YdZjkANpI",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-04T15:26:16.627154Z",
     "start_time": "2023-07-04T15:24:51.238295Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 645,
     "status": "ok",
     "timestamp": 1688643933138,
     "user": {
      "displayName": "Yoni Krichevsky",
      "userId": "07735752940575548299"
     },
     "user_tz": -180
    },
    "id": "5W2YdZjkANpI",
    "outputId": "e4d96d07-3fea-47a9-b0f1-436b7ee7e34e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_5 (LSTM)               (None, 100)               48400     \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 20)                2020      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 60,520\n",
      "Trainable params: 60,520\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "lstm = Sequential([LSTM(100, input_shape=(32, 20)),\n",
    "                   Dense(100, activation='sigmoid'),\n",
    "                   Dense(20, activation='softmax')]\n",
    "                  )\n",
    "lstm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "HoNbXRMLANpJ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1688643933139,
     "user": {
      "displayName": "Yoni Krichevsky",
      "userId": "07735752940575548299"
     },
     "user_tz": -180
    },
    "id": "HoNbXRMLANpJ",
    "outputId": "ead8d294-27ef-4d95-c266-d8dda5e5f6ee"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((None, 32, 20), (None, 20))"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm.input_shape, lstm.output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "IsJeK9wLANpJ",
   "metadata": {
    "id": "IsJeK9wLANpJ"
   },
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='loss', patience=5, min_delta=.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "LXtNkwHPANpJ",
   "metadata": {
    "id": "LXtNkwHPANpJ"
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "\n",
    "lstm.compile(optimizer=Adam(learning_rate=learning_rate),\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Q8afMtkKANpJ",
   "metadata": {
    "id": "Q8afMtkKANpJ"
   },
   "outputs": [],
   "source": [
    "tf.config.run_functions_eagerly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qTkfd46pANpJ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 963041,
     "status": "ok",
     "timestamp": 1688644905328,
     "user": {
      "displayName": "Yoni Krichevsky",
      "userId": "07735752940575548299"
     },
     "user_tz": -180
    },
    "id": "qTkfd46pANpJ",
    "outputId": "129ec303-ec3d-4f11-cbf3-024e4852a3fa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/structured_function.py:254: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1049/1049 [==============================] - 53s 50ms/step - loss: 3.0080 - accuracy: 0.0514 - val_loss: 3.0075 - val_accuracy: 0.0511\n",
      "Epoch 2/20\n",
      "1049/1049 [==============================] - 55s 53ms/step - loss: 3.0048 - accuracy: 0.0513 - val_loss: 3.0020 - val_accuracy: 0.0509\n",
      "Epoch 3/20\n",
      "1049/1049 [==============================] - 52s 50ms/step - loss: 3.0031 - accuracy: 0.0519 - val_loss: 2.9989 - val_accuracy: 0.0552\n",
      "Epoch 4/20\n",
      "1049/1049 [==============================] - 53s 50ms/step - loss: 3.0007 - accuracy: 0.0511 - val_loss: 2.9992 - val_accuracy: 0.0481\n",
      "Epoch 5/20\n",
      "1049/1049 [==============================] - 57s 55ms/step - loss: 2.9987 - accuracy: 0.0506 - val_loss: 2.9993 - val_accuracy: 0.0489\n",
      "Epoch 6/20\n",
      "1049/1049 [==============================] - 56s 53ms/step - loss: 2.9972 - accuracy: 0.0511 - val_loss: 2.9993 - val_accuracy: 0.0526\n",
      "Epoch 7/20\n",
      "1049/1049 [==============================] - 57s 54ms/step - loss: 2.9963 - accuracy: 0.0536 - val_loss: 2.9986 - val_accuracy: 0.0537\n",
      "Epoch 8/20\n",
      "1049/1049 [==============================] - 53s 51ms/step - loss: 2.9959 - accuracy: 0.0508 - val_loss: 2.9989 - val_accuracy: 0.0498\n",
      "Epoch 9/20\n",
      "1049/1049 [==============================] - 54s 52ms/step - loss: 2.9953 - accuracy: 0.0543 - val_loss: 2.9966 - val_accuracy: 0.0448\n",
      "Epoch 10/20\n",
      "1049/1049 [==============================] - 52s 50ms/step - loss: 2.9946 - accuracy: 0.0513 - val_loss: 2.9979 - val_accuracy: 0.0491\n",
      "Epoch 11/20\n",
      "1049/1049 [==============================] - 55s 52ms/step - loss: 2.9946 - accuracy: 0.0524 - val_loss: 2.9978 - val_accuracy: 0.0502\n",
      "Epoch 12/20\n",
      "1049/1049 [==============================] - 55s 52ms/step - loss: 2.9938 - accuracy: 0.0556 - val_loss: 2.9975 - val_accuracy: 0.0476\n",
      "Epoch 13/20\n",
      "1049/1049 [==============================] - 52s 49ms/step - loss: 2.9937 - accuracy: 0.0534 - val_loss: 2.9966 - val_accuracy: 0.0546\n",
      "Epoch 14/20\n",
      "1049/1049 [==============================] - 51s 49ms/step - loss: 2.9936 - accuracy: 0.0535 - val_loss: 2.9976 - val_accuracy: 0.0541\n",
      "Epoch 15/20\n",
      "1049/1049 [==============================] - 51s 49ms/step - loss: 2.9927 - accuracy: 0.0531 - val_loss: 2.9993 - val_accuracy: 0.0463\n",
      "Epoch 16/20\n",
      "1049/1049 [==============================] - 52s 49ms/step - loss: 2.9929 - accuracy: 0.0537 - val_loss: 3.0000 - val_accuracy: 0.0522\n",
      "Epoch 17/20\n",
      "1049/1049 [==============================] - 52s 50ms/step - loss: 2.9914 - accuracy: 0.0549 - val_loss: 2.9981 - val_accuracy: 0.0539\n",
      "Epoch 18/20\n",
      "1049/1049 [==============================] - 52s 50ms/step - loss: 2.9912 - accuracy: 0.0550 - val_loss: 3.0016 - val_accuracy: 0.0476\n"
     ]
    }
   ],
   "source": [
    "# learning_rate = 0.001\n",
    "lstm.fit(X_train, y_train, batch_size=32, epochs=20, validation_data=(X_val, y_val), callbacks=[early_stopping]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "WHzjb02WFqUf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 820290,
     "status": "ok",
     "timestamp": 1688645894891,
     "user": {
      "displayName": "Yoni Krichevsky",
      "userId": "07735752940575548299"
     },
     "user_tz": -180
    },
    "id": "WHzjb02WFqUf",
    "outputId": "7527e2d9-e614-4fee-d386-6c0b230e6793"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "   1/1049 [..............................] - ETA: 1:05 - loss: 3.0199 - accuracy: 0.0312"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/structured_function.py:254: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1049/1049 [==============================] - 54s 52ms/step - loss: 2.9983 - accuracy: 0.0503 - val_loss: 3.0000 - val_accuracy: 0.0465\n",
      "Epoch 2/20\n",
      "1049/1049 [==============================] - 53s 51ms/step - loss: 2.9981 - accuracy: 0.0474 - val_loss: 2.9965 - val_accuracy: 0.0522\n",
      "Epoch 3/20\n",
      "1049/1049 [==============================] - 55s 52ms/step - loss: 2.9976 - accuracy: 0.0502 - val_loss: 2.9993 - val_accuracy: 0.0502\n",
      "Epoch 4/20\n",
      "1049/1049 [==============================] - 53s 50ms/step - loss: 2.9980 - accuracy: 0.0483 - val_loss: 2.9970 - val_accuracy: 0.0502\n",
      "Epoch 5/20\n",
      "1049/1049 [==============================] - 53s 50ms/step - loss: 2.9976 - accuracy: 0.0510 - val_loss: 2.9976 - val_accuracy: 0.0465\n",
      "Epoch 6/20\n",
      "1049/1049 [==============================] - 54s 51ms/step - loss: 2.9973 - accuracy: 0.0532 - val_loss: 3.0005 - val_accuracy: 0.0463\n",
      "Epoch 7/20\n",
      "1049/1049 [==============================] - 54s 51ms/step - loss: 2.9976 - accuracy: 0.0473 - val_loss: 2.9997 - val_accuracy: 0.0522\n",
      "Epoch 8/20\n",
      "1049/1049 [==============================] - 54s 51ms/step - loss: 2.9975 - accuracy: 0.0529 - val_loss: 2.9989 - val_accuracy: 0.0504\n",
      "Epoch 9/20\n",
      "1049/1049 [==============================] - 58s 56ms/step - loss: 2.9973 - accuracy: 0.0503 - val_loss: 3.0004 - val_accuracy: 0.0517\n",
      "Epoch 10/20\n",
      "1049/1049 [==============================] - 56s 54ms/step - loss: 2.9972 - accuracy: 0.0494 - val_loss: 2.9979 - val_accuracy: 0.0485\n",
      "Epoch 11/20\n",
      "1049/1049 [==============================] - 53s 51ms/step - loss: 2.9978 - accuracy: 0.0488 - val_loss: 2.9992 - val_accuracy: 0.0487\n",
      "Epoch 12/20\n",
      "1049/1049 [==============================] - 57s 54ms/step - loss: 2.9975 - accuracy: 0.0487 - val_loss: 2.9993 - val_accuracy: 0.0465\n",
      "Epoch 13/20\n",
      "1049/1049 [==============================] - 53s 50ms/step - loss: 2.9976 - accuracy: 0.0495 - val_loss: 2.9976 - val_accuracy: 0.0465\n",
      "Epoch 14/20\n",
      "1049/1049 [==============================] - 55s 52ms/step - loss: 2.9978 - accuracy: 0.0498 - val_loss: 3.0002 - val_accuracy: 0.0535\n",
      "Epoch 15/20\n",
      "1049/1049 [==============================] - 59s 56ms/step - loss: 2.9976 - accuracy: 0.0499 - val_loss: 3.0008 - val_accuracy: 0.0487\n"
     ]
    }
   ],
   "source": [
    "# learning_rate = 0.01\n",
    "lstm.fit(X_train, y_train, batch_size=32, epochs=20, validation_data=(X_val, y_val), callbacks=[early_stopping]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "HHMmM4IAHb6L",
   "metadata": {
    "id": "HHMmM4IAHb6L"
   },
   "source": [
    "## RNN - Bidirections, small LSTM, larger Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "HgR5_O0vHb6L",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-04T15:26:16.627154Z",
     "start_time": "2023-07-04T15:24:51.238295Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 945,
     "status": "ok",
     "timestamp": 1688645947147,
     "user": {
      "displayName": "Yoni Krichevsky",
      "userId": "07735752940575548299"
     },
     "user_tz": -180
    },
    "id": "HgR5_O0vHb6L",
    "outputId": "3b39cd9b-f05f-493c-9a66-6a542c5d4614"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bidirectional (Bidirectiona  (None, 40)               6560      \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 100)               4100      \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 20)                2020      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 12,680\n",
      "Trainable params: 12,680\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "lstm = Sequential([Bidirectional(LSTM(20), input_shape=(32, 20)),\n",
    "                   Dense(100, activation='sigmoid'),\n",
    "                   Dense(20, activation='softmax')]\n",
    "                  )\n",
    "lstm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wVO4OOvpHb6M",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 276,
     "status": "ok",
     "timestamp": 1688645960835,
     "user": {
      "displayName": "Yoni Krichevsky",
      "userId": "07735752940575548299"
     },
     "user_tz": -180
    },
    "id": "wVO4OOvpHb6M",
    "outputId": "80e5292a-26ff-4e37-fadf-a1a3443b36a9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((None, 32, 20), (None, 20))"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm.input_shape, lstm.output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ulbgFVfOHb6M",
   "metadata": {
    "id": "ulbgFVfOHb6M"
   },
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='loss', patience=5, min_delta=.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9SoJ4hHFHb6M",
   "metadata": {
    "id": "9SoJ4hHFHb6M"
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "\n",
    "lstm.compile(optimizer=Adam(learning_rate=learning_rate),\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00MPBGeKHb6M",
   "metadata": {
    "id": "00MPBGeKHb6M"
   },
   "outputs": [],
   "source": [
    "tf.config.run_functions_eagerly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "X63u9DK-Hb6M",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1587821,
     "status": "ok",
     "timestamp": 1688647563568,
     "user": {
      "displayName": "Yoni Krichevsky",
      "userId": "07735752940575548299"
     },
     "user_tz": -180
    },
    "id": "X63u9DK-Hb6M",
    "outputId": "d4180166-d74d-4815-9e3e-8f5da5cd09a4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/structured_function.py:254: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1049/1049 [==============================] - 78s 74ms/step - loss: 3.0075 - accuracy: 0.0502 - val_loss: 3.0005 - val_accuracy: 0.0509\n",
      "Epoch 2/20\n",
      "1049/1049 [==============================] - 78s 75ms/step - loss: 3.0050 - accuracy: 0.0523 - val_loss: 3.0041 - val_accuracy: 0.0546\n",
      "Epoch 3/20\n",
      "1049/1049 [==============================] - 79s 75ms/step - loss: 3.0045 - accuracy: 0.0506 - val_loss: 3.0085 - val_accuracy: 0.0470\n",
      "Epoch 4/20\n",
      "1049/1049 [==============================] - 79s 75ms/step - loss: 3.0034 - accuracy: 0.0504 - val_loss: 3.0014 - val_accuracy: 0.0526\n",
      "Epoch 5/20\n",
      "1049/1049 [==============================] - 78s 74ms/step - loss: 3.0014 - accuracy: 0.0524 - val_loss: 3.0061 - val_accuracy: 0.0520\n",
      "Epoch 6/20\n",
      "1049/1049 [==============================] - 77s 74ms/step - loss: 3.0012 - accuracy: 0.0519 - val_loss: 3.0041 - val_accuracy: 0.0485\n",
      "Epoch 7/20\n",
      "1049/1049 [==============================] - 77s 74ms/step - loss: 3.0007 - accuracy: 0.0518 - val_loss: 2.9991 - val_accuracy: 0.0537\n",
      "Epoch 8/20\n",
      "1049/1049 [==============================] - 76s 73ms/step - loss: 2.9994 - accuracy: 0.0518 - val_loss: 3.0014 - val_accuracy: 0.0485\n",
      "Epoch 9/20\n",
      "1049/1049 [==============================] - 80s 77ms/step - loss: 2.9988 - accuracy: 0.0508 - val_loss: 3.0031 - val_accuracy: 0.0515\n",
      "Epoch 10/20\n",
      "1049/1049 [==============================] - 80s 76ms/step - loss: 2.9976 - accuracy: 0.0502 - val_loss: 2.9991 - val_accuracy: 0.0489\n",
      "Epoch 11/20\n",
      "1049/1049 [==============================] - 81s 77ms/step - loss: 2.9968 - accuracy: 0.0530 - val_loss: 2.9993 - val_accuracy: 0.0483\n",
      "Epoch 12/20\n",
      "1049/1049 [==============================] - 81s 77ms/step - loss: 2.9973 - accuracy: 0.0503 - val_loss: 2.9972 - val_accuracy: 0.0509\n",
      "Epoch 13/20\n",
      "1049/1049 [==============================] - 80s 76ms/step - loss: 2.9970 - accuracy: 0.0519 - val_loss: 2.9981 - val_accuracy: 0.0504\n",
      "Epoch 14/20\n",
      "1049/1049 [==============================] - 85s 81ms/step - loss: 2.9964 - accuracy: 0.0526 - val_loss: 2.9990 - val_accuracy: 0.0513\n",
      "Epoch 15/20\n",
      "1049/1049 [==============================] - 81s 78ms/step - loss: 2.9952 - accuracy: 0.0514 - val_loss: 2.9978 - val_accuracy: 0.0448\n",
      "Epoch 16/20\n",
      "1049/1049 [==============================] - 82s 78ms/step - loss: 2.9947 - accuracy: 0.0529 - val_loss: 2.9983 - val_accuracy: 0.0457\n",
      "Epoch 17/20\n",
      "1049/1049 [==============================] - 79s 75ms/step - loss: 2.9945 - accuracy: 0.0523 - val_loss: 2.9977 - val_accuracy: 0.0487\n",
      "Epoch 18/20\n",
      "1049/1049 [==============================] - 79s 75ms/step - loss: 2.9944 - accuracy: 0.0541 - val_loss: 2.9999 - val_accuracy: 0.0513\n",
      "Epoch 19/20\n",
      "1049/1049 [==============================] - 78s 74ms/step - loss: 2.9944 - accuracy: 0.0523 - val_loss: 2.9991 - val_accuracy: 0.0541\n",
      "Epoch 20/20\n",
      "1049/1049 [==============================] - 77s 74ms/step - loss: 2.9944 - accuracy: 0.0517 - val_loss: 2.9983 - val_accuracy: 0.0533\n"
     ]
    }
   ],
   "source": [
    "# learning_rate = 0.001\n",
    "lstm.fit(X_train, y_train, batch_size=32, epochs=20, validation_data=(X_val, y_val), callbacks=[early_stopping]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0tTFZMKpPQBM",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 473313,
     "status": "ok",
     "timestamp": 1688648076933,
     "user": {
      "displayName": "Yoni Krichevsky",
      "userId": "07735752940575548299"
     },
     "user_tz": -180
    },
    "id": "0tTFZMKpPQBM",
    "outputId": "4d1baf0e-4bed-49a1-b630-c827c3893fe9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/structured_function.py:254: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1049/1049 [==============================] - 76s 73ms/step - loss: 2.9979 - accuracy: 0.0512 - val_loss: 2.9989 - val_accuracy: 0.0487\n",
      "Epoch 2/20\n",
      "1049/1049 [==============================] - 79s 75ms/step - loss: 2.9976 - accuracy: 0.0499 - val_loss: 2.9994 - val_accuracy: 0.0522\n",
      "Epoch 3/20\n",
      "1049/1049 [==============================] - 80s 76ms/step - loss: 2.9974 - accuracy: 0.0515 - val_loss: 2.9969 - val_accuracy: 0.0522\n",
      "Epoch 4/20\n",
      "1049/1049 [==============================] - 81s 77ms/step - loss: 2.9975 - accuracy: 0.0516 - val_loss: 2.9989 - val_accuracy: 0.0487\n",
      "Epoch 5/20\n",
      "1049/1049 [==============================] - 79s 75ms/step - loss: 2.9975 - accuracy: 0.0483 - val_loss: 2.9998 - val_accuracy: 0.0520\n",
      "Epoch 6/20\n",
      "1049/1049 [==============================] - 78s 74ms/step - loss: 2.9973 - accuracy: 0.0500 - val_loss: 2.9993 - val_accuracy: 0.0463\n"
     ]
    }
   ],
   "source": [
    "# learning_rate = 0.01\n",
    "lstm.fit(X_train, y_train, batch_size=32, epochs=20, validation_data=(X_val, y_val), callbacks=[early_stopping]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "NvWMQzewNNej",
   "metadata": {
    "id": "NvWMQzewNNej"
   },
   "source": [
    "## RNN - Bidirections, 2 larger LSTMS, larger Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mMT5IJ41NNep",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-04T15:26:16.627154Z",
     "start_time": "2023-07-04T15:24:51.238295Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1779,
     "status": "ok",
     "timestamp": 1688648142586,
     "user": {
      "displayName": "Yoni Krichevsky",
      "userId": "07735752940575548299"
     },
     "user_tz": -180
    },
    "id": "mMT5IJ41NNep",
    "outputId": "cc2bbfb9-add2-4c92-f748-8790b893607c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bidirectional_1 (Bidirectio  (None, 32, 128)          43520     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " bidirectional_2 (Bidirectio  (None, 128)              98816     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 100)               12900     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 100)               0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 20)                2020      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 157,256\n",
      "Trainable params: 157,256\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "lstm = Sequential([Bidirectional(LSTM(64, return_sequences=True), input_shape=(32, 20)),\n",
    "                   Bidirectional(LSTM(64)),\n",
    "                   Dense(100, activation='sigmoid'),\n",
    "                   Dropout(.5),\n",
    "                   Dense(20, activation='softmax')]\n",
    "                  )\n",
    "lstm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "p0mzooYXNNeq",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1688648142586,
     "user": {
      "displayName": "Yoni Krichevsky",
      "userId": "07735752940575548299"
     },
     "user_tz": -180
    },
    "id": "p0mzooYXNNeq",
    "outputId": "6ce20a10-3645-498b-b383-bf3fb356ad26"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((None, 32, 20), (None, 20))"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm.input_shape, lstm.output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rlmSlaUaNNeq",
   "metadata": {
    "id": "rlmSlaUaNNeq"
   },
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='loss', patience=5, min_delta=.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "CBChupFeNNeq",
   "metadata": {
    "id": "CBChupFeNNeq"
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "\n",
    "lstm.compile(optimizer=Adam(learning_rate=learning_rate),\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "LCLH2mUgNNeq",
   "metadata": {
    "id": "LCLH2mUgNNeq"
   },
   "outputs": [],
   "source": [
    "tf.config.run_functions_eagerly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "RtPDU0NDNNeq",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 851454,
     "status": "ok",
     "timestamp": 1688649000399,
     "user": {
      "displayName": "Yoni Krichevsky",
      "userId": "07735752940575548299"
     },
     "user_tz": -180
    },
    "id": "RtPDU0NDNNeq",
    "outputId": "d737c749-e8b0-4ab2-f755-509c66dea153"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/structured_function.py:254: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1049/1049 [==============================] - 122s 116ms/step - loss: 3.0087 - accuracy: 0.0497 - val_loss: 2.9960 - val_accuracy: 0.0487\n",
      "Epoch 2/20\n",
      "1049/1049 [==============================] - 121s 115ms/step - loss: 2.9963 - accuracy: 0.0484 - val_loss: 2.9957 - val_accuracy: 0.0500\n",
      "Epoch 3/20\n",
      "1049/1049 [==============================] - 121s 115ms/step - loss: 2.9960 - accuracy: 0.0494 - val_loss: 2.9957 - val_accuracy: 0.0517\n",
      "Epoch 4/20\n",
      "1049/1049 [==============================] - 121s 115ms/step - loss: 2.9959 - accuracy: 0.0513 - val_loss: 2.9958 - val_accuracy: 0.0520\n",
      "Epoch 5/20\n",
      "1049/1049 [==============================] - 122s 116ms/step - loss: 2.9959 - accuracy: 0.0498 - val_loss: 2.9960 - val_accuracy: 0.0517\n",
      "Epoch 6/20\n",
      "1049/1049 [==============================] - 122s 117ms/step - loss: 2.9958 - accuracy: 0.0504 - val_loss: 2.9962 - val_accuracy: 0.0517\n",
      "Epoch 7/20\n",
      "1049/1049 [==============================] - 122s 117ms/step - loss: 2.9960 - accuracy: 0.0509 - val_loss: 2.9963 - val_accuracy: 0.0522\n"
     ]
    }
   ],
   "source": [
    "# learning_rate = 0.001\n",
    "lstm.fit(X_train, y_train, batch_size=32, epochs=20, validation_data=(X_val, y_val), callbacks=[early_stopping]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "B0mWKl0mUy8G",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 752665,
     "status": "ok",
     "timestamp": 1688649780447,
     "user": {
      "displayName": "Yoni Krichevsky",
      "userId": "07735752940575548299"
     },
     "user_tz": -180
    },
    "id": "B0mWKl0mUy8G",
    "outputId": "a8ac4e94-2d7f-4fb2-a50b-ff7ccc705b7a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1049/1049 [==============================] - 127s 121ms/step - loss: 2.9984 - accuracy: 0.0516 - val_loss: 2.9966 - val_accuracy: 0.0509\n",
      "Epoch 2/20\n",
      "1049/1049 [==============================] - 121s 115ms/step - loss: 2.9978 - accuracy: 0.0501 - val_loss: 2.9972 - val_accuracy: 0.0507\n",
      "Epoch 3/20\n",
      "1049/1049 [==============================] - 128s 122ms/step - loss: 2.9983 - accuracy: 0.0481 - val_loss: 2.9971 - val_accuracy: 0.0485\n",
      "Epoch 4/20\n",
      "1049/1049 [==============================] - 125s 119ms/step - loss: 2.9977 - accuracy: 0.0495 - val_loss: 2.9983 - val_accuracy: 0.0507\n",
      "Epoch 5/20\n",
      "1049/1049 [==============================] - 127s 121ms/step - loss: 2.9981 - accuracy: 0.0501 - val_loss: 2.9974 - val_accuracy: 0.0504\n",
      "Epoch 6/20\n",
      "1049/1049 [==============================] - 124s 118ms/step - loss: 2.9982 - accuracy: 0.0500 - val_loss: 2.9974 - val_accuracy: 0.0487\n"
     ]
    }
   ],
   "source": [
    "# learning_rate = 0.01\n",
    "lstm.fit(X_train, y_train, batch_size=32, epochs=20, validation_data=(X_val, y_val), callbacks=[early_stopping]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5srZn09GV3hV",
   "metadata": {
    "id": "5srZn09GV3hV"
   },
   "source": [
    "## RNN - Bidirections, 2 larger LSTMS, larger Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qxqk5orqV3hW",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-04T15:26:16.627154Z",
     "start_time": "2023-07-04T15:24:51.238295Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1327,
     "status": "ok",
     "timestamp": 1688653330051,
     "user": {
      "displayName": "Yoni Krichevsky",
      "userId": "07735752940575548299"
     },
     "user_tz": -180
    },
    "id": "qxqk5orqV3hW",
    "outputId": "7c79328a-ac4e-4522-f8b4-ee524f4e7b58"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bidirectional_9 (Bidirectio  (None, 32, 256)          152576    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " bidirectional_10 (Bidirecti  (None, 128)              164352    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 100)               12900     \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 100)               0         \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 20)                2020      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 331,848\n",
      "Trainable params: 331,848\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "lstm = Sequential([Bidirectional(LSTM(128, return_sequences=True), input_shape=(32, 20)),\n",
    "                  #  Dropout(.5),\n",
    "                   Bidirectional(LSTM(64)),\n",
    "                  #  Dropout(.5),\n",
    "                   Dense(100, activation='sigmoid'),\n",
    "                   Dropout(.5),\n",
    "                   Dense(20, activation='softmax')]\n",
    "                  )\n",
    "lstm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "-h3pGQcDV3hX",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 487,
     "status": "ok",
     "timestamp": 1688653339986,
     "user": {
      "displayName": "Yoni Krichevsky",
      "userId": "07735752940575548299"
     },
     "user_tz": -180
    },
    "id": "-h3pGQcDV3hX",
    "outputId": "fd182da8-7d41-4ed6-f71c-1f882da44f2d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((None, 32, 20), (None, 20))"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm.input_shape, lstm.output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Cbjzh9-1V3hX",
   "metadata": {
    "id": "Cbjzh9-1V3hX"
   },
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='loss', patience=4, min_delta=.001)\n",
    "early_stopping_val = EarlyStopping(monitor='val_loss', patience=4, min_delta=.001)\n",
    "callbacks = [early_stopping, early_stopping_val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nogPrCp0V3hX",
   "metadata": {
    "id": "nogPrCp0V3hX"
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "\n",
    "lstm.compile(optimizer=Adam(learning_rate=learning_rate),\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Esgal0uCV3hX",
   "metadata": {
    "id": "Esgal0uCV3hX"
   },
   "outputs": [],
   "source": [
    "tf.config.run_functions_eagerly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "zZCk3Iw3V3hX",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 113108,
     "status": "ok",
     "timestamp": 1688653462485,
     "user": {
      "displayName": "Yoni Krichevsky",
      "userId": "07735752940575548299"
     },
     "user_tz": -180
    },
    "id": "zZCk3Iw3V3hX",
    "outputId": "90909d26-34bc-45d4-d117-09c53bcaa0d8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "132/132 [==============================] - 17s 125ms/step - loss: 3.0350 - accuracy: 0.0513 - val_loss: 2.9959 - val_accuracy: 0.0541\n",
      "Epoch 2/20\n",
      "132/132 [==============================] - 16s 119ms/step - loss: 2.9974 - accuracy: 0.0501 - val_loss: 2.9960 - val_accuracy: 0.0517\n",
      "Epoch 3/20\n",
      "132/132 [==============================] - 16s 119ms/step - loss: 2.9961 - accuracy: 0.0516 - val_loss: 2.9961 - val_accuracy: 0.0517\n",
      "Epoch 4/20\n",
      "132/132 [==============================] - 16s 119ms/step - loss: 2.9959 - accuracy: 0.0503 - val_loss: 2.9960 - val_accuracy: 0.0487\n",
      "Epoch 5/20\n",
      "132/132 [==============================] - 16s 122ms/step - loss: 2.9960 - accuracy: 0.0487 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 6/20\n",
      "132/132 [==============================] - 16s 122ms/step - loss: 2.9959 - accuracy: 0.0494 - val_loss: 2.9959 - val_accuracy: 0.0517\n",
      "Epoch 7/20\n",
      "132/132 [==============================] - 16s 122ms/step - loss: 2.9958 - accuracy: 0.0495 - val_loss: 2.9960 - val_accuracy: 0.0517\n"
     ]
    }
   ],
   "source": [
    "# learning_rate = 0.001\n",
    "lstm.fit(X_train, y_train, batch_size=256, epochs=20, validation_data=(X_val, y_val),\n",
    "         callbacks=[early_stopping]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "NkjpgmCRl1d_",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 103897,
     "status": "ok",
     "timestamp": 1688653713985,
     "user": {
      "displayName": "Yoni Krichevsky",
      "userId": "07735752940575548299"
     },
     "user_tz": -180
    },
    "id": "NkjpgmCRl1d_",
    "outputId": "7c95bc53-1fb9-45e9-d23e-4cf667e5895b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "132/132 [==============================] - 16s 120ms/step - loss: 2.9957 - accuracy: 0.0516 - val_loss: 2.9961 - val_accuracy: 0.0522\n",
      "Epoch 2/20\n",
      "132/132 [==============================] - 16s 124ms/step - loss: 2.9955 - accuracy: 0.0496 - val_loss: 2.9960 - val_accuracy: 0.0509\n",
      "Epoch 3/20\n",
      "132/132 [==============================] - 16s 123ms/step - loss: 2.9957 - accuracy: 0.0509 - val_loss: 2.9962 - val_accuracy: 0.0465\n",
      "Epoch 4/20\n",
      "132/132 [==============================] - 16s 119ms/step - loss: 2.9958 - accuracy: 0.0500 - val_loss: 2.9962 - val_accuracy: 0.0517\n",
      "Epoch 5/20\n",
      "132/132 [==============================] - 16s 121ms/step - loss: 2.9958 - accuracy: 0.0517 - val_loss: 2.9961 - val_accuracy: 0.0517\n"
     ]
    }
   ],
   "source": [
    "# learning_rate = 0.001\n",
    "lstm.fit(X_train, y_train, batch_size=256, epochs=20, validation_data=(X_val, y_val),\n",
    "         callbacks=[early_stopping]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "k3nHHuznl-u5",
   "metadata": {
    "id": "k3nHHuznl-u5"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "867ainy0nIHq",
   "metadata": {
    "id": "867ainy0nIHq"
   },
   "source": [
    "## RNN - 3 Bidirections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Tu24UXwMnIH0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-04T15:26:16.627154Z",
     "start_time": "2023-07-04T15:24:51.238295Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 53286,
     "status": "ok",
     "timestamp": 1688653958510,
     "user": {
      "displayName": "Yoni Krichevsky",
      "userId": "07735752940575548299"
     },
     "user_tz": -180
    },
    "id": "Tu24UXwMnIH0",
    "outputId": "d2ccc8c2-0cf0-475a-a5d9-ae818211e1b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bidirectional_11 (Bidirecti  (None, 32, 256)          152576    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " bidirectional_12 (Bidirecti  (None, 32, 256)          394240    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " bidirectional_13 (Bidirecti  (None, 256)              394240    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 20)                5140      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 946,196\n",
      "Trainable params: 946,196\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "lstm = Sequential([Bidirectional(LSTM(128, return_sequences=True, dropout=.2), input_shape=(32, 20)),\n",
    "                   Bidirectional(LSTM(128, return_sequences=True, dropout=.2)),\n",
    "                   Bidirectional(LSTM(128, dropout=.2)),\n",
    "                  #  Dense(100, activation='sigmoid'),\n",
    "                  #  Dropout(.5),\n",
    "                   Dense(20, activation='softmax')]\n",
    "                  )\n",
    "lstm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Th98rYwLnIH1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 28,
     "status": "ok",
     "timestamp": 1688653958512,
     "user": {
      "displayName": "Yoni Krichevsky",
      "userId": "07735752940575548299"
     },
     "user_tz": -180
    },
    "id": "Th98rYwLnIH1",
    "outputId": "23174cb1-1af1-4903-c0dc-47fdde4636d6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((None, 32, 20), (None, 20))"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm.input_shape, lstm.output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gTuItHnlnIH1",
   "metadata": {
    "id": "gTuItHnlnIH1"
   },
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='loss', patience=4, min_delta=.001)\n",
    "early_stopping_val = EarlyStopping(monitor='val_loss', patience=4, min_delta=.001)\n",
    "callbacks = [early_stopping, early_stopping_val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "VQnogaaOnIH1",
   "metadata": {
    "id": "VQnogaaOnIH1"
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "\n",
    "lstm.compile(optimizer=Adam(learning_rate=learning_rate),\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "W2y5DgGVnIH1",
   "metadata": {
    "id": "W2y5DgGVnIH1"
   },
   "outputs": [],
   "source": [
    "tf.config.run_functions_eagerly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "JTeOEJnMnIH1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 454644,
     "status": "ok",
     "timestamp": 1688654413134,
     "user": {
      "displayName": "Yoni Krichevsky",
      "userId": "07735752940575548299"
     },
     "user_tz": -180
    },
    "id": "JTeOEJnMnIH1",
    "outputId": "a7bf9818-c35d-4f6c-e4ef-5467a3686982"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/structured_function.py:254: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132/132 [==============================] - 24s 181ms/step - loss: 3.0053 - accuracy: 0.0513 - val_loss: 3.0008 - val_accuracy: 0.0487\n",
      "Epoch 2/20\n",
      "132/132 [==============================] - 24s 179ms/step - loss: 2.9975 - accuracy: 0.0520 - val_loss: 2.9969 - val_accuracy: 0.0528\n",
      "Epoch 3/20\n",
      "132/132 [==============================] - 23s 175ms/step - loss: 2.9956 - accuracy: 0.0526 - val_loss: 2.9982 - val_accuracy: 0.0504\n",
      "Epoch 4/20\n",
      "132/132 [==============================] - 22s 168ms/step - loss: 2.9951 - accuracy: 0.0531 - val_loss: 2.9968 - val_accuracy: 0.0533\n",
      "Epoch 5/20\n",
      "132/132 [==============================] - 23s 171ms/step - loss: 2.9945 - accuracy: 0.0566 - val_loss: 2.9985 - val_accuracy: 0.0459\n",
      "Epoch 6/20\n",
      "132/132 [==============================] - 23s 173ms/step - loss: 2.9937 - accuracy: 0.0541 - val_loss: 2.9960 - val_accuracy: 0.0491\n",
      "Epoch 7/20\n",
      "132/132 [==============================] - 22s 169ms/step - loss: 2.9937 - accuracy: 0.0548 - val_loss: 2.9979 - val_accuracy: 0.0485\n",
      "Epoch 8/20\n",
      "132/132 [==============================] - 23s 173ms/step - loss: 2.9925 - accuracy: 0.0583 - val_loss: 2.9971 - val_accuracy: 0.0513\n",
      "Epoch 9/20\n",
      "132/132 [==============================] - 23s 175ms/step - loss: 2.9923 - accuracy: 0.0571 - val_loss: 2.9966 - val_accuracy: 0.0502\n",
      "Epoch 10/20\n",
      "132/132 [==============================] - 23s 172ms/step - loss: 2.9917 - accuracy: 0.0575 - val_loss: 2.9973 - val_accuracy: 0.0476\n",
      "Epoch 11/20\n",
      "132/132 [==============================] - 22s 169ms/step - loss: 2.9908 - accuracy: 0.0599 - val_loss: 2.9978 - val_accuracy: 0.0520\n",
      "Epoch 12/20\n",
      "132/132 [==============================] - 23s 176ms/step - loss: 2.9909 - accuracy: 0.0600 - val_loss: 2.9989 - val_accuracy: 0.0485\n",
      "Epoch 13/20\n",
      "132/132 [==============================] - 23s 173ms/step - loss: 2.9888 - accuracy: 0.0615 - val_loss: 2.9996 - val_accuracy: 0.0537\n",
      "Epoch 14/20\n",
      "132/132 [==============================] - 22s 166ms/step - loss: 2.9876 - accuracy: 0.0596 - val_loss: 3.0004 - val_accuracy: 0.0517\n",
      "Epoch 15/20\n",
      "132/132 [==============================] - 23s 173ms/step - loss: 2.9874 - accuracy: 0.0606 - val_loss: 3.0011 - val_accuracy: 0.0487\n",
      "Epoch 16/20\n",
      "132/132 [==============================] - 23s 171ms/step - loss: 2.9856 - accuracy: 0.0630 - val_loss: 3.0020 - val_accuracy: 0.0474\n",
      "Epoch 17/20\n",
      "132/132 [==============================] - 22s 167ms/step - loss: 2.9831 - accuracy: 0.0644 - val_loss: 3.0076 - val_accuracy: 0.0422\n",
      "Epoch 18/20\n",
      "132/132 [==============================] - 23s 172ms/step - loss: 2.9820 - accuracy: 0.0645 - val_loss: 3.0037 - val_accuracy: 0.0485\n",
      "Epoch 19/20\n",
      "132/132 [==============================] - 23s 173ms/step - loss: 2.9799 - accuracy: 0.0688 - val_loss: 3.0031 - val_accuracy: 0.0481\n",
      "Epoch 20/20\n",
      "132/132 [==============================] - 22s 167ms/step - loss: 2.9788 - accuracy: 0.0663 - val_loss: 3.0093 - val_accuracy: 0.0476\n"
     ]
    }
   ],
   "source": [
    "# learning_rate = 0.001\n",
    "lstm.fit(X_train, y_train, batch_size=256, epochs=20, validation_data=(X_val, y_val),\n",
    "         callbacks=[early_stopping]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "uGqUp_Xbl-xr",
   "metadata": {
    "id": "uGqUp_Xbl-xr"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "HOYfvdkNpcNx",
   "metadata": {
    "id": "HOYfvdkNpcNx"
   },
   "source": [
    "## RNN - 3 Bidirections with Dense and Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4EtTgzV_pcNy",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-04T15:26:16.627154Z",
     "start_time": "2023-07-04T15:24:51.238295Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1839,
     "status": "ok",
     "timestamp": 1688654841399,
     "user": {
      "displayName": "Yoni Krichevsky",
      "userId": "07735752940575548299"
     },
     "user_tz": -180
    },
    "id": "4EtTgzV_pcNy",
    "outputId": "20360374-0047-4df9-ab3f-a63cdb4e4987"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bidirectional_17 (Bidirecti  (None, 32, 256)          152576    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " bidirectional_18 (Bidirecti  (None, 32, 256)          394240    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " bidirectional_19 (Bidirecti  (None, 256)              394240    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 100)               25700     \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 100)               0         \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 20)                2020      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 968,776\n",
      "Trainable params: 968,776\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "lstm = Sequential([Bidirectional(LSTM(128, return_sequences=True, dropout=.2), input_shape=(32, 20)),\n",
    "                   Bidirectional(LSTM(128, return_sequences=True, dropout=.2)),\n",
    "                   Bidirectional(LSTM(128, dropout=.2)),\n",
    "                   Dense(100, activation='sigmoid'),\n",
    "                   Dropout(.2),\n",
    "                   Dense(20, activation='softmax')]\n",
    "                  )\n",
    "lstm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "TVi85O6wpcNz",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1688654841400,
     "user": {
      "displayName": "Yoni Krichevsky",
      "userId": "07735752940575548299"
     },
     "user_tz": -180
    },
    "id": "TVi85O6wpcNz",
    "outputId": "4c4c61f1-6f0e-4505-e79d-dcc7fcecaeea"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((None, 32, 20), (None, 20))"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm.input_shape, lstm.output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cG23XfqjpcN0",
   "metadata": {
    "id": "cG23XfqjpcN0"
   },
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='loss', patience=4, min_delta=.001)\n",
    "early_stopping_val = EarlyStopping(monitor='val_loss', patience=4, min_delta=.001)\n",
    "callbacks = [early_stopping, early_stopping_val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "r7O9pTV9pcN0",
   "metadata": {
    "id": "r7O9pTV9pcN0"
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "\n",
    "lstm.compile(optimizer=Adam(learning_rate=learning_rate),\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "y5gs8TsUpcN0",
   "metadata": {
    "id": "y5gs8TsUpcN0"
   },
   "outputs": [],
   "source": [
    "tf.config.run_functions_eagerly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "YjGs995kpcN1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 191492,
     "status": "ok",
     "timestamp": 1688655036846,
     "user": {
      "displayName": "Yoni Krichevsky",
      "userId": "07735752940575548299"
     },
     "user_tz": -180
    },
    "id": "YjGs995kpcN1",
    "outputId": "e2bb0cac-4ae8-4702-d1f6-9d3047a3d36b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "132/132 [==============================] - 24s 179ms/step - loss: 3.0135 - accuracy: 0.0487 - val_loss: 2.9962 - val_accuracy: 0.0507\n",
      "Epoch 2/20\n",
      "132/132 [==============================] - 25s 188ms/step - loss: 2.9970 - accuracy: 0.0482 - val_loss: 2.9959 - val_accuracy: 0.0465\n",
      "Epoch 3/20\n",
      "132/132 [==============================] - 24s 180ms/step - loss: 2.9961 - accuracy: 0.0499 - val_loss: 2.9960 - val_accuracy: 0.0517\n",
      "Epoch 4/20\n",
      "132/132 [==============================] - 25s 186ms/step - loss: 2.9959 - accuracy: 0.0494 - val_loss: 2.9957 - val_accuracy: 0.0507\n",
      "Epoch 5/20\n",
      "132/132 [==============================] - 23s 173ms/step - loss: 2.9959 - accuracy: 0.0491 - val_loss: 2.9958 - val_accuracy: 0.0517\n",
      "Epoch 6/20\n",
      "132/132 [==============================] - 24s 180ms/step - loss: 2.9959 - accuracy: 0.0518 - val_loss: 2.9958 - val_accuracy: 0.0517\n",
      "Epoch 7/20\n",
      "132/132 [==============================] - 24s 182ms/step - loss: 2.9958 - accuracy: 0.0516 - val_loss: 2.9958 - val_accuracy: 0.0517\n",
      "Epoch 8/20\n",
      "132/132 [==============================] - 24s 180ms/step - loss: 2.9957 - accuracy: 0.0505 - val_loss: 2.9958 - val_accuracy: 0.0522\n"
     ]
    }
   ],
   "source": [
    "# learning_rate = 0.001\n",
    "lstm.fit(X_train, y_train, batch_size=256, epochs=20, validation_data=(X_val, y_val),\n",
    "         callbacks=[early_stopping]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "s_pS10Jgl-0g",
   "metadata": {
    "id": "s_pS10Jgl-0g"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8dVlf2DXr_EC",
   "metadata": {
    "id": "8dVlf2DXr_EC"
   },
   "source": [
    "## RNN - 3 Bidirection, no dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6HTaiOtcr_ED",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-04T15:26:16.627154Z",
     "start_time": "2023-07-04T15:24:51.238295Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 47840,
     "status": "ok",
     "timestamp": 1688655169992,
     "user": {
      "displayName": "Yoni Krichevsky",
      "userId": "07735752940575548299"
     },
     "user_tz": -180
    },
    "id": "6HTaiOtcr_ED",
    "outputId": "8d38ec30-484f-4886-96aa-d69239324692"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bidirectional_20 (Bidirecti  (None, 32, 256)          152576    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " bidirectional_21 (Bidirecti  (None, 32, 256)          394240    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " bidirectional_22 (Bidirecti  (None, 256)              394240    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_24 (Dense)            (None, 20)                5140      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 946,196\n",
      "Trainable params: 946,196\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "lstm = Sequential([Bidirectional(LSTM(128, return_sequences=True), input_shape=(32, 20)),\n",
    "                   Bidirectional(LSTM(128, return_sequences=True)),\n",
    "                   Bidirectional(LSTM(128)),\n",
    "                  #  Dense(100, activation='sigmoid'),\n",
    "                  #  Dropout(.5),\n",
    "                   Dense(20, activation='softmax')]\n",
    "                  )\n",
    "lstm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1AgjkMnKr_EE",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1688655169992,
     "user": {
      "displayName": "Yoni Krichevsky",
      "userId": "07735752940575548299"
     },
     "user_tz": -180
    },
    "id": "1AgjkMnKr_EE",
    "outputId": "d6e0ccdb-c6b3-489f-bb85-c5e8bb54a55e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((None, 32, 20), (None, 20))"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm.input_shape, lstm.output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5iiBq7-Mr_EE",
   "metadata": {
    "id": "5iiBq7-Mr_EE"
   },
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='loss', patience=4, min_delta=.001)\n",
    "early_stopping_val = EarlyStopping(monitor='val_loss', patience=4, min_delta=.001)\n",
    "callbacks = [early_stopping, early_stopping_val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0frzRHZKr_EE",
   "metadata": {
    "id": "0frzRHZKr_EE"
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "\n",
    "lstm.compile(optimizer=Adam(learning_rate=learning_rate),\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "uw1j_A0Dr_EF",
   "metadata": {
    "id": "uw1j_A0Dr_EF"
   },
   "outputs": [],
   "source": [
    "tf.config.run_functions_eagerly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Xeg5SKo1r_EF",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 442278,
     "status": "ok",
     "timestamp": 1688655612265,
     "user": {
      "displayName": "Yoni Krichevsky",
      "userId": "07735752940575548299"
     },
     "user_tz": -180
    },
    "id": "Xeg5SKo1r_EF",
    "outputId": "756b4f29-890b-4905-a21c-95c9c40d9f06"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "132/132 [==============================] - 21s 158ms/step - loss: 3.0055 - accuracy: 0.0486 - val_loss: 3.0007 - val_accuracy: 0.0528\n",
      "Epoch 2/20\n",
      "132/132 [==============================] - 21s 159ms/step - loss: 2.9981 - accuracy: 0.0521 - val_loss: 3.0005 - val_accuracy: 0.0517\n",
      "Epoch 3/20\n",
      "132/132 [==============================] - 20s 150ms/step - loss: 2.9966 - accuracy: 0.0531 - val_loss: 3.0003 - val_accuracy: 0.0452\n",
      "Epoch 4/20\n",
      "132/132 [==============================] - 21s 160ms/step - loss: 2.9953 - accuracy: 0.0521 - val_loss: 2.9981 - val_accuracy: 0.0483\n",
      "Epoch 5/20\n",
      "132/132 [==============================] - 20s 154ms/step - loss: 2.9942 - accuracy: 0.0556 - val_loss: 2.9979 - val_accuracy: 0.0489\n",
      "Epoch 6/20\n",
      "132/132 [==============================] - 21s 157ms/step - loss: 2.9926 - accuracy: 0.0550 - val_loss: 2.9979 - val_accuracy: 0.0513\n",
      "Epoch 7/20\n",
      "132/132 [==============================] - 20s 151ms/step - loss: 2.9916 - accuracy: 0.0561 - val_loss: 2.9973 - val_accuracy: 0.0530\n",
      "Epoch 8/20\n",
      "132/132 [==============================] - 21s 158ms/step - loss: 2.9897 - accuracy: 0.0588 - val_loss: 3.0031 - val_accuracy: 0.0504\n",
      "Epoch 9/20\n",
      "132/132 [==============================] - 20s 154ms/step - loss: 2.9870 - accuracy: 0.0604 - val_loss: 3.0001 - val_accuracy: 0.0496\n",
      "Epoch 10/20\n",
      "132/132 [==============================] - 21s 162ms/step - loss: 2.9831 - accuracy: 0.0626 - val_loss: 3.0051 - val_accuracy: 0.0500\n",
      "Epoch 11/20\n",
      "132/132 [==============================] - 20s 153ms/step - loss: 2.9802 - accuracy: 0.0634 - val_loss: 3.0064 - val_accuracy: 0.0522\n",
      "Epoch 12/20\n",
      "132/132 [==============================] - 21s 160ms/step - loss: 2.9738 - accuracy: 0.0683 - val_loss: 3.0067 - val_accuracy: 0.0520\n",
      "Epoch 13/20\n",
      "132/132 [==============================] - 20s 155ms/step - loss: 2.9680 - accuracy: 0.0678 - val_loss: 3.0132 - val_accuracy: 0.0530\n",
      "Epoch 14/20\n",
      "132/132 [==============================] - 21s 156ms/step - loss: 2.9596 - accuracy: 0.0731 - val_loss: 3.0174 - val_accuracy: 0.0457\n",
      "Epoch 15/20\n",
      "132/132 [==============================] - 20s 154ms/step - loss: 2.9479 - accuracy: 0.0772 - val_loss: 3.0215 - val_accuracy: 0.0569\n",
      "Epoch 16/20\n",
      "132/132 [==============================] - 20s 153ms/step - loss: 2.9353 - accuracy: 0.0855 - val_loss: 3.0404 - val_accuracy: 0.0595\n",
      "Epoch 17/20\n",
      "132/132 [==============================] - 21s 157ms/step - loss: 2.9186 - accuracy: 0.0889 - val_loss: 3.0415 - val_accuracy: 0.0543\n",
      "Epoch 18/20\n",
      "132/132 [==============================] - 20s 150ms/step - loss: 2.8950 - accuracy: 0.1002 - val_loss: 3.0649 - val_accuracy: 0.0559\n",
      "Epoch 19/20\n",
      "132/132 [==============================] - 21s 157ms/step - loss: 2.8683 - accuracy: 0.1097 - val_loss: 3.0900 - val_accuracy: 0.0537\n",
      "Epoch 20/20\n",
      "132/132 [==============================] - 20s 153ms/step - loss: 2.8299 - accuracy: 0.1238 - val_loss: 3.0936 - val_accuracy: 0.0520\n"
     ]
    }
   ],
   "source": [
    "# learning_rate = 0.001\n",
    "lstm.fit(X_train, y_train, batch_size=256, epochs=20, validation_data=(X_val, y_val),\n",
    "         callbacks=[early_stopping]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "uMq40cIOr_EF",
   "metadata": {
    "id": "uMq40cIOr_EF"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8R4J2ZmfuZoT",
   "metadata": {
    "id": "8R4J2ZmfuZoT"
   },
   "source": [
    "## RNN - 3 Bidirection, tiny dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "YNbnc-hDuZod",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-04T15:26:16.627154Z",
     "start_time": "2023-07-04T15:24:51.238295Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2131,
     "status": "ok",
     "timestamp": 1688655761820,
     "user": {
      "displayName": "Yoni Krichevsky",
      "userId": "07735752940575548299"
     },
     "user_tz": -180
    },
    "id": "YNbnc-hDuZod",
    "outputId": "f5eb3c21-0271-496a-d7b9-2fbb6c14e0ec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bidirectional_23 (Bidirecti  (None, 32, 256)          152576    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " bidirectional_24 (Bidirecti  (None, 32, 256)          394240    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " bidirectional_25 (Bidirecti  (None, 256)              394240    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 20)                5140      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 946,196\n",
      "Trainable params: 946,196\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "lstm = Sequential([Bidirectional(LSTM(128, return_sequences=True, dropout=.1), input_shape=(32, 20)),\n",
    "                   Bidirectional(LSTM(128, return_sequences=True, dropout=.1)),\n",
    "                   Bidirectional(LSTM(128, dropout=.1)),\n",
    "                  #  Dense(100, activation='sigmoid'),\n",
    "                  #  Dropout(.5),\n",
    "                   Dense(20, activation='softmax')]\n",
    "                  )\n",
    "lstm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "FAB_4fXNuZod",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1688655761820,
     "user": {
      "displayName": "Yoni Krichevsky",
      "userId": "07735752940575548299"
     },
     "user_tz": -180
    },
    "id": "FAB_4fXNuZod",
    "outputId": "a3caab9f-cf1a-498d-8987-75d589aedc08"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((None, 32, 20), (None, 20))"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm.input_shape, lstm.output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cK2HA42vuZoe",
   "metadata": {
    "id": "cK2HA42vuZoe"
   },
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='loss', patience=4, min_delta=.001)\n",
    "early_stopping_val = EarlyStopping(monitor='val_loss', patience=4, min_delta=.001)\n",
    "callbacks = [early_stopping, early_stopping_val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "A7KMout0uZoe",
   "metadata": {
    "id": "A7KMout0uZoe"
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "\n",
    "lstm.compile(optimizer=Adam(learning_rate=learning_rate),\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9h2ARYtauZoe",
   "metadata": {
    "id": "9h2ARYtauZoe"
   },
   "outputs": [],
   "source": [
    "tf.config.run_functions_eagerly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "zRnuNdiRuZoe",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 502150,
     "status": "ok",
     "timestamp": 1688656267660,
     "user": {
      "displayName": "Yoni Krichevsky",
      "userId": "07735752940575548299"
     },
     "user_tz": -180
    },
    "id": "zRnuNdiRuZoe",
    "outputId": "134231f1-e8b7-4186-f5e0-7c9233fc8750"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/structured_function.py:254: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132/132 [==============================] - 23s 173ms/step - loss: 3.0047 - accuracy: 0.0506 - val_loss: 2.9986 - val_accuracy: 0.0463\n",
      "Epoch 2/20\n",
      "132/132 [==============================] - 22s 166ms/step - loss: 2.9971 - accuracy: 0.0529 - val_loss: 2.9975 - val_accuracy: 0.0550\n",
      "Epoch 3/20\n",
      "132/132 [==============================] - 23s 176ms/step - loss: 2.9955 - accuracy: 0.0550 - val_loss: 2.9974 - val_accuracy: 0.0539\n",
      "Epoch 4/20\n",
      "132/132 [==============================] - 23s 176ms/step - loss: 2.9951 - accuracy: 0.0545 - val_loss: 2.9974 - val_accuracy: 0.0509\n",
      "Epoch 5/20\n",
      "132/132 [==============================] - 24s 186ms/step - loss: 2.9945 - accuracy: 0.0526 - val_loss: 2.9967 - val_accuracy: 0.0548\n",
      "Epoch 6/20\n",
      "132/132 [==============================] - 22s 170ms/step - loss: 2.9940 - accuracy: 0.0561 - val_loss: 2.9971 - val_accuracy: 0.0476\n",
      "Epoch 7/20\n",
      "132/132 [==============================] - 23s 176ms/step - loss: 2.9929 - accuracy: 0.0575 - val_loss: 2.9980 - val_accuracy: 0.0515\n",
      "Epoch 8/20\n",
      "132/132 [==============================] - 23s 174ms/step - loss: 2.9925 - accuracy: 0.0574 - val_loss: 2.9977 - val_accuracy: 0.0517\n",
      "Epoch 9/20\n",
      "132/132 [==============================] - 22s 169ms/step - loss: 2.9926 - accuracy: 0.0565 - val_loss: 2.9971 - val_accuracy: 0.0485\n",
      "Epoch 10/20\n",
      "132/132 [==============================] - 23s 175ms/step - loss: 2.9911 - accuracy: 0.0598 - val_loss: 2.9996 - val_accuracy: 0.0520\n",
      "Epoch 11/20\n",
      "132/132 [==============================] - 23s 175ms/step - loss: 2.9901 - accuracy: 0.0568 - val_loss: 2.9986 - val_accuracy: 0.0509\n",
      "Epoch 12/20\n",
      "132/132 [==============================] - 22s 167ms/step - loss: 2.9895 - accuracy: 0.0599 - val_loss: 2.9989 - val_accuracy: 0.0459\n",
      "Epoch 13/20\n",
      "132/132 [==============================] - 23s 173ms/step - loss: 2.9878 - accuracy: 0.0626 - val_loss: 3.0020 - val_accuracy: 0.0502\n",
      "Epoch 14/20\n",
      "132/132 [==============================] - 23s 176ms/step - loss: 2.9862 - accuracy: 0.0628 - val_loss: 3.0043 - val_accuracy: 0.0520\n",
      "Epoch 15/20\n",
      "132/132 [==============================] - 22s 166ms/step - loss: 2.9840 - accuracy: 0.0649 - val_loss: 3.0036 - val_accuracy: 0.0481\n",
      "Epoch 16/20\n",
      "132/132 [==============================] - 23s 171ms/step - loss: 2.9822 - accuracy: 0.0638 - val_loss: 3.0060 - val_accuracy: 0.0541\n",
      "Epoch 17/20\n",
      "132/132 [==============================] - 23s 174ms/step - loss: 2.9796 - accuracy: 0.0688 - val_loss: 3.0123 - val_accuracy: 0.0483\n",
      "Epoch 18/20\n",
      "132/132 [==============================] - 22s 168ms/step - loss: 2.9758 - accuracy: 0.0707 - val_loss: 3.0126 - val_accuracy: 0.0528\n",
      "Epoch 19/20\n",
      "132/132 [==============================] - 26s 196ms/step - loss: 2.9716 - accuracy: 0.0688 - val_loss: 3.0217 - val_accuracy: 0.0543\n",
      "Epoch 20/20\n",
      "132/132 [==============================] - 23s 176ms/step - loss: 2.9675 - accuracy: 0.0727 - val_loss: 3.0278 - val_accuracy: 0.0474\n"
     ]
    }
   ],
   "source": [
    "# learning_rate = 0.001\n",
    "lstm.fit(X_train, y_train, batch_size=256, epochs=20, validation_data=(X_val, y_val),\n",
    "         callbacks=[early_stopping]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "TaLLIruYl-3w",
   "metadata": {
    "id": "TaLLIruYl-3w"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dYXUjpSWwHFO",
   "metadata": {
    "id": "dYXUjpSWwHFO"
   },
   "source": [
    "## RNN - 3 Bidirection, tiny dropout + Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9QPni2dgwHFP",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-04T15:26:16.627154Z",
     "start_time": "2023-07-04T15:24:51.238295Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2207,
     "status": "ok",
     "timestamp": 1688656269857,
     "user": {
      "displayName": "Yoni Krichevsky",
      "userId": "07735752940575548299"
     },
     "user_tz": -180
    },
    "id": "9QPni2dgwHFP",
    "outputId": "82e536f6-0669-437b-b009-905c9abda7e1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bidirectional_26 (Bidirecti  (None, 32, 256)          152576    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " bidirectional_27 (Bidirecti  (None, 32, 256)          394240    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " bidirectional_28 (Bidirecti  (None, 256)              394240    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, 100)               25700     \n",
      "                                                                 \n",
      " dense_27 (Dense)            (None, 20)                2020      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 968,776\n",
      "Trainable params: 968,776\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "lstm = Sequential([Bidirectional(LSTM(128, return_sequences=True, dropout=.1), input_shape=(32, 20)),\n",
    "                   Bidirectional(LSTM(128, return_sequences=True, dropout=.1)),\n",
    "                   Bidirectional(LSTM(128, dropout=.1)),\n",
    "                   Dense(100, activation='sigmoid'),\n",
    "                  #  Dropout(.5),\n",
    "                   Dense(20, activation='softmax')]\n",
    "                  )\n",
    "lstm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2XCDBNoGwHFP",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1688656269857,
     "user": {
      "displayName": "Yoni Krichevsky",
      "userId": "07735752940575548299"
     },
     "user_tz": -180
    },
    "id": "2XCDBNoGwHFP",
    "outputId": "b36f6341-4567-4ba5-bbc3-5df65a11bbb1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((None, 32, 20), (None, 20))"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm.input_shape, lstm.output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "RXpUOWKpwHFP",
   "metadata": {
    "id": "RXpUOWKpwHFP"
   },
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='loss', patience=4, min_delta=.001)\n",
    "early_stopping_val = EarlyStopping(monitor='val_loss', patience=4, min_delta=.001)\n",
    "callbacks = [early_stopping, early_stopping_val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dm7wDXzwHFP",
   "metadata": {
    "id": "1dm7wDXzwHFP"
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "\n",
    "lstm.compile(optimizer=Adam(learning_rate=learning_rate),\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "t4t9MFxWwHFP",
   "metadata": {
    "id": "t4t9MFxWwHFP"
   },
   "outputs": [],
   "source": [
    "tf.config.run_functions_eagerly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "F3qXmqm9wHFP",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 207002,
     "status": "ok",
     "timestamp": 1688656476854,
     "user": {
      "displayName": "Yoni Krichevsky",
      "userId": "07735752940575548299"
     },
     "user_tz": -180
    },
    "id": "F3qXmqm9wHFP",
    "outputId": "55c796f1-6985-40ec-8085-7a0b6a5f150e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "132/132 [==============================] - 23s 175ms/step - loss: 3.0060 - accuracy: 0.0509 - val_loss: 3.0009 - val_accuracy: 0.0509\n",
      "Epoch 2/20\n",
      "132/132 [==============================] - 23s 173ms/step - loss: 3.0005 - accuracy: 0.0496 - val_loss: 2.9989 - val_accuracy: 0.0500\n",
      "Epoch 3/20\n",
      "132/132 [==============================] - 23s 174ms/step - loss: 2.9998 - accuracy: 0.0512 - val_loss: 2.9997 - val_accuracy: 0.0487\n",
      "Epoch 4/20\n",
      "132/132 [==============================] - 23s 175ms/step - loss: 3.0001 - accuracy: 0.0538 - val_loss: 3.0008 - val_accuracy: 0.0478\n",
      "Epoch 5/20\n",
      "132/132 [==============================] - 23s 171ms/step - loss: 2.9983 - accuracy: 0.0530 - val_loss: 2.9993 - val_accuracy: 0.0465\n",
      "Epoch 6/20\n",
      "132/132 [==============================] - 23s 178ms/step - loss: 2.9987 - accuracy: 0.0497 - val_loss: 2.9991 - val_accuracy: 0.0422\n",
      "Epoch 7/20\n",
      "132/132 [==============================] - 23s 177ms/step - loss: 2.9989 - accuracy: 0.0502 - val_loss: 2.9981 - val_accuracy: 0.0481\n",
      "Epoch 8/20\n",
      "132/132 [==============================] - 23s 172ms/step - loss: 2.9981 - accuracy: 0.0518 - val_loss: 2.9974 - val_accuracy: 0.0515\n",
      "Epoch 9/20\n",
      "132/132 [==============================] - 23s 171ms/step - loss: 2.9976 - accuracy: 0.0493 - val_loss: 3.0006 - val_accuracy: 0.0502\n"
     ]
    }
   ],
   "source": [
    "# learning_rate = 0.001\n",
    "lstm.fit(X_train, y_train, batch_size=256, epochs=20, validation_data=(X_val, y_val),\n",
    "         callbacks=[early_stopping]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qzLO-3Sayf1g",
   "metadata": {
    "id": "qzLO-3Sayf1g"
   },
   "source": [
    "## RNN - 3 Bidirection, tiny dropout + Dense, only 13 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Dto88uwdyf1g",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-04T15:26:16.627154Z",
     "start_time": "2023-07-04T15:24:51.238295Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1818,
     "status": "ok",
     "timestamp": 1688656919877,
     "user": {
      "displayName": "Yoni Krichevsky",
      "userId": "07735752940575548299"
     },
     "user_tz": -180
    },
    "id": "Dto88uwdyf1g",
    "outputId": "68bc999a-48a4-4429-ba9f-117282a028c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bidirectional_32 (Bidirecti  (None, 32, 256)          145408    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " bidirectional_33 (Bidirecti  (None, 32, 256)          394240    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " bidirectional_34 (Bidirecti  (None, 256)              394240    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_30 (Dense)            (None, 100)               25700     \n",
      "                                                                 \n",
      " dense_31 (Dense)            (None, 20)                2020      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 961,608\n",
      "Trainable params: 961,608\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "lstm = Sequential([Bidirectional(LSTM(128, return_sequences=True, dropout=.1), input_shape=(32, 13)),\n",
    "                   Bidirectional(LSTM(128, return_sequences=True, dropout=.1)),\n",
    "                   Bidirectional(LSTM(128, dropout=.1)),\n",
    "                   Dense(100, activation='sigmoid'),\n",
    "                  #  Dropout(.5),\n",
    "                   Dense(20, activation='softmax')]\n",
    "                  )\n",
    "lstm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "UXKThagyyf1h",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1688656919877,
     "user": {
      "displayName": "Yoni Krichevsky",
      "userId": "07735752940575548299"
     },
     "user_tz": -180
    },
    "id": "UXKThagyyf1h",
    "outputId": "0254b4ca-d44c-47b4-a357-dfa731d306e1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((None, 32, 13), (None, 20))"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm.input_shape, lstm.output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qUCHmmYWyf1h",
   "metadata": {
    "id": "qUCHmmYWyf1h"
   },
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='loss', patience=4, min_delta=.001)\n",
    "early_stopping_val = EarlyStopping(monitor='val_loss', patience=4, min_delta=.001)\n",
    "callbacks = [early_stopping, early_stopping_val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Np3CJzPzyf1h",
   "metadata": {
    "id": "Np3CJzPzyf1h"
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "\n",
    "lstm.compile(optimizer=Adam(learning_rate=learning_rate),\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0l_vqmrByf1h",
   "metadata": {
    "id": "0l_vqmrByf1h"
   },
   "outputs": [],
   "source": [
    "tf.config.run_functions_eagerly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rTkVtmjUyf1h",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 143654,
     "status": "ok",
     "timestamp": 1688657066267,
     "user": {
      "displayName": "Yoni Krichevsky",
      "userId": "07735752940575548299"
     },
     "user_tz": -180
    },
    "id": "rTkVtmjUyf1h",
    "outputId": "42dc8a1b-85c9-4f17-e97b-fd327fda0afe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "132/132 [==============================] - 23s 176ms/step - loss: 3.0060 - accuracy: 0.0488 - val_loss: 3.0030 - val_accuracy: 0.0478\n",
      "Epoch 2/20\n",
      "132/132 [==============================] - 25s 192ms/step - loss: 3.0002 - accuracy: 0.0515 - val_loss: 3.0011 - val_accuracy: 0.0465\n",
      "Epoch 3/20\n",
      "132/132 [==============================] - 24s 179ms/step - loss: 3.0001 - accuracy: 0.0506 - val_loss: 2.9979 - val_accuracy: 0.0522\n",
      "Epoch 4/20\n",
      "132/132 [==============================] - 24s 179ms/step - loss: 2.9993 - accuracy: 0.0510 - val_loss: 2.9992 - val_accuracy: 0.0522\n",
      "Epoch 5/20\n",
      "132/132 [==============================] - 23s 174ms/step - loss: 2.9996 - accuracy: 0.0494 - val_loss: 2.9986 - val_accuracy: 0.0535\n",
      "Epoch 6/20\n",
      "132/132 [==============================] - 24s 185ms/step - loss: 2.9997 - accuracy: 0.0487 - val_loss: 2.9991 - val_accuracy: 0.0487\n"
     ]
    }
   ],
   "source": [
    "# learning_rate = 0.001\n",
    "lstm.fit(X_train[:,:,:13], y_train, batch_size=256, epochs=20, validation_data=(X_val[:,:,:13], y_val),\n",
    "         callbacks=[early_stopping]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "v7de6-H91-56",
   "metadata": {
    "id": "v7de6-H91-56"
   },
   "source": [
    "## RNN - 3 Bidirection, no dropout + Dense, only 13 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loSGuDYA1-6D",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-04T15:26:16.627154Z",
     "start_time": "2023-07-04T15:24:51.238295Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 49244,
     "status": "ok",
     "timestamp": 1688657787019,
     "user": {
      "displayName": "Yoni Krichevsky",
      "userId": "07735752940575548299"
     },
     "user_tz": -180
    },
    "id": "loSGuDYA1-6D",
    "outputId": "8faa7684-1c89-4bfa-db50-fea55f1fcdb0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_20\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bidirectional_35 (Bidirecti  (None, 32, 256)          145408    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " bidirectional_36 (Bidirecti  (None, 32, 256)          394240    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " bidirectional_37 (Bidirecti  (None, 256)              394240    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_32 (Dense)            (None, 100)               25700     \n",
      "                                                                 \n",
      " dense_33 (Dense)            (None, 20)                2020      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 961,608\n",
      "Trainable params: 961,608\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "lstm = Sequential([Bidirectional(LSTM(128, return_sequences=True), input_shape=(32, 13)),\n",
    "                   Bidirectional(LSTM(128, return_sequences=True)),\n",
    "                   Bidirectional(LSTM(128)),\n",
    "                   Dense(100, activation='sigmoid'),\n",
    "                  #  Dropout(.5),\n",
    "                   Dense(20, activation='softmax')]\n",
    "                  )\n",
    "lstm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "JWXxuW4W1-6E",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 326,
     "status": "ok",
     "timestamp": 1688657807820,
     "user": {
      "displayName": "Yoni Krichevsky",
      "userId": "07735752940575548299"
     },
     "user_tz": -180
    },
    "id": "JWXxuW4W1-6E",
    "outputId": "ae52eaca-56fc-4cec-f7fd-c32e43a8dd6e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((None, 32, 13), (None, 20))"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm.input_shape, lstm.output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "RjKZeR6_1-6E",
   "metadata": {
    "id": "RjKZeR6_1-6E"
   },
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='loss', patience=4, min_delta=.001)\n",
    "early_stopping_val = EarlyStopping(monitor='val_loss', patience=4, min_delta=.001)\n",
    "callbacks = [early_stopping, early_stopping_val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "oUz9egaF1-6E",
   "metadata": {
    "id": "oUz9egaF1-6E"
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "\n",
    "lstm.compile(optimizer=Adam(learning_rate=learning_rate),\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9JAb5SXW1-6E",
   "metadata": {
    "id": "9JAb5SXW1-6E"
   },
   "outputs": [],
   "source": [
    "tf.config.run_functions_eagerly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dAXEdrbK1-6E",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 441340,
     "status": "ok",
     "timestamp": 1688658255950,
     "user": {
      "displayName": "Yoni Krichevsky",
      "userId": "07735752940575548299"
     },
     "user_tz": -180
    },
    "id": "dAXEdrbK1-6E",
    "outputId": "aa2fc934-a865-4f8b-d267-c941e3229a36"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "132/132 [==============================] - 23s 173ms/step - loss: 3.0071 - accuracy: 0.0510 - val_loss: 3.0010 - val_accuracy: 0.0517\n",
      "Epoch 2/20\n",
      "132/132 [==============================] - 23s 171ms/step - loss: 3.0009 - accuracy: 0.0497 - val_loss: 3.0023 - val_accuracy: 0.0487\n",
      "Epoch 3/20\n",
      "132/132 [==============================] - 22s 163ms/step - loss: 3.0011 - accuracy: 0.0501 - val_loss: 3.0002 - val_accuracy: 0.0487\n",
      "Epoch 4/20\n",
      "132/132 [==============================] - 23s 173ms/step - loss: 2.9995 - accuracy: 0.0488 - val_loss: 3.0020 - val_accuracy: 0.0517\n",
      "Epoch 5/20\n",
      "132/132 [==============================] - 23s 171ms/step - loss: 2.9992 - accuracy: 0.0510 - val_loss: 3.0020 - val_accuracy: 0.0489\n",
      "Epoch 6/20\n",
      "132/132 [==============================] - 22s 165ms/step - loss: 2.9984 - accuracy: 0.0512 - val_loss: 3.0034 - val_accuracy: 0.0507\n",
      "Epoch 7/20\n",
      "132/132 [==============================] - 22s 167ms/step - loss: 2.9985 - accuracy: 0.0504 - val_loss: 2.9993 - val_accuracy: 0.0509\n",
      "Epoch 8/20\n",
      "132/132 [==============================] - 22s 168ms/step - loss: 2.9975 - accuracy: 0.0506 - val_loss: 3.0009 - val_accuracy: 0.0483\n",
      "Epoch 9/20\n",
      "132/132 [==============================] - 22s 165ms/step - loss: 2.9967 - accuracy: 0.0545 - val_loss: 3.0008 - val_accuracy: 0.0502\n",
      "Epoch 10/20\n",
      "132/132 [==============================] - 22s 167ms/step - loss: 2.9963 - accuracy: 0.0531 - val_loss: 3.0008 - val_accuracy: 0.0478\n",
      "Epoch 11/20\n",
      "132/132 [==============================] - 21s 162ms/step - loss: 2.9964 - accuracy: 0.0560 - val_loss: 2.9994 - val_accuracy: 0.0491\n",
      "Epoch 12/20\n",
      "132/132 [==============================] - 22s 166ms/step - loss: 2.9959 - accuracy: 0.0543 - val_loss: 2.9988 - val_accuracy: 0.0481\n",
      "Epoch 13/20\n",
      "132/132 [==============================] - 23s 171ms/step - loss: 2.9943 - accuracy: 0.0554 - val_loss: 3.0006 - val_accuracy: 0.0515\n",
      "Epoch 14/20\n",
      "132/132 [==============================] - 22s 163ms/step - loss: 2.9937 - accuracy: 0.0564 - val_loss: 2.9990 - val_accuracy: 0.0543\n",
      "Epoch 15/20\n",
      "132/132 [==============================] - 22s 167ms/step - loss: 2.9935 - accuracy: 0.0542 - val_loss: 3.0028 - val_accuracy: 0.0507\n",
      "Epoch 16/20\n",
      "132/132 [==============================] - 22s 167ms/step - loss: 2.9921 - accuracy: 0.0582 - val_loss: 3.0008 - val_accuracy: 0.0450\n",
      "Epoch 17/20\n",
      "132/132 [==============================] - 21s 161ms/step - loss: 2.9913 - accuracy: 0.0583 - val_loss: 3.0005 - val_accuracy: 0.0509\n",
      "Epoch 18/20\n",
      "132/132 [==============================] - 22s 170ms/step - loss: 2.9905 - accuracy: 0.0590 - val_loss: 2.9990 - val_accuracy: 0.0500\n",
      "Epoch 19/20\n",
      "132/132 [==============================] - 21s 162ms/step - loss: 2.9884 - accuracy: 0.0594 - val_loss: 3.0001 - val_accuracy: 0.0494\n",
      "Epoch 20/20\n",
      "132/132 [==============================] - 22s 167ms/step - loss: 2.9878 - accuracy: 0.0608 - val_loss: 2.9994 - val_accuracy: 0.0461\n"
     ]
    }
   ],
   "source": [
    "# learning_rate = 0.001\n",
    "lstm.fit(X_train[:,:,:13], y_train, batch_size=256, epochs=20, validation_data=(X_val[:,:,:13], y_val),\n",
    "         callbacks=[early_stopping]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Ak1TZfUm4Pra",
   "metadata": {
    "id": "Ak1TZfUm4Pra"
   },
   "outputs": [],
   "source": [
    "# learning_rate = 0.002\n",
    "lstm.fit(X_train[:,:,:13], y_train, batch_size=256, epochs=20, validation_data=(X_val[:,:,:13], y_val),\n",
    "         callbacks=[early_stopping]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "AX3XivYy4TCP",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 639
    },
    "executionInfo": {
     "elapsed": 144073,
     "status": "error",
     "timestamp": 1688658475711,
     "user": {
      "displayName": "Yoni Krichevsky",
      "userId": "07735752940575548299"
     },
     "user_tz": -180
    },
    "id": "AX3XivYy4TCP",
    "outputId": "ab84e382-fe60-4c2f-b45e-3f8c52fe5b51"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "132/132 [==============================] - 23s 171ms/step - loss: 2.9902 - accuracy: 0.0570 - val_loss: 3.0032 - val_accuracy: 0.0515\n",
      "Epoch 2/20\n",
      "132/132 [==============================] - 21s 161ms/step - loss: 2.9899 - accuracy: 0.0605 - val_loss: 3.0038 - val_accuracy: 0.0522\n",
      "Epoch 3/20\n",
      "132/132 [==============================] - 21s 163ms/step - loss: 2.9897 - accuracy: 0.0586 - val_loss: 2.9976 - val_accuracy: 0.0487\n",
      "Epoch 4/20\n",
      "132/132 [==============================] - 22s 165ms/step - loss: 2.9878 - accuracy: 0.0604 - val_loss: 2.9984 - val_accuracy: 0.0461\n",
      "Epoch 5/20\n",
      "132/132 [==============================] - 21s 159ms/step - loss: 2.9866 - accuracy: 0.0603 - val_loss: 3.0041 - val_accuracy: 0.0517\n",
      "Epoch 6/20\n",
      "132/132 [==============================] - 21s 162ms/step - loss: 2.9845 - accuracy: 0.0642 - val_loss: 3.0025 - val_accuracy: 0.0533\n",
      "Epoch 7/20\n",
      " 93/132 [====================>.........] - ETA: 5s - loss: 2.9827 - accuracy: 0.0635"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-175-142f4fd8e78f>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# learning_rate = 0.002\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m lstm.fit(X_train[:,:,:13], y_train, batch_size=256, epochs=20, validation_data=(X_val[:,:,:13], y_val),\n\u001b[0m\u001b[1;32m      3\u001b[0m          callbacks=[early_stopping]);\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1683\u001b[0m                         ):\n\u001b[1;32m   1684\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1685\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1686\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1687\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m   1282\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1283\u001b[0m                 \u001b[0;34m\"\"\"Runs a training execution with a single step.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1284\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mstep_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1286\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_eagerly\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mstep_function\u001b[0;34m(model, iterator)\u001b[0m\n\u001b[1;32m   1266\u001b[0m                 )\n\u001b[1;32m   1267\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1268\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute_strategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1269\u001b[0m             outputs = reduce_per_replica(\n\u001b[1;32m   1270\u001b[0m                 \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   1314\u001b[0m       fn = autograph.tf_convert(\n\u001b[1;32m   1315\u001b[0m           fn, autograph_ctx.control_status_ctx(), convert_by_default=False)\n\u001b[0;32m-> 1316\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extended\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mcall_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   2893\u001b[0m       \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2894\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2895\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2897\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36m_call_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   3694\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3695\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mReplicaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplica_id_in_sync_group\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3696\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3697\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3698\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_reduce_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdestinations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    593\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    594\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mControlStatusCtx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUNSPECIFIED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 595\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    596\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mismethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mrun_step\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m   1247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1248\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mrun_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1249\u001b[0;31m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1250\u001b[0m                 \u001b[0;31m# Ensure counter is updated only if `train_step` succeeds.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1251\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_minimum_control_deps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1052\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_target_and_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0;31m# Run backwards pass.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1054\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1055\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1056\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/optimizers/optimizer.py\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(self, loss, var_list, tape)\u001b[0m\n\u001b[1;32m    540\u001b[0m           \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m         \"\"\"\n\u001b[0;32m--> 542\u001b[0;31m         \u001b[0mgrads_and_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/optimizers/optimizer.py\u001b[0m in \u001b[0;36mcompute_gradients\u001b[0;34m(self, loss, var_list, tape)\u001b[0m\n\u001b[1;32m    273\u001b[0m                     \u001b[0mvar_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvar_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 275\u001b[0;31m         \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    276\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[0;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[1;32m   1061\u001b[0m                           for x in output_gradients]\n\u001b[1;32m   1062\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1063\u001b[0;31m     flat_grad = imperative_grad.imperative_grad(\n\u001b[0m\u001b[1;32m   1064\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1065\u001b[0m         \u001b[0mflat_targets\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/imperative_grad.py\u001b[0m in \u001b[0;36mimperative_grad\u001b[0;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[1;32m     65\u001b[0m         \"Unknown value for unconnected_gradients: %r\" % unconnected_gradients)\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m   return pywrap_tfe.TFE_Py_TapeGradient(\n\u001b[0m\u001b[1;32m     68\u001b[0m       \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tape\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36m_gradient_function\u001b[0;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices, forward_pass_name_scope)\u001b[0m\n\u001b[1;32m    144\u001b[0m       \u001b[0mgradient_name_scope\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mforward_pass_name_scope\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradient_name_scope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/cudnn_rnn_grad.py\u001b[0m in \u001b[0;36m_cudnn_rnn_backward\u001b[0;34m(op, *grads)\u001b[0m\n\u001b[1;32m     24\u001b[0m     raise ValueError(\n\u001b[1;32m     25\u001b[0m         \"To use CudnnRNN in gradients, is_training must be set to True.\")\n\u001b[0;32m---> 26\u001b[0;31m   return gen_cudnn_rnn_ops.cudnn_rnn_backprop(\n\u001b[0m\u001b[1;32m     27\u001b[0m       \u001b[0minput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m       \u001b[0minput_h\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/gen_cudnn_rnn_ops.py\u001b[0m in \u001b[0;36mcudnn_rnn_backprop\u001b[0;34m(input, input_h, input_c, params, output, output_h, output_c, output_backprop, output_h_backprop, output_c_backprop, reserve_space, rnn_mode, input_mode, direction, dropout, seed, seed2, name)\u001b[0m\n\u001b[1;32m    264\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0m\u001b[1;32m    267\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"CudnnRNNBackprop\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_c\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_c\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_backprop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_h_backprop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# learning_rate = 0.002\n",
    "lstm.fit(X_train[:,:,:13], y_train, batch_size=256, epochs=20, validation_data=(X_val[:,:,:13], y_val),\n",
    "         callbacks=[early_stopping]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1J3f06dV4_-H",
   "metadata": {
    "id": "1J3f06dV4_-H"
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.003\n",
    "\n",
    "lstm.compile(optimizer=Adam(learning_rate=learning_rate),\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bMdfjCK4_R3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 429856,
     "status": "ok",
     "timestamp": 1688658956949,
     "user": {
      "displayName": "Yoni Krichevsky",
      "userId": "07735752940575548299"
     },
     "user_tz": -180
    },
    "id": "4bMdfjCK4_R3",
    "outputId": "06ea9f5c-329f-47c6-83c8-3f78f7e81f55"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/structured_function.py:254: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132/132 [==============================] - 22s 164ms/step - loss: 2.9852 - accuracy: 0.0604 - val_loss: 2.9999 - val_accuracy: 0.0515\n",
      "Epoch 2/20\n",
      "132/132 [==============================] - 23s 173ms/step - loss: 2.9853 - accuracy: 0.0586 - val_loss: 2.9992 - val_accuracy: 0.0513\n",
      "Epoch 3/20\n",
      "132/132 [==============================] - 21s 161ms/step - loss: 2.9862 - accuracy: 0.0615 - val_loss: 3.0023 - val_accuracy: 0.0554\n",
      "Epoch 4/20\n",
      "132/132 [==============================] - 23s 172ms/step - loss: 2.9829 - accuracy: 0.0614 - val_loss: 3.0048 - val_accuracy: 0.0582\n",
      "Epoch 5/20\n",
      "132/132 [==============================] - 21s 158ms/step - loss: 2.9845 - accuracy: 0.0606 - val_loss: 3.0008 - val_accuracy: 0.0539\n",
      "Epoch 6/20\n",
      "132/132 [==============================] - 22s 166ms/step - loss: 2.9803 - accuracy: 0.0627 - val_loss: 3.0051 - val_accuracy: 0.0507\n",
      "Epoch 7/20\n",
      "132/132 [==============================] - 21s 159ms/step - loss: 2.9795 - accuracy: 0.0623 - val_loss: 3.0124 - val_accuracy: 0.0459\n",
      "Epoch 8/20\n",
      "132/132 [==============================] - 22s 166ms/step - loss: 2.9759 - accuracy: 0.0651 - val_loss: 3.0113 - val_accuracy: 0.0494\n",
      "Epoch 9/20\n",
      "132/132 [==============================] - 22s 165ms/step - loss: 2.9742 - accuracy: 0.0648 - val_loss: 3.0082 - val_accuracy: 0.0498\n",
      "Epoch 10/20\n",
      "132/132 [==============================] - 21s 158ms/step - loss: 2.9708 - accuracy: 0.0683 - val_loss: 3.0118 - val_accuracy: 0.0504\n",
      "Epoch 11/20\n",
      "132/132 [==============================] - 21s 162ms/step - loss: 2.9658 - accuracy: 0.0678 - val_loss: 3.0243 - val_accuracy: 0.0448\n",
      "Epoch 12/20\n",
      "132/132 [==============================] - 21s 159ms/step - loss: 2.9632 - accuracy: 0.0705 - val_loss: 3.0290 - val_accuracy: 0.0509\n",
      "Epoch 13/20\n",
      "132/132 [==============================] - 21s 160ms/step - loss: 2.9586 - accuracy: 0.0742 - val_loss: 3.0275 - val_accuracy: 0.0468\n",
      "Epoch 14/20\n",
      "132/132 [==============================] - 22s 164ms/step - loss: 2.9568 - accuracy: 0.0735 - val_loss: 3.0221 - val_accuracy: 0.0524\n",
      "Epoch 15/20\n",
      "132/132 [==============================] - 21s 159ms/step - loss: 2.9498 - accuracy: 0.0746 - val_loss: 3.0221 - val_accuracy: 0.0476\n",
      "Epoch 16/20\n",
      "132/132 [==============================] - 22s 166ms/step - loss: 2.9475 - accuracy: 0.0755 - val_loss: 3.0274 - val_accuracy: 0.0483\n",
      "Epoch 17/20\n",
      "132/132 [==============================] - 21s 159ms/step - loss: 2.9391 - accuracy: 0.0803 - val_loss: 3.0268 - val_accuracy: 0.0472\n",
      "Epoch 18/20\n",
      "132/132 [==============================] - 21s 161ms/step - loss: 2.9352 - accuracy: 0.0806 - val_loss: 3.0327 - val_accuracy: 0.0437\n",
      "Epoch 19/20\n",
      "132/132 [==============================] - 22s 164ms/step - loss: 2.9249 - accuracy: 0.0849 - val_loss: 3.0501 - val_accuracy: 0.0457\n",
      "Epoch 20/20\n",
      "132/132 [==============================] - 21s 157ms/step - loss: 2.9112 - accuracy: 0.0917 - val_loss: 3.0617 - val_accuracy: 0.0463\n"
     ]
    }
   ],
   "source": [
    "# learning_rate = 0.003\n",
    "lstm.fit(X_train[:,:,:13], y_train, batch_size=256, epochs=20, validation_data=(X_val[:,:,:13], y_val),\n",
    "         callbacks=[early_stopping]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hqsInbaK60xj",
   "metadata": {
    "id": "hqsInbaK60xj"
   },
   "source": [
    "## RNN - 2 Bidirection, only 13 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "P6GVKSY860xr",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-04T15:26:16.627154Z",
     "start_time": "2023-07-04T15:24:51.238295Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1566,
     "status": "ok",
     "timestamp": 1688659123674,
     "user": {
      "displayName": "Yoni Krichevsky",
      "userId": "07735752940575548299"
     },
     "user_tz": -180
    },
    "id": "P6GVKSY860xr",
    "outputId": "1cb9c950-cf3a-44d0-8a8f-23373fba4db9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_22\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bidirectional_40 (Bidirecti  (None, 32, 256)          145408    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " bidirectional_41 (Bidirecti  (None, 256)              394240    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_35 (Dense)            (None, 20)                5140      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 544,788\n",
      "Trainable params: 544,788\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "lstm = Sequential([Bidirectional(LSTM(128, return_sequences=True), input_shape=(32, 13)),\n",
    "                   Bidirectional(LSTM(128)),\n",
    "                  #  Bidirectional(LSTM(128)),\n",
    "                  #  Dense(100, activation='sigmoid'),\n",
    "                  #  Dropout(.5),\n",
    "                   Dense(20, activation='softmax')]\n",
    "                  )\n",
    "lstm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "IEfnifAD60xr",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1688659123674,
     "user": {
      "displayName": "Yoni Krichevsky",
      "userId": "07735752940575548299"
     },
     "user_tz": -180
    },
    "id": "IEfnifAD60xr",
    "outputId": "b28a0633-f098-479e-d056-c44294c3d87a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((None, 32, 13), (None, 20))"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm.input_shape, lstm.output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "AqU3Pvaj60xr",
   "metadata": {
    "id": "AqU3Pvaj60xr"
   },
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='loss', patience=4, min_delta=.001)\n",
    "early_stopping_val = EarlyStopping(monitor='val_loss', patience=4, min_delta=.001)\n",
    "callbacks = [early_stopping, early_stopping_val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pqJr_OgV60xs",
   "metadata": {
    "id": "pqJr_OgV60xs"
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "\n",
    "lstm.compile(optimizer=Adam(learning_rate=learning_rate),\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tpT2tQNL60xs",
   "metadata": {
    "id": "tpT2tQNL60xs"
   },
   "outputs": [],
   "source": [
    "tf.config.run_functions_eagerly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gCbVPoMX60xs",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 322457,
     "status": "ok",
     "timestamp": 1688659447198,
     "user": {
      "displayName": "Yoni Krichevsky",
      "userId": "07735752940575548299"
     },
     "user_tz": -180
    },
    "id": "gCbVPoMX60xs",
    "outputId": "93f0f07e-a901-40a3-a7f2-2b4d51dfe6dc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "132/132 [==============================] - 15s 111ms/step - loss: 3.0084 - accuracy: 0.0486 - val_loss: 2.9999 - val_accuracy: 0.0509\n",
      "Epoch 2/20\n",
      "132/132 [==============================] - 15s 115ms/step - loss: 2.9982 - accuracy: 0.0530 - val_loss: 3.0005 - val_accuracy: 0.0522\n",
      "Epoch 3/20\n",
      "132/132 [==============================] - 15s 114ms/step - loss: 2.9965 - accuracy: 0.0531 - val_loss: 3.0001 - val_accuracy: 0.0522\n",
      "Epoch 4/20\n",
      "132/132 [==============================] - 16s 124ms/step - loss: 2.9947 - accuracy: 0.0557 - val_loss: 3.0001 - val_accuracy: 0.0459\n",
      "Epoch 5/20\n",
      "132/132 [==============================] - 15s 111ms/step - loss: 2.9931 - accuracy: 0.0573 - val_loss: 3.0033 - val_accuracy: 0.0478\n",
      "Epoch 6/20\n",
      "132/132 [==============================] - 15s 114ms/step - loss: 2.9924 - accuracy: 0.0583 - val_loss: 2.9998 - val_accuracy: 0.0507\n",
      "Epoch 7/20\n",
      "132/132 [==============================] - 15s 110ms/step - loss: 2.9895 - accuracy: 0.0584 - val_loss: 3.0002 - val_accuracy: 0.0463\n",
      "Epoch 8/20\n",
      "132/132 [==============================] - 14s 109ms/step - loss: 2.9871 - accuracy: 0.0613 - val_loss: 3.0035 - val_accuracy: 0.0504\n",
      "Epoch 9/20\n",
      "132/132 [==============================] - 15s 114ms/step - loss: 2.9846 - accuracy: 0.0638 - val_loss: 3.0062 - val_accuracy: 0.0513\n",
      "Epoch 10/20\n",
      "132/132 [==============================] - 15s 114ms/step - loss: 2.9807 - accuracy: 0.0651 - val_loss: 3.0073 - val_accuracy: 0.0507\n",
      "Epoch 11/20\n",
      "132/132 [==============================] - 15s 114ms/step - loss: 2.9764 - accuracy: 0.0674 - val_loss: 3.0080 - val_accuracy: 0.0461\n",
      "Epoch 12/20\n",
      "132/132 [==============================] - 15s 114ms/step - loss: 2.9716 - accuracy: 0.0717 - val_loss: 3.0123 - val_accuracy: 0.0520\n",
      "Epoch 13/20\n",
      "132/132 [==============================] - 15s 116ms/step - loss: 2.9629 - accuracy: 0.0725 - val_loss: 3.0136 - val_accuracy: 0.0520\n",
      "Epoch 14/20\n",
      "132/132 [==============================] - 15s 114ms/step - loss: 2.9544 - accuracy: 0.0765 - val_loss: 3.0256 - val_accuracy: 0.0442\n",
      "Epoch 15/20\n",
      "132/132 [==============================] - 15s 113ms/step - loss: 2.9413 - accuracy: 0.0801 - val_loss: 3.0235 - val_accuracy: 0.0470\n",
      "Epoch 16/20\n",
      "132/132 [==============================] - 14s 109ms/step - loss: 2.9284 - accuracy: 0.0855 - val_loss: 3.0404 - val_accuracy: 0.0461\n",
      "Epoch 17/20\n",
      "132/132 [==============================] - 15s 110ms/step - loss: 2.9108 - accuracy: 0.0927 - val_loss: 3.0501 - val_accuracy: 0.0494\n",
      "Epoch 18/20\n",
      "132/132 [==============================] - 15s 110ms/step - loss: 2.8900 - accuracy: 0.1029 - val_loss: 3.0733 - val_accuracy: 0.0431\n",
      "Epoch 19/20\n",
      "132/132 [==============================] - 15s 114ms/step - loss: 2.8713 - accuracy: 0.1090 - val_loss: 3.0777 - val_accuracy: 0.0474\n",
      "Epoch 20/20\n",
      "132/132 [==============================] - 15s 110ms/step - loss: 2.8409 - accuracy: 0.1209 - val_loss: 3.0933 - val_accuracy: 0.0491\n"
     ]
    }
   ],
   "source": [
    "# learning_rate = 0.001\n",
    "lstm.fit(X_train[:,:,:13], y_train, batch_size=256, epochs=20, validation_data=(X_val[:,:,:13], y_val),\n",
    "         callbacks=[early_stopping]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "oo7K9Y6lgpNJ",
   "metadata": {
    "id": "oo7K9Y6lgpNJ"
   },
   "source": [
    "## RNN - 2 Bidirection, only 13 features, a bit of dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "T2XMdF9VgpNO",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-04T15:26:16.627154Z",
     "start_time": "2023-07-04T15:24:51.238295Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1698,
     "status": "ok",
     "timestamp": 1688669028514,
     "user": {
      "displayName": "Yoni Krichevsky",
      "userId": "07735752940575548299"
     },
     "user_tz": -180
    },
    "id": "T2XMdF9VgpNO",
    "outputId": "c1bb26c3-0423-4ad5-f534-f8ccc8a90889"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bidirectional (Bidirectiona  (None, 32, 256)          145408    \n",
      " l)                                                              \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirectio  (None, 256)              394240    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dense (Dense)               (None, 20)                5140      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 544,788\n",
      "Trainable params: 544,788\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "lstm = Sequential([Bidirectional(LSTM(128, return_sequences=True, dropout=.1), input_shape=(32, 13)),\n",
    "                   Bidirectional(LSTM(128, dropout=.1)),\n",
    "                  #  Bidirectional(LSTM(128)),\n",
    "                  #  Dense(100, activation='sigmoid'),\n",
    "                  #  Dropout(.5),\n",
    "                   Dense(20, activation='softmax')]\n",
    "                  )\n",
    "lstm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8jSbroh7gpNP",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1688669028515,
     "user": {
      "displayName": "Yoni Krichevsky",
      "userId": "07735752940575548299"
     },
     "user_tz": -180
    },
    "id": "8jSbroh7gpNP",
    "outputId": "7343bf4b-fa20-47e3-d229-422553dd1179"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((None, 32, 13), (None, 20))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm.input_shape, lstm.output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "P3Pn8oR9gpNP",
   "metadata": {
    "id": "P3Pn8oR9gpNP"
   },
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='loss', patience=4, min_delta=.001)\n",
    "early_stopping_val = EarlyStopping(monitor='val_loss', patience=4, min_delta=.001)\n",
    "callbacks = [early_stopping, early_stopping_val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ahyk6ID1gpNP",
   "metadata": {
    "id": "ahyk6ID1gpNP"
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "\n",
    "lstm.compile(optimizer=Adam(learning_rate=learning_rate),\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Vj0V-4HbgpNP",
   "metadata": {
    "id": "Vj0V-4HbgpNP"
   },
   "outputs": [],
   "source": [
    "tf.config.run_functions_eagerly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "w1QO1cy4gpNP",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 936
    },
    "executionInfo": {
     "elapsed": 313958,
     "status": "error",
     "timestamp": 1688671350419,
     "user": {
      "displayName": "Yoni Krichevsky",
      "userId": "07735752940575548299"
     },
     "user_tz": -180
    },
    "id": "w1QO1cy4gpNP",
    "outputId": "447358b6-73c8-4a9c-e4ed-6885332657a9"
   },
   "outputs": [
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/structured_function.py:254: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132/132 [==============================] - 166s 1s/step - loss: 3.0078 - accuracy: 0.0525 - val_loss: 3.0002 - val_accuracy: 0.0457\n",
      "Epoch 2/20\n",
      "132/132 [==============================] - 166s 1s/step - loss: 2.9989 - accuracy: 0.0525 - val_loss: 3.0012 - val_accuracy: 0.0474\n",
      "Epoch 3/20\n",
      "132/132 [==============================] - 168s 1s/step - loss: 2.9972 - accuracy: 0.0544 - val_loss: 3.0005 - val_accuracy: 0.0448\n",
      "Epoch 4/20\n",
      "132/132 [==============================] - 165s 1s/step - loss: 2.9958 - accuracy: 0.0558 - val_loss: 3.0000 - val_accuracy: 0.0489\n",
      "Epoch 5/20\n",
      "132/132 [==============================] - 168s 1s/step - loss: 2.9947 - accuracy: 0.0552 - val_loss: 3.0000 - val_accuracy: 0.0470\n",
      "Epoch 6/20\n",
      "132/132 [==============================] - 165s 1s/step - loss: 2.9943 - accuracy: 0.0531 - val_loss: 2.9981 - val_accuracy: 0.0507\n",
      "Epoch 7/20\n",
      "132/132 [==============================] - 166s 1s/step - loss: 2.9932 - accuracy: 0.0577 - val_loss: 2.9983 - val_accuracy: 0.0530\n",
      "Epoch 8/20\n",
      "132/132 [==============================] - 169s 1s/step - loss: 2.9922 - accuracy: 0.0587 - val_loss: 2.9986 - val_accuracy: 0.0470\n",
      "Epoch 9/20\n",
      "132/132 [==============================] - 169s 1s/step - loss: 2.9919 - accuracy: 0.0597 - val_loss: 3.0004 - val_accuracy: 0.0468\n",
      "Epoch 10/20\n",
      "132/132 [==============================] - 168s 1s/step - loss: 2.9917 - accuracy: 0.0587 - val_loss: 3.0025 - val_accuracy: 0.0452\n",
      "Epoch 11/20\n",
      "132/132 [==============================] - 166s 1s/step - loss: 2.9910 - accuracy: 0.0592 - val_loss: 3.0001 - val_accuracy: 0.0517\n",
      "Epoch 12/20\n",
      "132/132 [==============================] - 166s 1s/step - loss: 2.9897 - accuracy: 0.0595 - val_loss: 3.0009 - val_accuracy: 0.0502\n",
      "Epoch 13/20\n",
      "132/132 [==============================] - 169s 1s/step - loss: 2.9880 - accuracy: 0.0597 - val_loss: 3.0043 - val_accuracy: 0.0461\n",
      "Epoch 14/20\n",
      "121/132 [==========================>...] - ETA: 13s - loss: 2.9883 - accuracy: 0.0614"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-e920722e33d6>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# learning_rate = 0.001\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m lstm.fit(X_train[:,:,:13], y_train, batch_size=256, epochs=20, validation_data=(X_val[:,:,:13], y_val),\n\u001b[0m\u001b[1;32m      3\u001b[0m          callbacks=[early_stopping]);\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1683\u001b[0m                         ):\n\u001b[1;32m   1684\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1685\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1686\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1687\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m   1282\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1283\u001b[0m                 \u001b[0;34m\"\"\"Runs a training execution with a single step.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1284\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mstep_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1286\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_eagerly\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mstep_function\u001b[0;34m(model, iterator)\u001b[0m\n\u001b[1;32m   1266\u001b[0m                 )\n\u001b[1;32m   1267\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1268\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute_strategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1269\u001b[0m             outputs = reduce_per_replica(\n\u001b[1;32m   1270\u001b[0m                 \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   1314\u001b[0m       fn = autograph.tf_convert(\n\u001b[1;32m   1315\u001b[0m           fn, autograph_ctx.control_status_ctx(), convert_by_default=False)\n\u001b[0;32m-> 1316\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extended\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mcall_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   2893\u001b[0m       \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2894\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2895\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2897\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36m_call_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   3694\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3695\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mReplicaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplica_id_in_sync_group\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3696\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3697\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3698\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_reduce_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdestinations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    593\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    594\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mControlStatusCtx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUNSPECIFIED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 595\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    596\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mismethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mrun_step\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m   1247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1248\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mrun_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1249\u001b[0;31m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1250\u001b[0m                 \u001b[0;31m# Ensure counter is updated only if `train_step` succeeds.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1251\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_minimum_control_deps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1048\u001b[0m         \u001b[0;31m# Run forward pass.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1049\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1050\u001b[0;31m             \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1051\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1052\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_target_and_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    556\u001b[0m             \u001b[0mlayout_map_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_subclass_model_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_layout_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 558\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    559\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mdoc_controls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdoc_in_current_and_subclasses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1143\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_dtype_object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1144\u001b[0m                 ):\n\u001b[0;32m-> 1145\u001b[0;31m                     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1147\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0mbound_signature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_keras_call_info_injected\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/sequential.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    410\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_graph_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 412\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    413\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m  \u001b[0;31m# handle the corner case where self.layers is empty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/functional.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    510\u001b[0m             \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0mtensors\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mthere\u001b[0m \u001b[0mare\u001b[0m \u001b[0mmore\u001b[0m \u001b[0mthan\u001b[0m \u001b[0mone\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    511\u001b[0m         \"\"\"\n\u001b[0;32m--> 512\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_internal_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    513\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcompute_output_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/functional.py\u001b[0m in \u001b[0;36m_run_internal_graph\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    667\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_arguments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 669\u001b[0;31m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m                 \u001b[0;31m# Update tensor_dict.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/layers/rnn/bidirectional.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, initial_state, constants, **kwargs)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minitial_state\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconstants\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 279\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m         \u001b[0;31m# Applies the same workaround as in `RNN.__call__`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1143\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_dtype_object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1144\u001b[0m                 ):\n\u001b[0;32m-> 1145\u001b[0;31m                     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1147\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0mbound_signature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_keras_call_info_injected\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/layers/rnn/bidirectional.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training, mask, initial_state, constants)\u001b[0m\n\u001b[1;32m    407\u001b[0m                 \u001b[0mforward_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforward_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m             )\n\u001b[0;32m--> 409\u001b[0;31m             y_rev = self.backward_layer(\n\u001b[0m\u001b[1;32m    410\u001b[0m                 \u001b[0mbackward_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbackward_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m             )\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/layers/rnn/base_rnn.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, initial_state, constants, **kwargs)\u001b[0m\n\u001b[1;32m    554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minitial_state\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconstants\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 556\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    557\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m         \u001b[0;31m# If any of `initial_state` or `constants` are specified and are Keras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1143\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_dtype_object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1144\u001b[0m                 ):\n\u001b[0;32m-> 1145\u001b[0;31m                     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1147\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0mbound_signature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_keras_call_info_injected\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/layers/rnn/lstm.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, mask, training, initial_state)\u001b[0m\n\u001b[1;32m    738\u001b[0m                             \u001b[0mnew_c\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m                             \u001b[0mruntime\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 740\u001b[0;31m                         ) = standard_lstm(**normal_lstm_kwargs)\n\u001b[0m\u001b[1;32m    741\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    742\u001b[0m                     (\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/layers/rnn/lstm.py\u001b[0m in \u001b[0;36mstandard_lstm\u001b[0;34m(inputs, init_h, init_c, kernel, recurrent_kernel, bias, mask, time_major, go_backwards, sequence_lengths, zero_output_for_mask, return_sequences)\u001b[0m\n\u001b[1;32m    978\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 980\u001b[0;31m     last_output, outputs, new_states = backend.rnn(\n\u001b[0m\u001b[1;32m    981\u001b[0m         \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    982\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mop_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1174\u001b[0m       \u001b[0;31m# Fallback dispatch system (dispatch v1):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1175\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1176\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdispatch_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1177\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1178\u001b[0m         \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/backend.py\u001b[0m in \u001b[0;36mrnn\u001b[0;34m(step_function, inputs, initial_states, go_backwards, mask, constants, unroll, input_length, time_major, zero_output_for_mask, return_all_outputs)\u001b[0m\n\u001b[1;32m   5167\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_ta_t\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5169\u001b[0;31m             final_outputs = tf.compat.v1.while_loop(\n\u001b[0m\u001b[1;32m   5170\u001b[0m                 \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_step\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5171\u001b[0m                 \u001b[0mloop_vars\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_ta\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36mwhile_loop\u001b[0;34m(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, name, maximum_iterations, return_same_structure)\u001b[0m\n\u001b[1;32m   2821\u001b[0m                                               list(loop_vars))\n\u001b[1;32m   2822\u001b[0m       \u001b[0;32mwhile\u001b[0m \u001b[0mcond\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mloop_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2823\u001b[0;31m         \u001b[0mloop_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mloop_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2824\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtry_to_pack\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloop_vars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_basetuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2825\u001b[0m           \u001b[0mpacked\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/backend.py\u001b[0m in \u001b[0;36m_step\u001b[0;34m(time, output_ta_t, *states)\u001b[0m\n\u001b[1;32m   5146\u001b[0m                 \u001b[0mcurrent_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mta\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minput_ta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5147\u001b[0m                 \u001b[0mcurrent_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_sequence_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5148\u001b[0;31m                 output, new_states = step_function(\n\u001b[0m\u001b[1;32m   5149\u001b[0m                     \u001b[0mcurrent_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconstants\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5150\u001b[0m                 )\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/layers/rnn/lstm.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(cell_inputs, cell_states)\u001b[0m\n\u001b[1;32m    965\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    966\u001b[0m         \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcell_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 967\u001b[0;31m         \u001b[0mz\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh_tm1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecurrent_kernel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    968\u001b[0m         \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias_add\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    969\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mop_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1174\u001b[0m       \u001b[0;31m# Fallback dispatch system (dispatch v1):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1175\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1176\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdispatch_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1177\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1178\u001b[0m         \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/backend.py\u001b[0m in \u001b[0;36mdot\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m   2462\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse_dense_matmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2463\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2464\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2465\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2466\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mop_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1174\u001b[0m       \u001b[0;31m# Fallback dispatch system (dispatch v1):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1175\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1176\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdispatch_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1177\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1178\u001b[0m         \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mmatmul\u001b[0;34m(a, b, transpose_a, transpose_b, adjoint_a, adjoint_b, a_is_sparse, b_is_sparse, output_type, name)\u001b[0m\n\u001b[1;32m   3764\u001b[0m             a, b, adj_x=adjoint_a, adj_y=adjoint_b, Tout=output_type, name=name)\n\u001b[1;32m   3765\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3766\u001b[0;31m         return gen_math_ops.mat_mul(\n\u001b[0m\u001b[1;32m   3767\u001b[0m             a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)\n\u001b[1;32m   3768\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36mmat_mul\u001b[0;34m(a, b, transpose_a, transpose_b, name)\u001b[0m\n\u001b[1;32m   6011\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6012\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6013\u001b[0;31m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0m\u001b[1;32m   6014\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"MatMul\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"transpose_a\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranspose_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"transpose_b\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6015\u001b[0m         transpose_b)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# learning_rate = 0.001\n",
    "lstm.fit(X_train[:,:,:13], y_train, batch_size=256, epochs=20, validation_data=(X_val[:,:,:13], y_val),\n",
    "         callbacks=[early_stopping]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cGGkycnAppa2",
   "metadata": {
    "id": "cGGkycnAppa2"
   },
   "source": [
    "## RNN - 3 Bidirection, no dropout + Dense, only 13 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90oR_c9ep3YN",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 384,
     "status": "ok",
     "timestamp": 1688674368047,
     "user": {
      "displayName": "Yoni Krichevsky",
      "userId": "07735752940575548299"
     },
     "user_tz": -180
    },
    "id": "90oR_c9ep3YN",
    "outputId": "aded8de5-fa67-4f8b-f6bd-17ae96ed4bcc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52.29702396428691, 173.88891616468194)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MEAN = X_train[:,:,:13].mean()\n",
    "STDEV = np.std(X_train[:,:,:13])\n",
    "MEAN, STDEV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12mnhRIHppa8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-04T15:26:16.627154Z",
     "start_time": "2023-07-04T15:24:51.238295Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1870,
     "status": "ok",
     "timestamp": 1688674432863,
     "user": {
      "displayName": "Yoni Krichevsky",
      "userId": "07735752940575548299"
     },
     "user_tz": -180
    },
    "id": "12mnhRIHppa8",
    "outputId": "a6f3547b-9e4f-4fc1-aadf-73c15db23125"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bidirectional_5 (Bidirectio  (None, 32, 256)          145408    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " bidirectional_6 (Bidirectio  (None, 32, 256)          394240    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " bidirectional_7 (Bidirectio  (None, 256)              394240    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 100)               25700     \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 20)                2020      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 961,608\n",
      "Trainable params: 961,608\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "lstm = Sequential([Bidirectional(LSTM(128, return_sequences=True), input_shape=(32, 13)),\n",
    "                   Bidirectional(LSTM(128, return_sequences=True)),\n",
    "                   Bidirectional(LSTM(128)),\n",
    "                   Dense(100, activation='sigmoid'),\n",
    "                  #  Dropout(.5),\n",
    "                   Dense(20, activation='softmax')]\n",
    "                  )\n",
    "lstm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hmAM_bFkppa8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 465,
     "status": "ok",
     "timestamp": 1688674447200,
     "user": {
      "displayName": "Yoni Krichevsky",
      "userId": "07735752940575548299"
     },
     "user_tz": -180
    },
    "id": "hmAM_bFkppa8",
    "outputId": "d051055d-ddc5-4125-cf97-1c637c80e474"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((None, 32, 13), (None, 20))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm.input_shape, lstm.output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dx-4YiDnppa8",
   "metadata": {
    "id": "dx-4YiDnppa8"
   },
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='loss', patience=4, min_delta=.001)\n",
    "early_stopping_val = EarlyStopping(monitor='val_loss', patience=4, min_delta=.001)\n",
    "callbacks = [early_stopping, early_stopping_val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "KHNTUB-Uppa8",
   "metadata": {
    "id": "KHNTUB-Uppa8"
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.005\n",
    "\n",
    "lstm.compile(optimizer=Adam(learning_rate=learning_rate),\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fvPwQiNJppa8",
   "metadata": {
    "id": "fvPwQiNJppa8"
   },
   "outputs": [],
   "source": [
    "tf.config.run_functions_eagerly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "XLxJiztmppa8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1691478,
     "status": "ok",
     "timestamp": 1688676150070,
     "user": {
      "displayName": "Yoni Krichevsky",
      "userId": "07735752940575548299"
     },
     "user_tz": -180
    },
    "id": "XLxJiztmppa8",
    "outputId": "75e56e9a-ae47-45b4-eb14-0ff7853002fa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/structured_function.py:254: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132/132 [==============================] - 246s 2s/step - loss: 3.0115 - accuracy: 0.0518 - val_loss: 3.0134 - val_accuracy: 0.0465\n",
      "Epoch 2/20\n",
      "132/132 [==============================] - 238s 2s/step - loss: 3.0002 - accuracy: 0.0508 - val_loss: 2.9959 - val_accuracy: 0.0522\n",
      "Epoch 3/20\n",
      "132/132 [==============================] - 237s 2s/step - loss: 2.9962 - accuracy: 0.0482 - val_loss: 2.9963 - val_accuracy: 0.0463\n",
      "Epoch 4/20\n",
      "132/132 [==============================] - 248s 2s/step - loss: 2.9960 - accuracy: 0.0516 - val_loss: 2.9962 - val_accuracy: 0.0517\n",
      "Epoch 5/20\n",
      "132/132 [==============================] - 238s 2s/step - loss: 2.9959 - accuracy: 0.0497 - val_loss: 2.9964 - val_accuracy: 0.0517\n",
      "Epoch 6/20\n",
      "132/132 [==============================] - 238s 2s/step - loss: 2.9959 - accuracy: 0.0498 - val_loss: 2.9965 - val_accuracy: 0.0517\n",
      "Epoch 7/20\n",
      "132/132 [==============================] - 246s 2s/step - loss: 2.9958 - accuracy: 0.0498 - val_loss: 2.9964 - val_accuracy: 0.0465\n"
     ]
    }
   ],
   "source": [
    "# learning_rate = 0.005\n",
    "lstm.fit((X_train[:,:,:13] - MEAN) / STDEV, y_train,\n",
    "         batch_size=256,\n",
    "         epochs=20,\n",
    "         validation_data=((X_val[:,:,:13] - MEAN) / STDEV, y_val),\n",
    "         callbacks=[early_stopping]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "iGQTjK2k9Jdr",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 583
    },
    "executionInfo": {
     "elapsed": 1079177,
     "status": "error",
     "timestamp": 1688677470562,
     "user": {
      "displayName": "Yoni Krichevsky",
      "userId": "07735752940575548299"
     },
     "user_tz": -180
    },
    "id": "iGQTjK2k9Jdr",
    "outputId": "518cdb3a-7565-4c27-c4a0-efeaf628e8bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "132/132 [==============================] - 249s 2s/step - loss: 2.9956 - accuracy: 0.0505 - val_loss: 2.9965 - val_accuracy: 0.0465\n",
      "Epoch 2/20\n",
      "132/132 [==============================] - 247s 2s/step - loss: 2.9955 - accuracy: 0.0504 - val_loss: 2.9966 - val_accuracy: 0.0465\n",
      "Epoch 3/20\n",
      "132/132 [==============================] - 246s 2s/step - loss: 2.9955 - accuracy: 0.0504 - val_loss: 2.9967 - val_accuracy: 0.0517\n",
      "Epoch 4/20\n",
      "132/132 [==============================] - 246s 2s/step - loss: 2.9955 - accuracy: 0.0517 - val_loss: 2.9968 - val_accuracy: 0.0517\n",
      "Epoch 5/20\n",
      " 47/132 [=========>....................] - ETA: 2:25 - loss: 2.9951 - accuracy: 0.0515"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-ee9ac2fdcacf>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m              metrics=['accuracy'])\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m lstm.fit((X_train[:,:,:13] - MEAN) / STDEV, y_train,\n\u001b[0m\u001b[1;32m      8\u001b[0m          \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m          \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1683\u001b[0m                         ):\n\u001b[1;32m   1684\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1685\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1686\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1687\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m   1282\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1283\u001b[0m                 \u001b[0;34m\"\"\"Runs a training execution with a single step.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1284\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mstep_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1286\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_eagerly\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mstep_function\u001b[0;34m(model, iterator)\u001b[0m\n\u001b[1;32m   1266\u001b[0m                 )\n\u001b[1;32m   1267\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1268\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute_strategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1269\u001b[0m             outputs = reduce_per_replica(\n\u001b[1;32m   1270\u001b[0m                 \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   1314\u001b[0m       fn = autograph.tf_convert(\n\u001b[1;32m   1315\u001b[0m           fn, autograph_ctx.control_status_ctx(), convert_by_default=False)\n\u001b[0;32m-> 1316\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extended\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mcall_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   2893\u001b[0m       \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2894\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2895\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2897\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36m_call_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   3694\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3695\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mReplicaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplica_id_in_sync_group\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3696\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3697\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3698\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_reduce_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdestinations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    593\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    594\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mControlStatusCtx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUNSPECIFIED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 595\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    596\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mismethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mrun_step\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m   1247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1248\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mrun_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1249\u001b[0;31m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1250\u001b[0m                 \u001b[0;31m# Ensure counter is updated only if `train_step` succeeds.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1251\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_minimum_control_deps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1048\u001b[0m         \u001b[0;31m# Run forward pass.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1049\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1050\u001b[0;31m             \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1051\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1052\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_target_and_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    556\u001b[0m             \u001b[0mlayout_map_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_subclass_model_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_layout_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 558\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    559\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mdoc_controls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdoc_in_current_and_subclasses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1143\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_dtype_object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1144\u001b[0m                 ):\n\u001b[0;32m-> 1145\u001b[0;31m                     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1147\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0mbound_signature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_keras_call_info_injected\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/sequential.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    410\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_graph_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 412\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    413\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m  \u001b[0;31m# handle the corner case where self.layers is empty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/functional.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    510\u001b[0m             \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0mtensors\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mthere\u001b[0m \u001b[0mare\u001b[0m \u001b[0mmore\u001b[0m \u001b[0mthan\u001b[0m \u001b[0mone\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    511\u001b[0m         \"\"\"\n\u001b[0;32m--> 512\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_internal_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    513\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcompute_output_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/functional.py\u001b[0m in \u001b[0;36m_run_internal_graph\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    667\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_arguments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 669\u001b[0;31m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m                 \u001b[0;31m# Update tensor_dict.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/layers/rnn/bidirectional.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, initial_state, constants, **kwargs)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minitial_state\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconstants\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 279\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m         \u001b[0;31m# Applies the same workaround as in `RNN.__call__`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1143\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_dtype_object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1144\u001b[0m                 ):\n\u001b[0;32m-> 1145\u001b[0;31m                     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1147\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0mbound_signature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_keras_call_info_injected\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/layers/rnn/bidirectional.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training, mask, initial_state, constants)\u001b[0m\n\u001b[1;32m    407\u001b[0m                 \u001b[0mforward_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforward_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m             )\n\u001b[0;32m--> 409\u001b[0;31m             y_rev = self.backward_layer(\n\u001b[0m\u001b[1;32m    410\u001b[0m                 \u001b[0mbackward_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbackward_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m             )\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/layers/rnn/base_rnn.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, initial_state, constants, **kwargs)\u001b[0m\n\u001b[1;32m    554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minitial_state\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconstants\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 556\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    557\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m         \u001b[0;31m# If any of `initial_state` or `constants` are specified and are Keras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1143\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_dtype_object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1144\u001b[0m                 ):\n\u001b[0;32m-> 1145\u001b[0;31m                     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1147\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0mbound_signature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_keras_call_info_injected\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/layers/rnn/lstm.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, mask, training, initial_state)\u001b[0m\n\u001b[1;32m    738\u001b[0m                             \u001b[0mnew_c\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m                             \u001b[0mruntime\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 740\u001b[0;31m                         ) = standard_lstm(**normal_lstm_kwargs)\n\u001b[0m\u001b[1;32m    741\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    742\u001b[0m                     (\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/layers/rnn/lstm.py\u001b[0m in \u001b[0;36mstandard_lstm\u001b[0;34m(inputs, init_h, init_c, kernel, recurrent_kernel, bias, mask, time_major, go_backwards, sequence_lengths, zero_output_for_mask, return_sequences)\u001b[0m\n\u001b[1;32m    978\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 980\u001b[0;31m     last_output, outputs, new_states = backend.rnn(\n\u001b[0m\u001b[1;32m    981\u001b[0m         \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    982\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mop_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1174\u001b[0m       \u001b[0;31m# Fallback dispatch system (dispatch v1):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1175\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1176\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdispatch_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1177\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1178\u001b[0m         \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/backend.py\u001b[0m in \u001b[0;36mrnn\u001b[0;34m(step_function, inputs, initial_states, go_backwards, mask, constants, unroll, input_length, time_major, zero_output_for_mask, return_all_outputs)\u001b[0m\n\u001b[1;32m   5167\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_ta_t\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5169\u001b[0;31m             final_outputs = tf.compat.v1.while_loop(\n\u001b[0m\u001b[1;32m   5170\u001b[0m                 \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_step\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5171\u001b[0m                 \u001b[0mloop_vars\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_ta\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36mwhile_loop\u001b[0;34m(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, name, maximum_iterations, return_same_structure)\u001b[0m\n\u001b[1;32m   2821\u001b[0m                                               list(loop_vars))\n\u001b[1;32m   2822\u001b[0m       \u001b[0;32mwhile\u001b[0m \u001b[0mcond\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mloop_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2823\u001b[0;31m         \u001b[0mloop_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mloop_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2824\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtry_to_pack\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloop_vars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_basetuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2825\u001b[0m           \u001b[0mpacked\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/backend.py\u001b[0m in \u001b[0;36m_step\u001b[0;34m(time, output_ta_t, *states)\u001b[0m\n\u001b[1;32m   5146\u001b[0m                 \u001b[0mcurrent_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mta\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minput_ta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5147\u001b[0m                 \u001b[0mcurrent_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_sequence_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5148\u001b[0;31m                 output, new_states = step_function(\n\u001b[0m\u001b[1;32m   5149\u001b[0m                     \u001b[0mcurrent_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconstants\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5150\u001b[0m                 )\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/layers/rnn/lstm.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(cell_inputs, cell_states)\u001b[0m\n\u001b[1;32m    968\u001b[0m         \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias_add\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    969\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 970\u001b[0;31m         \u001b[0mz0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    971\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    972\u001b[0m         \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mop_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1174\u001b[0m       \u001b[0;31m# Fallback dispatch system (dispatch v1):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1175\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1176\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdispatch_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1177\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1178\u001b[0m         \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36msplit\u001b[0;34m(value, num_or_size_splits, axis, num, name)\u001b[0m\n\u001b[1;32m   2199\u001b[0m   if isinstance(num_or_size_splits,\n\u001b[1;32m   2200\u001b[0m                 (numbers.Integral, tensor_shape.Dimension)):\n\u001b[0;32m-> 2201\u001b[0;31m     return gen_array_ops.split(\n\u001b[0m\u001b[1;32m   2202\u001b[0m         axis=axis, num_split=num_or_size_splits, value=value, name=name)\n\u001b[1;32m   2203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36msplit\u001b[0;34m(axis, value, num_split, name)\u001b[0m\n\u001b[1;32m  10238\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10239\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m> 10240\u001b[0;31m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0m\u001b[1;32m  10241\u001b[0m         _ctx, \"Split\", name, axis, value, \"num_split\", num_split)\n\u001b[1;32m  10242\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "learning_rate = 0.001\n",
    "\n",
    "lstm.compile(optimizer=Adam(learning_rate=learning_rate),\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "lstm.fit((X_train[:,:,:13] - MEAN) / STDEV, y_train,\n",
    "         batch_size=256,\n",
    "         epochs=20,\n",
    "         validation_data=((X_val[:,:,:13] - MEAN) / STDEV, y_val),\n",
    "         callbacks=[early_stopping]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0VaelMU1wJm",
   "metadata": {
    "id": "e0VaelMU1wJm"
   },
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "Df0mEJan1zcT",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 130
    },
    "executionInfo": {
     "elapsed": 23365,
     "status": "ok",
     "timestamp": 1688742086395,
     "user": {
      "displayName": "Yoni Krichevsky",
      "userId": "07735752940575548299"
     },
     "user_tz": -180
    },
    "id": "Df0mEJan1zcT",
    "outputId": "4b05a6a6-28e4-446e-c143-6e013d622ce3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   10.5s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:   23.4s finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {color: black;background-color: white;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(min_impurity_decrease=1e-05, n_jobs=-1, verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" checked><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(min_impurity_decrease=1e-05, n_jobs=-1, verbose=1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(min_impurity_decrease=1e-05, n_jobs=-1, verbose=1)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_jobs=-1, verbose=1, min_impurity_decrease=.00001)\n",
    "rf.fit((X_train[:,:,0] - np.mean(X_train[:,:,0])) / np.std(X_train[:,:,0]), y_train)\n",
    "\n",
    "# rf.fit(X_train.reshape(X_train.shape[0], -1), y_train)\n",
    "# lstm.fit((X_train[:,:,0] - np.mean(X_train[:,:,0])) / np.std(X_train[:,:,0]), y_train,\n",
    "#          batch_size=256,\n",
    "#          epochs=20,\n",
    "#          validation_data=((X_val[:,:,0] - np.mean(X_train[:,:,0]) / np.std(X_train[:,:,0]), y_val),\n",
    "#          callbacks=[early_stopping]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bD82mOvq3BW7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1688742086396,
     "user": {
      "displayName": "Yoni Krichevsky",
      "userId": "07735752940575548299"
     },
     "user_tz": -180
    },
    "id": "bD82mOvq3BW7",
    "outputId": "ba529e20-8dae-4ad1-de3a-e0babd090a97"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.04      0.04      0.04       247\n",
      "           1       0.06      0.07      0.06       226\n",
      "           2       0.06      0.08      0.07       224\n",
      "           3       0.06      0.06      0.06       261\n",
      "           4       0.05      0.05      0.05       231\n",
      "           5       0.07      0.09      0.08       233\n",
      "           6       0.03      0.04      0.03       215\n",
      "           7       0.03      0.02      0.02       235\n",
      "           8       0.06      0.06      0.06       232\n",
      "           9       0.06      0.06      0.06       234\n",
      "          10       0.05      0.04      0.05       209\n",
      "          11       0.05      0.06      0.05       235\n",
      "          12       0.05      0.05      0.05       240\n",
      "          13       0.05      0.05      0.05       241\n",
      "          14       0.04      0.05      0.05       225\n",
      "          15       0.04      0.04      0.04       225\n",
      "          16       0.04      0.05      0.04       214\n",
      "          17       0.05      0.04      0.05       221\n",
      "          18       0.04      0.03      0.03       232\n",
      "          19       0.03      0.03      0.03       239\n",
      "\n",
      "    accuracy                           0.05      4619\n",
      "   macro avg       0.05      0.05      0.05      4619\n",
      "weighted avg       0.05      0.05      0.05      4619\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.1s finished\n"
     ]
    }
   ],
   "source": [
    "y_pred_rf = rf.predict((X_val[:,:,0] - np.mean(X_train[:,:,0])) / np.std(X_train[:,:,0]))\n",
    "print(classification_report(y_val, y_pred_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c731wAml4Dq0",
   "metadata": {
    "id": "c731wAml4Dq0"
   },
   "source": [
    "## 1st MFCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "gajsWlaF4Vcp",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1688742243034,
     "user": {
      "displayName": "Yoni Krichevsky",
      "userId": "07735752940575548299"
     },
     "user_tz": -180
    },
    "id": "gajsWlaF4Vcp",
    "outputId": "056bb76b-7ce2-4aa6-9e94-0a4e3de32715"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(617.7811827258297, 176.7701128678243)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MEAN = X_train[:,:,0].mean()\n",
    "STDEV = np.std(X_train[:,:,0])\n",
    "MEAN, STDEV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "o2Co-i9B4KcK",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 932,
     "status": "ok",
     "timestamp": 1688742582492,
     "user": {
      "displayName": "Yoni Krichevsky",
      "userId": "07735752940575548299"
     },
     "user_tz": -180
    },
    "id": "o2Co-i9B4KcK",
    "outputId": "d07e12a3-8ad2-4670-a9fd-09789548d469"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bidirectional_2 (Bidirectio  (None, 128)              33792     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 20)                2580      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 36,372\n",
      "Trainable params: 36,372\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "lstm = Sequential([Bidirectional(LSTM(64), input_shape=(32, 1)),\n",
    "                  #  Bidirectional(LSTM(128, return_sequences=True)),\n",
    "                  #  Bidirectional(LSTM(128)),\n",
    "                  #  Dense(64, activation='sigmoid'),\n",
    "                  #  Dropout(.5),\n",
    "                   Dense(20, activation='softmax')]\n",
    "                  )\n",
    "lstm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "_u5r4Nsg4rCX",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1688742583020,
     "user": {
      "displayName": "Yoni Krichevsky",
      "userId": "07735752940575548299"
     },
     "user_tz": -180
    },
    "id": "_u5r4Nsg4rCX",
    "outputId": "707b48fb-8944-450e-cb94-3ad48cb2a2ae"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((None, 32, 1), (None, 20))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm.input_shape, lstm.output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "dLDRVKIY4rCY",
   "metadata": {
    "executionInfo": {
     "elapsed": 555,
     "status": "ok",
     "timestamp": 1688742633522,
     "user": {
      "displayName": "Yoni Krichevsky",
      "userId": "07735752940575548299"
     },
     "user_tz": -180
    },
    "id": "dLDRVKIY4rCY"
   },
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='loss', patience=4, min_delta=.001)\n",
    "early_stopping_val = EarlyStopping(monitor='val_loss', patience=8, min_delta=.001)\n",
    "callbacks = [early_stopping, early_stopping_val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "dMl1iBTT4etd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12939,
     "status": "ok",
     "timestamp": 1688742741493,
     "user": {
      "displayName": "Yoni Krichevsky",
      "userId": "07735752940575548299"
     },
     "user_tz": -180
    },
    "id": "dMl1iBTT4etd",
    "outputId": "ed814c57-7c06-4943-c1da-04366a957f26"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "132/132 [==============================] - 6s 12ms/step - loss: 2.9984 - accuracy: 0.0531 - val_loss: 2.9962 - val_accuracy: 0.0526\n",
      "Epoch 2/20\n",
      "132/132 [==============================] - 1s 6ms/step - loss: 2.9972 - accuracy: 0.0500 - val_loss: 2.9969 - val_accuracy: 0.0496\n",
      "Epoch 3/20\n",
      "132/132 [==============================] - 1s 6ms/step - loss: 2.9965 - accuracy: 0.0505 - val_loss: 2.9972 - val_accuracy: 0.0513\n",
      "Epoch 4/20\n",
      "132/132 [==============================] - 1s 6ms/step - loss: 2.9963 - accuracy: 0.0530 - val_loss: 2.9982 - val_accuracy: 0.0483\n",
      "Epoch 5/20\n",
      "132/132 [==============================] - 1s 6ms/step - loss: 2.9962 - accuracy: 0.0509 - val_loss: 2.9975 - val_accuracy: 0.0463\n",
      "Epoch 6/20\n",
      "132/132 [==============================] - 1s 6ms/step - loss: 2.9960 - accuracy: 0.0525 - val_loss: 2.9974 - val_accuracy: 0.0520\n",
      "Epoch 7/20\n",
      "132/132 [==============================] - 1s 6ms/step - loss: 2.9961 - accuracy: 0.0529 - val_loss: 2.9971 - val_accuracy: 0.0546\n",
      "Epoch 8/20\n",
      "132/132 [==============================] - 1s 7ms/step - loss: 2.9958 - accuracy: 0.0530 - val_loss: 2.9979 - val_accuracy: 0.0522\n",
      "Epoch 9/20\n",
      "132/132 [==============================] - 1s 7ms/step - loss: 2.9958 - accuracy: 0.0526 - val_loss: 2.9970 - val_accuracy: 0.0522\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.01\n",
    "\n",
    "lstm.compile(optimizer=Adam(learning_rate=learning_rate),\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "lstm.fit((X_train[:,:,0] - MEAN) / STDEV, y_train,\n",
    "         batch_size=256,\n",
    "         epochs=20,\n",
    "         validation_data=((X_val[:,:,0] - MEAN) / STDEV, y_val),\n",
    "         callbacks=[early_stopping]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Z3RdXOZlrzkF",
   "metadata": {
    "id": "Z3RdXOZlrzkF"
   },
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "U5IiNdxWyLmY",
   "metadata": {
    "id": "U5IiNdxWyLmY"
   },
   "outputs": [],
   "source": [
    "y_pred_lstm = lstm.predict(X_val[:, :, None])\n",
    "print(classification_report(y_val, y_pred_lstm.argmax(axis=1)))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": [],
   "toc_visible": true
  },
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "297.865px",
    "left": "1754.33px",
    "right": "20px",
    "top": "120px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
